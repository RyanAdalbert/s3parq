{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.helpers.session_helper import SessionHelper\n",
    "session = SessionHelper().session"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "************ CONFIGURATION - PLEASE TOUCH **************\n",
    "Pipeline Builder configuration: creates configurations from variables specified here!!\n",
    "This cell will be off in production as configurations will come from the configuration postgres DB.\n",
    "\"\"\"\n",
    "# config vars: this dataset\n",
    "config_pharma = \"sun\" # the pharmaceutical company which owns {brand}\n",
    "config_brand = \"ilumya\" # the brand this pipeline operates on\n",
    "config_state = \"enrich\" # the state this transform runs in\n",
    "config_name = \"enrich_cancel_before_active\" # the name of this transform, which is the name of this notebook without .ipynb\n",
    "\n",
    "# input vars: dataset to fetch. Recall that a contract published to S3 has a key format branch/pharma/brand/state/name\n",
    "# Note: this key is case sensitive!!\n",
    "input_pharma = \"sun\"\n",
    "input_brand = \"ilumya\"\n",
    "input_state = \"ingest\"\n",
    "input_name = \"symphony_health_association_ingest_column_mapping\"\n",
    "input_branch = \"sun-extract-validation\" # if None, input_branch is automagically set to your working branch"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "************ SETUP - DON'T TOUCH **************\n",
    "Populating config mocker based on config parameters...\n",
    "\"\"\"\n",
    "import core.helpers.pipeline_builder as builder\n",
    "\n",
    "ids = builder.build(config_pharma, config_brand, config_state, config_name, session)\n",
    "transform_id = ids[0]\n",
    "run_id = ids[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "************ SETUP - DON'T TOUCH **************\n",
    "This section imports data from the configuration database\n",
    "and should not need to be altered or otherwise messed with. \n",
    "~~These are not the droids you are looking for~~\n",
    "\"\"\"\n",
    "from core.constants import BRANCH_NAME, ENV_BUCKET\n",
    "from core.helpers.session_helper import SessionHelper\n",
    "from core.models.configuration import Transformation\n",
    "from dataclasses import dataclass\n",
    "from core.dataset_contract import DatasetContract\n",
    "\n",
    "db_transform = session.query(Transformation).filter(Transformation.id == transform_id).one()\n",
    "\n",
    "@dataclass\n",
    "class DbTransform:\n",
    "    id: int = db_transform.id ## the instance id of the transform in the config app\n",
    "    name: str = db_transform.transformation_template.name ## the transform name in the config app\n",
    "    state: str = db_transform.pipeline_state.pipeline_state_type.name ## the pipeline state, one of raw, ingest, master, enhance, enrich, metrics, dimensional\n",
    "    branch:str = BRANCH_NAME ## the git branch for this execution \n",
    "    brand: str = db_transform.pipeline_state.pipeline.brand.name ## the pharma brand name\n",
    "    pharmaceutical_company: str = db_transform.pipeline_state.pipeline.brand.pharmaceutical_company.name # the pharma company name\n",
    "    publish_contract: DatasetContract = DatasetContract(branch=BRANCH_NAME,\n",
    "                            state=db_transform.pipeline_state.pipeline_state_type.name,\n",
    "                            parent=db_transform.pipeline_state.pipeline.brand.pharmaceutical_company.name,\n",
    "                            child=db_transform.pipeline_state.pipeline.brand.name,\n",
    "                            dataset=db_transform.transformation_template.name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CORE Cartridge Notebook::[transform name here]\n",
    "![CORE Logo](assets/coreLogo.png) \n",
    "\n",
    "---\n",
    "## Keep in Mind\n",
    "Good Transforms Are...\n",
    "- **singular in purpose:** good transforms do one and only one thing, and handle all known cases for that thing. \n",
    "- **repeatable:** transforms should be written in a way that they can be run against the same dataset an infinate number of times and get the same result every time. \n",
    "- **easy to read:** 99 times out of 100, readable, clear code that runs a little slower is more valuable than a mess that runs quickly. \n",
    "- **No 'magic numbers':** if a variable or function is not instantly obvious as to what it is or does, without context, maybe consider renaming it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow - how to use this notebook to make science\n",
    "#### Data Science\n",
    "1. **Document your transform.** Fill out the _description_ cell below describing what it is this transform does; this will appear in the configuration application where Ops will create, configure and update pipelines. \n",
    "1. **Define your config object.** Fill out the _configuration_ cell below the commented-out guide to define the variables you want ops to set in the configuration application (these will populate here for every pipeline). \n",
    "2. **Build your transformation logic.** Use the transformation cell to do that magic that you do. \n",
    "![caution](assets/cautionTape.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "********* VARIABLES - PLEASE TOUCH ********* \n",
    "This section defines what you expect to get from the configuration application \n",
    "in a single \"transform\" object. Define the vars you need here, and comment inline to the right of them \n",
    "for all-in-one documentation. \n",
    "Engineering will build a production \"transform\" object for every pipeline that matches what you define here.\n",
    "\n",
    "@@@ FORMAT OF THE DATA CLASS IS: @@@ \n",
    "\n",
    "<variable_name>: <data_type> #<comment explaining what the value is to future us>\n",
    "\n",
    "e.g.\n",
    "\n",
    "class Transform(DbTransform):\n",
    "    some_ratio: float\n",
    "    site_name: str\n",
    "\n",
    "~~These ARE the droids you are looking for~~\n",
    "\"\"\"\n",
    "\n",
    "class Transform(DbTransform):\n",
    "    '''\n",
    "    YOUR properties go here!!\n",
    "    Variable properties should be assigned to the exact name of\n",
    "    the transformation as it appears in the Jupyter notebook filename.\n",
    "    '''\n",
    "    trans_id: str # Column name to use for Transaction ID\n",
    "    brand_col: str # Column name to use for Brand\n",
    "    patient_id: str # Column name to use for Patient ID\n",
    "    pharmacy: str # Column name to use for Pharmacy\n",
    "    status_date: str # Column name to use for Status Date\n",
    "    referral_date: str # Column name to use for Referral Date\n",
    "    status: str # Column name to use for Status\n",
    "    substatus: str # Column name to use for Substatus\n",
    "    hierarchy: str # Column name to use for Hierarchy\n",
    "    active_substatus_code: str # Active Shipment Substatus code, e.g. 'SHIPMENT' (customer-specific)\n",
    "    cancel_discontinue_status_code: list # List of Cancelled and Discontinued status codes (customer-specific)\n",
    "    bvpa_cancel_discontinue_substatus: list # List of accepted substatus codes used for BVPA hierarchy, e.g. ['INSURANCE DENIED','COVERAGE DENIED'] (customer-specific)\n",
    "    active_diff_threshold: int # Threshold value for Active/Cancel date difference logic (customer-specific)\n",
    "    prior_diff_threshold: int # Threshold value for Cancel/Prior date difference logic (customer-specific)\n",
    "    active_hierarchy: str # Hierarchy to assign to statuses after the first fill, e.g. 'ACTIVE - SHIPMENT' (customer-specific)\n",
    "    remove_from_ttff: str # Hierarchy to assign to statuses that are ignored from TTFF (customer-specific)\n",
    "    no_status_clarity: str # Hierarchy to assign to cancelled/discontinued statuses with no status clarity (customer-specific)\n",
    "    bvpa_hierarchy: str # Hierarchy to assign to cancelled/discontinued statuses that have BVPA substatus (customer-specific)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = Transform()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## Please place your value assignments for development here!!\n",
    "## This cell will be turned off in production and Engineering will set to pull form the configuration application instead\n",
    "\n",
    "if input_pharma == 'sun':\n",
    "    transform.trans_id = 'pharm_transaction_id'\n",
    "    transform.brand_col = 'medication'\n",
    "    transform.patient_id = 'msa_patient_id'\n",
    "    transform.pharmacy = 'pharm_code'\n",
    "    transform.status_date = 'status_date'\n",
    "    transform.referral_date = 'ref_date'\n",
    "    transform.status =  'status_code'\n",
    "    transform.substatus =  'sub_status'\n",
    "    transform.hierarchy = 'hierarchy'\n",
    "    datetime = '%Y%m%d'\n",
    "    transform.active_substatus_code = 'SHIPMENT'\n",
    "    transform.cancel_discontinue_status_code = ['CANCELLED', 'DISCONTINUED']\n",
    "    transform.bvpa_cancel_discontinue_substatus = ['INSURANCE DENIED']\n",
    "    transform.active_diff_threshold = 60\n",
    "    transform.prior_diff_threshold = 60\n",
    "    transform.active_hierarchy = 'ACTIVE - SHIPMENT'\n",
    "    transform.remove_from_ttff = 'REMOVE FROM TTFF'\n",
    "    transform.no_status_clarity = 'NO STATUS CLARITY'\n",
    "    transform.bvpa_hierarchy = 'BVPA'\n",
    "    \n",
    "else:\n",
    "    transform.trans_id = 'pmcTransactionId'\n",
    "    transform.brand_col = 'medication'\n",
    "    transform.patient_id = 'pmcPatientID'\n",
    "    transform.pharmacy = 'pharmName'\n",
    "    transform.status_date = 'statusDate'\n",
    "    transform.referral_date = 'refDate'\n",
    "    transform.status =  'statusCode'\n",
    "    transform.substatus =  'custStatusCode'\n",
    "    transform.hierarchy = 'hierarchy'\n",
    "    datetime = '%Y-%b-%d'\n",
    "    transform.active_substatus_code = 'S01'\n",
    "    transform.cancel_discontinue_status_code = ['CANCELLED', 'DISCONTINUED']\n",
    "    transform.bvpa_cancel_discontinue_substatus = ['INSURANCE DENIED']\n",
    "    transform.active_diff_threshold = 60\n",
    "    transform.prior_diff_threshold = 60\n",
    "    transform.active_hierarchy = 'ACTIVE - S01'\n",
    "    transform.remove_from_ttff = 'REMOVE FROM TTFF'\n",
    "    transform.no_status_clarity = 'NO STATUS CLARITY'\n",
    "    transform.bvpa_hierarchy = 'BVPA'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description\n",
    "What does this transformation do? be specific.\n",
    "\n",
    "![what does your transform do](assets/what.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cancelled/Discontinued Before Active enrichment.\n",
    "Assigns hierarchy values in cases where cancelled or discontinued status is reported before first active shipment.  This is used as part of the TTFF enrichment.  See logic diagram below:\n",
    "\n",
    "<img src='assets/cancel_before_active.svg' width=700>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\"\"\"\n",
    "************ FETCH DATA - TOUCH, BUT CAREFULLY **************\n",
    "This cell will be turned off in production, as the input_contract will be handled by the pipeline.\n",
    "\"\"\"\n",
    "\n",
    "if not input_branch:\n",
    "    input_branch = BRANCH_NAME\n",
    "input_contract = DatasetContract(branch=input_branch, state=input_state, parent=input_pharma, child=input_brand, dataset=input_name)\n",
    "run_filter = []\n",
    "run_filter.append(dict(partition=\"__metadata_run_id\", comparison=\"==\", values=[4]))\n",
    "# IF YOU HAVE PUBLISHED DATA MULTIPLE TIMES, uncomment the above line and change the int to the run_id to fetch.\n",
    "# Otherwise, you will have duplicate values in your fetched dataset!\n",
    "df = input_contract.fetch(filters=run_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Retrieve current dataset from contract\n",
    "from core.dataset_diff import DatasetDiff\n",
    "\n",
    "diff = DatasetDiff(db_transform.id)\n",
    "df = diff.get_diff(transform_name=transform.input_transform, values=[run_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Use the variables above to execute your transformation. the final output needs to be a variable named final_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', 100)\n",
    "pd.set_option('display.max_rows', 500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DATA CLEANING: ADDRESS THIS SECTION BEFORE PIPELINE INTEGRATION"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# CLEAN DATA - This step should not be necessary once transform is integrated into pipeline.\n",
    "#    Extract and map relevant columns\n",
    "#    Convert dates to datetime format\n",
    "#    Extract brand from medication\n",
    "#    Convert substatuses to uppercase\n",
    "#    Populate null referral dates with the min(status_date) for that patient/pharmacy/brand.\n",
    "    \n",
    "def clean_data(cust_input_df, datetime, transform):\n",
    "\n",
    "    clean_df = (\n",
    "        cust_input_df\n",
    "        .loc[:,\n",
    "             [transform.trans_id,\n",
    "              transform.patient_id,\n",
    "              transform.pharmacy,\n",
    "              transform.brand_col,\n",
    "              transform.status_date,\n",
    "              transform.referral_date,\n",
    "              transform.status,\n",
    "              transform.substatus]\n",
    "            ]\n",
    "        .assign(**{\n",
    "            transform.status_date : lambda x: (\n",
    "                pd.to_datetime(\n",
    "                    x[transform.status_date].str[:8].astype(str),\n",
    "                    format=datetime,\n",
    "                    errors='coerce'\n",
    "                )),\n",
    "            'min_status_date' : lambda x: (\n",
    "                x.groupby([transform.patient_id,transform.pharmacy,transform.brand_col])\n",
    "                [transform.status_date]\n",
    "                .transform(min)\n",
    "            )\n",
    "        })       \n",
    "        .fillna(value={transform.referral_date:'min_status_date'})\n",
    "        .assign(**{\n",
    "            transform.referral_date : lambda x: (\n",
    "                pd.to_datetime(\n",
    "                    x[transform.referral_date].str[:8].astype(str),\n",
    "                    format=datetime,\n",
    "                    errors='coerce'\n",
    "                ))\n",
    "        })\n",
    "        .dropna()\n",
    "        .assign(**{\n",
    "            transform.brand_col : lambda x: (x[transform.brand_col].apply(lambda x: x.split()[0].strip())),\n",
    "            transform.status : lambda x: (x[transform.status].str.upper()),\n",
    "            transform.substatus : lambda x: (x[transform.substatus].str.upper())\n",
    "        })\n",
    "        .drop(['min_status_date'],axis=1)\n",
    "        .drop_duplicates()\n",
    "        .sort_values(\n",
    "            by=[transform.patient_id, transform.pharmacy, transform.brand_col, transform.status_date, transform.status, transform.trans_id],\n",
    "            ascending=[True, True, True, True, False, True])\n",
    "        .reset_index(drop=True)\n",
    "        .assign(**{transform.hierarchy : 'Dummy'})\n",
    "    )\n",
    "\n",
    "    return clean_df"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df = clean_data(\n",
    "    df,\n",
    "    datetime,\n",
    "    transform\n",
    ")\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### APPLY TRANSFORM LOGIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign Patient Journey (pj_id) and Patient Journey Step (pj_step) identifiers\n",
    "# (These IDs are used for calculation purposes only.  They will not be published)\n",
    "\n",
    "def pj(df):\n",
    "    pj_df = (\n",
    "        df\n",
    "        .assign(**{\n",
    "            'pj_id' : lambda x: (\n",
    "                x.groupby([transform.patient_id, transform.pharmacy, transform.brand_col]).grouper.group_info[0]\n",
    "            ),\n",
    "            'pj_step' : lambda x: x.index\n",
    "        })\n",
    "        .sort_values(\n",
    "            by=[transform.patient_id, transform.pharmacy, transform.brand_col, transform.status_date, transform.status, transform.trans_id],\n",
    "            ascending=[True, True, True, True, False, True])\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "    return pj_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to only include patient journeys where:\n",
    "#    a) Active Shipment status is reported\n",
    "#    b) Cancelled or Discontinued status occurs prior to first active shipment\n",
    "\n",
    "def cancel_before_active(pj_df):\n",
    "    cancel_before_active_df = (\n",
    "        pj_df\n",
    "        .assign(active_step = lambda x: (\n",
    "            np.where(\n",
    "                x[transform.substatus] == transform.active_substatus_code,\n",
    "                x['pj_step'],\n",
    "                np.nan\n",
    "        )))\n",
    "        .assign(active_status_date = lambda x: (\n",
    "            pd.to_datetime(np.where(\n",
    "                x[transform.substatus] == transform.active_substatus_code,\n",
    "                x[transform.status_date],\n",
    "                pd.NaT\n",
    "        ))))\n",
    "        .assign(first_active_step = lambda x: (\n",
    "            x.groupby(['pj_id'])['active_step']\n",
    "            .transform(min)\n",
    "        ))\n",
    "        .assign(first_active_status_date = lambda x: (\n",
    "            x.groupby(['pj_id'])['active_status_date']\n",
    "            .transform(min)\n",
    "        ))\n",
    "        .drop(['active_step', 'active_status_date'], axis=1)\n",
    "        .assign(active_cancel_diff = lambda x:(\n",
    "            np.where(x[transform.status].isin(transform.cancel_discontinue_status_code),\n",
    "                     (x['first_active_status_date'] - x[transform.status_date]) / np.timedelta64(1, 'D'),\n",
    "                     np.nan\n",
    "                    )\n",
    "        ))\n",
    "        .assign(active_cancel_diff = lambda x: (\n",
    "            x.groupby(['pj_id'], sort=False)['active_cancel_diff']\n",
    "            .transform(lambda x: x.bfill())\n",
    "            ))\n",
    "        .loc[lambda x: (\n",
    "            x['pj_id'].isin(x\n",
    "                            .loc[x['active_cancel_diff'] >= 0]\n",
    "                            .pj_id\n",
    "                            .drop_duplicates()\n",
    "                            .tolist()\n",
    "                           )\n",
    "        )]\n",
    "    )\n",
    "    return cancel_before_active_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each patient journey step, get the previous status. If it's the first step in the patient journey, show \"no_prior_status\"\n",
    "# For cancelled or discontinued statuses, get the time spent in previous status (if >= 60 days) - and then backfill values for that patient journey.\n",
    "\n",
    "def prior_status(cancel_before_active_df):\n",
    "    prior_status_df = (\n",
    "        cancel_before_active_df\n",
    "        .assign(prior_status = lambda x:(\n",
    "            x.groupby(['pj_id'])[transform.status]\n",
    "            .transform(lambda x: x.shift(1))\n",
    "        ))\n",
    "        .fillna(value={'prior_status':'no_prior_status'})\n",
    "        .assign(prior_status_diff = lambda x: (\n",
    "            np.where(\n",
    "                (x[transform.status].isin(transform.cancel_discontinue_status_code)) & ((x[transform.status_date] - x[transform.status_date].shift(1))/np.timedelta64(1,'D') >= 60),\n",
    "                (x\n",
    "                 .groupby(['pj_id'])[transform.status_date]\n",
    "                 .transform(lambda x: (x - x.shift(1))/np.timedelta64(1,'D'))),\n",
    "                np.nan       \n",
    "            )\n",
    "        ))\n",
    "        .assign(prior_status_diff = lambda x: (\n",
    "            x.groupby(['pj_id'], sort=False)['prior_status_diff']\n",
    "            .transform(lambda x: x.bfill())\n",
    "        ))\n",
    "    )\n",
    "    return prior_status_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply logic to determine patient journey hierarchy. See logic diagram in transform description.\n",
    "\n",
    "def hierarchy(prior_status_df):\n",
    "    hierarchy_df = (\n",
    "        prior_status_df\n",
    "        .assign(**{\n",
    "            transform.hierarchy : lambda x:(\n",
    "                np.where(\n",
    "                    x['pj_step'] >= x['first_active_step'],\n",
    "                    transform.active_hierarchy,\n",
    "                    np.where(\n",
    "                        x['active_cancel_diff'] > transform.active_diff_threshold,\n",
    "                        transform.remove_from_ttff,\n",
    "                        np.where(\n",
    "                            (~x[transform.status].isin(transform.cancel_discontinue_status_code)),\n",
    "                            np.where(\n",
    "                                x['prior_status_diff'] > transform.prior_diff_threshold,\n",
    "                                transform.remove_from_ttff,\n",
    "                                x[transform.hierarchy]\n",
    "                            ),\n",
    "                            np.where(\n",
    "                                (x['prior_status_diff'] > transform.prior_diff_threshold) | (x['prior_status'] == 'no_prior_status'),\n",
    "                                transform.no_status_clarity,\n",
    "                                np.where(\n",
    "                                    x[transform.substatus].isin(transform.bvpa_cancel_discontinue_substatus),\n",
    "                                    transform.bvpa_hierarchy,\n",
    "                                    None\n",
    "                                )\n",
    "                            )\n",
    "                        )\n",
    "                    )\n",
    "                )\n",
    "            )\n",
    "        })\n",
    "                \n",
    "        .reset_index(drop=True)\n",
    "        .assign(**{\n",
    "            transform.hierarchy : lambda x: (\n",
    "                x.groupby(['pj_id'], sort=False)[transform.hierarchy]\n",
    "                .transform(lambda x: x.ffill())\n",
    "                )\n",
    "        })\n",
    "    )\n",
    "    return hierarchy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rec_date</th>\n",
       "      <th>pharm_code</th>\n",
       "      <th>pharm_npi</th>\n",
       "      <th>transtype</th>\n",
       "      <th>pharm_transaction_id</th>\n",
       "      <th>trans_seq</th>\n",
       "      <th>ref_source</th>\n",
       "      <th>ref_date</th>\n",
       "      <th>program_id</th>\n",
       "      <th>pharmacy_id</th>\n",
       "      <th>pat_last_name</th>\n",
       "      <th>pat_first_name</th>\n",
       "      <th>pat_dob</th>\n",
       "      <th>pat_gender</th>\n",
       "      <th>pat_addr1</th>\n",
       "      <th>pat_addr2</th>\n",
       "      <th>pat_city</th>\n",
       "      <th>pat_state</th>\n",
       "      <th>pat_zip</th>\n",
       "      <th>dx1_code</th>\n",
       "      <th>dx2_code</th>\n",
       "      <th>status_date</th>\n",
       "      <th>status_code</th>\n",
       "      <th>sub_status</th>\n",
       "      <th>pres_last_name</th>\n",
       "      <th>pres_first_name</th>\n",
       "      <th>pres_addr1</th>\n",
       "      <th>pres_addr2</th>\n",
       "      <th>pres_city</th>\n",
       "      <th>pres_state</th>\n",
       "      <th>pres_zip</th>\n",
       "      <th>pres_phone</th>\n",
       "      <th>pres_npi</th>\n",
       "      <th>pres_dea</th>\n",
       "      <th>facility_name</th>\n",
       "      <th>rxdate</th>\n",
       "      <th>rxnumber</th>\n",
       "      <th>rxrefills</th>\n",
       "      <th>rxfill</th>\n",
       "      <th>refill_remaining</th>\n",
       "      <th>prev_disp</th>\n",
       "      <th>rx_ndc_number</th>\n",
       "      <th>medication</th>\n",
       "      <th>quantity</th>\n",
       "      <th>day_supply</th>\n",
       "      <th>ship_date</th>\n",
       "      <th>ship_carrier</th>\n",
       "      <th>shiptracking_num</th>\n",
       "      <th>ship_location</th>\n",
       "      <th>ship_address</th>\n",
       "      <th>ship_city</th>\n",
       "      <th>ship_state</th>\n",
       "      <th>ship_zip</th>\n",
       "      <th>has_medical</th>\n",
       "      <th>primary_coverage_type</th>\n",
       "      <th>primary_payer_name</th>\n",
       "      <th>primary_payer_type</th>\n",
       "      <th>secondary_coverage_type</th>\n",
       "      <th>secondary_payer_name</th>\n",
       "      <th>secondary_payer_type</th>\n",
       "      <th>plan_paid_amt</th>\n",
       "      <th>pat_copay</th>\n",
       "      <th>copay_assist_amount</th>\n",
       "      <th>oth_payer_amt</th>\n",
       "      <th>xfer_pharmname</th>\n",
       "      <th>msa_patient_id</th>\n",
       "      <th>msa_patient_bmap</th>\n",
       "      <th>__metadata_run_timestamp</th>\n",
       "      <th>__metadata_app_version</th>\n",
       "      <th>__metadata_output_contract</th>\n",
       "      <th>__metadata_transform_timestamp</th>\n",
       "      <th>__metadata_run_id</th>\n",
       "      <th>pj_id</th>\n",
       "      <th>pj_step</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20181106 23:00:00</td>\n",
       "      <td>CVS</td>\n",
       "      <td>1043382302</td>\n",
       "      <td>COM</td>\n",
       "      <td>182176830</td>\n",
       "      <td>0</td>\n",
       "      <td>HUB</td>\n",
       "      <td>20181019 23:00:00</td>\n",
       "      <td>1303801</td>\n",
       "      <td>9009919609</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>30</td>\n",
       "      <td>L40.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20181231 23:00:00</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>SHIPMENT</td>\n",
       "      <td>CHAO</td>\n",
       "      <td>TOMAS</td>\n",
       "      <td>100 STONEFOREST DR</td>\n",
       "      <td>STE 320</td>\n",
       "      <td>WOODSTOCK</td>\n",
       "      <td>GA</td>\n",
       "      <td>30189</td>\n",
       "      <td>7705165199</td>\n",
       "      <td>1316003577</td>\n",
       "      <td>MC0707286</td>\n",
       "      <td>None</td>\n",
       "      <td>20180918</td>\n",
       "      <td>81872197</td>\n",
       "      <td>0</td>\n",
       "      <td>00</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>47335017795</td>\n",
       "      <td>ILUMYA SD PFS</td>\n",
       "      <td>1</td>\n",
       "      <td>28</td>\n",
       "      <td>20181106 23:00:00</td>\n",
       "      <td>UPS</td>\n",
       "      <td>1Z265561NW85358841</td>\n",
       "      <td>PRESCRIBER OFFICE</td>\n",
       "      <td>100 STONE FOREST DRIVE,SUITE 320</td>\n",
       "      <td>WOODSTOCK</td>\n",
       "      <td>GA</td>\n",
       "      <td>30</td>\n",
       "      <td>None</td>\n",
       "      <td>PHARMACY</td>\n",
       "      <td>None</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2120001</td>\n",
       "      <td>VVVVV</td>\n",
       "      <td>2019-06-26 15:28:20</td>\n",
       "      <td>0.0.11</td>\n",
       "      <td>s3://ichain-dev/sun-extract-validation/sun/ilu...</td>\n",
       "      <td>2019-06-26 15:33:32</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20181220 23:00:00</td>\n",
       "      <td>CVS</td>\n",
       "      <td>1043382302</td>\n",
       "      <td>COM</td>\n",
       "      <td>183711690</td>\n",
       "      <td>0</td>\n",
       "      <td>HUB</td>\n",
       "      <td>20181019 23:00:00</td>\n",
       "      <td>1303801</td>\n",
       "      <td>9009919609</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>30</td>\n",
       "      <td>L40.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20181231 23:00:00</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>SHIPMENT</td>\n",
       "      <td>CHAO</td>\n",
       "      <td>TOMAS</td>\n",
       "      <td>100 STONEFOREST DR</td>\n",
       "      <td>STE 320</td>\n",
       "      <td>WOODSTOCK</td>\n",
       "      <td>GA</td>\n",
       "      <td>30189</td>\n",
       "      <td>7705165199</td>\n",
       "      <td>1316003577</td>\n",
       "      <td>MC0707286</td>\n",
       "      <td>None</td>\n",
       "      <td>20180918</td>\n",
       "      <td>81872456</td>\n",
       "      <td>0</td>\n",
       "      <td>00</td>\n",
       "      <td>0</td>\n",
       "      <td>None</td>\n",
       "      <td>47335017795</td>\n",
       "      <td>ILUMYA SD PFS</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>20181220 23:00:00</td>\n",
       "      <td>UPS</td>\n",
       "      <td>1Z265561NW86226400</td>\n",
       "      <td>PRESCRIBER OFFICE</td>\n",
       "      <td>100 STONE FOREST DRIVE,100 STONE FOREST DRIVE ...</td>\n",
       "      <td>WOODSTOCK</td>\n",
       "      <td>GA</td>\n",
       "      <td>30</td>\n",
       "      <td>None</td>\n",
       "      <td>PHARMACY</td>\n",
       "      <td>None</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2120001</td>\n",
       "      <td>VVVVV</td>\n",
       "      <td>2019-06-26 15:28:20</td>\n",
       "      <td>0.0.11</td>\n",
       "      <td>s3://ichain-dev/sun-extract-validation/sun/ilu...</td>\n",
       "      <td>2019-06-26 15:33:32</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20190308 23:00:00</td>\n",
       "      <td>CVS</td>\n",
       "      <td>1043382302</td>\n",
       "      <td>COM</td>\n",
       "      <td>901165655620190308000000</td>\n",
       "      <td>0</td>\n",
       "      <td>HUB</td>\n",
       "      <td>20190308 23:00:00</td>\n",
       "      <td>1337729</td>\n",
       "      <td>9011656556</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>08</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>20190308 23:00:00</td>\n",
       "      <td>PENDING</td>\n",
       "      <td>NEW</td>\n",
       "      <td>PRADEEP</td>\n",
       "      <td>MEERA</td>\n",
       "      <td>347 MT PLEASANT AVE</td>\n",
       "      <td>STE 103</td>\n",
       "      <td>WEST ORANGE</td>\n",
       "      <td>NJ</td>\n",
       "      <td>07052</td>\n",
       "      <td>9735712121</td>\n",
       "      <td>1346529948</td>\n",
       "      <td>MP3244314</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MEDICAL</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2120004</td>\n",
       "      <td>VVVVV</td>\n",
       "      <td>2019-06-26 15:28:20</td>\n",
       "      <td>0.0.11</td>\n",
       "      <td>s3://ichain-dev/sun-extract-validation/sun/ilu...</td>\n",
       "      <td>2019-06-26 15:33:32</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20190311 23:00:00</td>\n",
       "      <td>CVS</td>\n",
       "      <td>1518948413</td>\n",
       "      <td>COM</td>\n",
       "      <td>901165655620190311000000</td>\n",
       "      <td>0</td>\n",
       "      <td>HUB</td>\n",
       "      <td>20190308 23:00:00</td>\n",
       "      <td>1337729</td>\n",
       "      <td>9011656556</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>08</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>20190311 23:00:00</td>\n",
       "      <td>PENDING</td>\n",
       "      <td>APPEAL</td>\n",
       "      <td>PRADEEP</td>\n",
       "      <td>MEERA</td>\n",
       "      <td>347 MT PLEASANT AVE</td>\n",
       "      <td>STE 103</td>\n",
       "      <td>WEST ORANGE</td>\n",
       "      <td>NJ</td>\n",
       "      <td>07052</td>\n",
       "      <td>9735712121</td>\n",
       "      <td>1346529948</td>\n",
       "      <td>MP3244314</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MEDICAL</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2120004</td>\n",
       "      <td>VVVVV</td>\n",
       "      <td>2019-06-26 15:28:20</td>\n",
       "      <td>0.0.11</td>\n",
       "      <td>s3://ichain-dev/sun-extract-validation/sun/ilu...</td>\n",
       "      <td>2019-06-26 15:33:32</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20190314 23:00:00</td>\n",
       "      <td>CVS</td>\n",
       "      <td>1518948413</td>\n",
       "      <td>COM</td>\n",
       "      <td>901165655620190314000000</td>\n",
       "      <td>0</td>\n",
       "      <td>HUB</td>\n",
       "      <td>20190308 23:00:00</td>\n",
       "      <td>1337729</td>\n",
       "      <td>9011656556</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>08</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>20190314 23:00:00</td>\n",
       "      <td>CANCELLED</td>\n",
       "      <td>INSURANCE DENIED</td>\n",
       "      <td>PRADEEP</td>\n",
       "      <td>MEERA</td>\n",
       "      <td>347 MT PLEASANT AVE</td>\n",
       "      <td>STE 103</td>\n",
       "      <td>WEST ORANGE</td>\n",
       "      <td>NJ</td>\n",
       "      <td>07052</td>\n",
       "      <td>9735712121</td>\n",
       "      <td>1346529948</td>\n",
       "      <td>MP3244314</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>MEDICAL</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>2120004</td>\n",
       "      <td>VVVVV</td>\n",
       "      <td>2019-06-26 15:28:20</td>\n",
       "      <td>0.0.11</td>\n",
       "      <td>s3://ichain-dev/sun-extract-validation/sun/ilu...</td>\n",
       "      <td>2019-06-26 15:33:32</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>1041</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            rec_date pharm_code   pharm_npi transtype  \\\n",
       "0  20181106 23:00:00        CVS  1043382302       COM   \n",
       "1  20181220 23:00:00        CVS  1043382302       COM   \n",
       "2  20190308 23:00:00        CVS  1043382302       COM   \n",
       "3  20190311 23:00:00        CVS  1518948413       COM   \n",
       "4  20190314 23:00:00        CVS  1518948413       COM   \n",
       "\n",
       "       pharm_transaction_id trans_seq ref_source           ref_date  \\\n",
       "0                 182176830         0        HUB  20181019 23:00:00   \n",
       "1                 183711690         0        HUB  20181019 23:00:00   \n",
       "2  901165655620190308000000         0        HUB  20190308 23:00:00   \n",
       "3  901165655620190311000000         0        HUB  20190308 23:00:00   \n",
       "4  901165655620190314000000         0        HUB  20190308 23:00:00   \n",
       "\n",
       "  program_id pharmacy_id pat_last_name pat_first_name pat_dob pat_gender  \\\n",
       "0    1303801  9009919609          None           None    None          M   \n",
       "1    1303801  9009919609          None           None    None          M   \n",
       "2    1337729  9011656556          None           None    None          M   \n",
       "3    1337729  9011656556          None           None    None          M   \n",
       "4    1337729  9011656556          None           None    None          M   \n",
       "\n",
       "  pat_addr1 pat_addr2 pat_city pat_state pat_zip dx1_code dx2_code  \\\n",
       "0      None      None     None      None      30    L40.0     None   \n",
       "1      None      None     None      None      30    L40.0     None   \n",
       "2      None      None     None      None      08     None     None   \n",
       "3      None      None     None      None      08     None     None   \n",
       "4      None      None     None      None      08     None     None   \n",
       "\n",
       "         status_date status_code        sub_status pres_last_name  \\\n",
       "0  20181231 23:00:00      ACTIVE          SHIPMENT           CHAO   \n",
       "1  20181231 23:00:00      ACTIVE          SHIPMENT           CHAO   \n",
       "2  20190308 23:00:00     PENDING               NEW        PRADEEP   \n",
       "3  20190311 23:00:00     PENDING            APPEAL        PRADEEP   \n",
       "4  20190314 23:00:00   CANCELLED  INSURANCE DENIED        PRADEEP   \n",
       "\n",
       "  pres_first_name           pres_addr1 pres_addr2    pres_city pres_state  \\\n",
       "0           TOMAS   100 STONEFOREST DR    STE 320    WOODSTOCK         GA   \n",
       "1           TOMAS   100 STONEFOREST DR    STE 320    WOODSTOCK         GA   \n",
       "2           MEERA  347 MT PLEASANT AVE    STE 103  WEST ORANGE         NJ   \n",
       "3           MEERA  347 MT PLEASANT AVE    STE 103  WEST ORANGE         NJ   \n",
       "4           MEERA  347 MT PLEASANT AVE    STE 103  WEST ORANGE         NJ   \n",
       "\n",
       "  pres_zip  pres_phone    pres_npi   pres_dea facility_name    rxdate  \\\n",
       "0    30189  7705165199  1316003577  MC0707286          None  20180918   \n",
       "1    30189  7705165199  1316003577  MC0707286          None  20180918   \n",
       "2    07052  9735712121  1346529948  MP3244314          None      None   \n",
       "3    07052  9735712121  1346529948  MP3244314          None      None   \n",
       "4    07052  9735712121  1346529948  MP3244314          None      None   \n",
       "\n",
       "   rxnumber rxrefills rxfill refill_remaining prev_disp rx_ndc_number  \\\n",
       "0  81872197         0     00                0      None   47335017795   \n",
       "1  81872456         0     00                0      None   47335017795   \n",
       "2      None      None   None             None      None          None   \n",
       "3      None      None   None             None      None          None   \n",
       "4      None      None   None             None      None          None   \n",
       "\n",
       "      medication quantity day_supply          ship_date ship_carrier  \\\n",
       "0  ILUMYA SD PFS        1         28  20181106 23:00:00          UPS   \n",
       "1  ILUMYA SD PFS        1         31  20181220 23:00:00          UPS   \n",
       "2           None     None       None               None         None   \n",
       "3           None     None       None               None         None   \n",
       "4           None     None       None               None         None   \n",
       "\n",
       "     shiptracking_num      ship_location  \\\n",
       "0  1Z265561NW85358841  PRESCRIBER OFFICE   \n",
       "1  1Z265561NW86226400  PRESCRIBER OFFICE   \n",
       "2                None               None   \n",
       "3                None               None   \n",
       "4                None               None   \n",
       "\n",
       "                                        ship_address  ship_city ship_state  \\\n",
       "0                   100 STONE FOREST DRIVE,SUITE 320  WOODSTOCK         GA   \n",
       "1  100 STONE FOREST DRIVE,100 STONE FOREST DRIVE ...  WOODSTOCK         GA   \n",
       "2                                               None       None       None   \n",
       "3                                               None       None       None   \n",
       "4                                               None       None       None   \n",
       "\n",
       "  ship_zip has_medical primary_coverage_type primary_payer_name  \\\n",
       "0       30        None              PHARMACY               None   \n",
       "1       30        None              PHARMACY               None   \n",
       "2     None        None               MEDICAL               None   \n",
       "3     None        None               MEDICAL               None   \n",
       "4     None        None               MEDICAL               None   \n",
       "\n",
       "  primary_payer_type secondary_coverage_type secondary_payer_name  \\\n",
       "0              OTHER                    None                 None   \n",
       "1              OTHER                    None                 None   \n",
       "2               None                    None                 None   \n",
       "3               None                    None                 None   \n",
       "4               None                    None                 None   \n",
       "\n",
       "  secondary_payer_type plan_paid_amt pat_copay copay_assist_amount  \\\n",
       "0                 None          None      None                None   \n",
       "1                 None          None      None                None   \n",
       "2                 None          None      None                None   \n",
       "3                 None          None      None                None   \n",
       "4                 None          None      None                None   \n",
       "\n",
       "  oth_payer_amt xfer_pharmname msa_patient_id msa_patient_bmap  \\\n",
       "0          None           None        2120001            VVVVV   \n",
       "1          None           None        2120001            VVVVV   \n",
       "2          None           None        2120004            VVVVV   \n",
       "3          None           None        2120004            VVVVV   \n",
       "4          None           None        2120004            VVVVV   \n",
       "\n",
       "  __metadata_run_timestamp __metadata_app_version  \\\n",
       "0      2019-06-26 15:28:20                 0.0.11   \n",
       "1      2019-06-26 15:28:20                 0.0.11   \n",
       "2      2019-06-26 15:28:20                 0.0.11   \n",
       "3      2019-06-26 15:28:20                 0.0.11   \n",
       "4      2019-06-26 15:28:20                 0.0.11   \n",
       "\n",
       "                          __metadata_output_contract  \\\n",
       "0  s3://ichain-dev/sun-extract-validation/sun/ilu...   \n",
       "1  s3://ichain-dev/sun-extract-validation/sun/ilu...   \n",
       "2  s3://ichain-dev/sun-extract-validation/sun/ilu...   \n",
       "3  s3://ichain-dev/sun-extract-validation/sun/ilu...   \n",
       "4  s3://ichain-dev/sun-extract-validation/sun/ilu...   \n",
       "\n",
       "  __metadata_transform_timestamp  __metadata_run_id  pj_id  pj_step  \n",
       "0            2019-06-26 15:33:32                  4      0      274  \n",
       "1            2019-06-26 15:33:32                  4      0      275  \n",
       "2            2019-06-26 15:33:32                  4     -1      932  \n",
       "3            2019-06-26 15:33:32                  4     -1      960  \n",
       "4            2019-06-26 15:33:32                  4     -1     1041  "
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pj_df = pj(df)\n",
    "\n",
    "pj_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hierarchy_df = (\n",
    "    pj_df\n",
    "    .pipe(cancel_before_active)\n",
    "    .pipe(prior_status)\n",
    "    .pipe(hierarchy)\n",
    ")\n",
    "\n",
    "hierarchy_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge hierarchy results for this enrichment back into the initial dataframe\n",
    "\n",
    "final_dataframe = (\n",
    "    pd.merge(\n",
    "        pj_df.rename(columns = {transform.hierarchy:'old_hierarchy'}),\n",
    "        hierarchy_df.loc[:,['pj_id', 'pj_step', transform.hierarchy]],\n",
    "        how='left',\n",
    "        on=['pj_id', 'pj_step']\n",
    "    )\n",
    "    .assign(**{\n",
    "        transform.hierarchy : lambda x:(\n",
    "            np.where(\n",
    "                x[transform.hierarchy].isnull(),\n",
    "                x['old_hierarchy'],\n",
    "                x[transform.hierarchy]\n",
    "            )\n",
    "        )}\n",
    "    )\n",
    "    .drop(['pj_id', 'pj_step', 'old_hierarchy'], axis=1)\n",
    ")\n",
    "\n",
    "final_dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataframe.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TEST TRANSFORM OUTPUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST 1: Check that final dataframe has the same number of rows as the input dataframe\n",
    "\n",
    "test1 = (pj_df.shape[0] == final_dataframe.shape[0])\n",
    "\n",
    "test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST 2: Check that hierarchy is not changed for statuses after first active shipment, or for journeys that never reported active shipment\n",
    "\n",
    "first_active_status = (\n",
    "    final_dataframe\n",
    "    .assign(pj_id = lambda x: x.groupby([transform.patient_id, transform.pharmacy, transform.brand_col]).grouper.group_info[0])\n",
    "    .assign(pj_step = lambda x: x.index)\n",
    "    .assign(active_status_date = lambda x: (\n",
    "        pd.to_datetime(np.where(\n",
    "            x[transform.substatus] == transform.active_substatus_code,\n",
    "            x[transform.status_date],\n",
    "            pd.NaT\n",
    "    ))))\n",
    "    .assign(first_active_status_date = lambda x: (\n",
    "        x.groupby(['pj_id'])['active_status_date']\n",
    "        .transform(min)\n",
    "    ))\n",
    "    .drop(['active_status_date'], axis=1)\n",
    "    .merge(\n",
    "        pj_df.loc[:,['pj_step', transform.hierarchy]].rename(columns={transform.hierarchy:'old_hierarchy'}),\n",
    "        how = 'inner',\n",
    "        on = ['pj_step']\n",
    "    )\n",
    ")\n",
    "\n",
    "test2 = (first_active_status   \n",
    "    .loc[lambda x: (\n",
    "        ((x[transform.status_date] > x['first_active_status_date'])\n",
    "         |\n",
    "         (x['first_active_status_date'].isnull())\n",
    "        )\n",
    "        &\n",
    "        (x[transform.hierarchy] != x['old_hierarchy'])\n",
    "        &\n",
    "        ~((x[transform.hierarchy].isnull()) & (x['old_hierarchy'].isnull()))\n",
    "        &\n",
    "        (x[transform.hierarchy] != transform.active_hierarchy)\n",
    "    )]\n",
    ")\n",
    "\n",
    "test2 = (test2.shape[0] == 0)\n",
    "\n",
    "test2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST 3: Check that all cancelled and discontinued statuses prior to first active shipment have a new hierarchy assigned to them\n",
    "\n",
    "test3 = (\n",
    "    first_active_status   \n",
    "    .loc[lambda x: (\n",
    "        (x[transform.status_date] < x['first_active_status_date'])\n",
    "        &\n",
    "        (x[transform.status].isin(transform.cancel_discontinue_status_code))\n",
    "        &\n",
    "        (\n",
    "            ((x['first_active_status_date'] - x[transform.status_date]) / np.timedelta64(1,'D') > transform.active_diff_threshold)\n",
    "            |\n",
    "            ((x[transform.status_date] - x[transform.status_date].shift(1)) / np.timedelta64(1,'D') > transform.prior_diff_threshold)\n",
    "            |\n",
    "            (x[transform.substatus].isin(transform.bvpa_cancel_discontinue_substatus))\n",
    "        )\n",
    "        &\n",
    "        (x[transform.hierarchy] == x['old_hierarchy'])\n",
    "    )]\n",
    ")\n",
    "\n",
    "test3 = (test3.shape[0] == 0)\n",
    "\n",
    "test3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST 4: Check that all non-cancel/discontinue statuses prior to first active shipment have their previous hierarchy assignment (unless they are REMOVE FROM TTFF)\n",
    "\n",
    "test4 = (\n",
    "    first_active_status\n",
    "    .loc[lambda x: (\n",
    "        (x[transform.status_date] < x['first_active_status_date'])\n",
    "        &\n",
    "        (x['pj_id'].isin(\n",
    "            x\n",
    "            .loc[(x[transform.status].isin(transform.cancel_discontinue_status_code)) & (x[transform.status_date] < x['first_active_status_date'])]\n",
    "            .pj_id\n",
    "            .drop_duplicates()\n",
    "            .tolist()\n",
    "        ))\n",
    "        &\n",
    "        (~x[transform.status].isin(transform.cancel_discontinue_status_code))\n",
    "        &\n",
    "        (\n",
    "            (x[transform.hierarchy] != x['old_hierarchy'])\n",
    "            &\n",
    "            ~((x[transform.hierarchy].isnull()) & (x['old_hierarchy'].isnull()))\n",
    "            &\n",
    "            (x[transform.hierarchy] != transform.remove_from_ttff)\n",
    "        )\n",
    "    )]\n",
    ")\n",
    "\n",
    "test4 = (test4.shape[0] == 0)\n",
    "\n",
    "test4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST 5: Create a \"test\" dataframe with expected results\n",
    "\n",
    "test_data = ([\n",
    "    [1, 0, 'PENDING', 'OTHER', 'PENDING - OTHER'],\n",
    "    [1, 70, 'PENDING', 'OTHER', 'PENDING - OTHER'],\n",
    "    [1, 72, transform.cancel_discontinue_status_code[0], transform.bvpa_cancel_discontinue_substatus[0], transform.bvpa_hierarchy],\n",
    "    [1, 72, transform.cancel_discontinue_status_code[1], 'OTHER', transform.bvpa_hierarchy],\n",
    "    [1, 72, 'ACTIVE', transform.active_substatus_code, transform.active_hierarchy],\n",
    "    [2, 0, 'PENDING', 'OTHER', transform.remove_from_ttff],\n",
    "    [2, 70, transform.cancel_discontinue_status_code[1], 'OTHER', transform.no_status_clarity],\n",
    "    [2, 72, 'PENDING', 'OTHER', 'PENDING - OTHER'],\n",
    "    [2, 72, transform.cancel_discontinue_status_code[0], 'OTHER', 'PENDING - OTHER'],\n",
    "    [2, 72, 'ACTIVE', transform.active_substatus_code, transform.active_hierarchy],\n",
    "    [3, 0, transform.cancel_discontinue_status_code[1], transform.bvpa_cancel_discontinue_substatus[0], transform.remove_from_ttff],\n",
    "    [3, 1, 'PENDING', 'OTHER', transform.remove_from_ttff],\n",
    "    [3, 2, transform.cancel_discontinue_status_code[1], 'OTHER', transform.remove_from_ttff],\n",
    "    [3, 70, transform.cancel_discontinue_status_code[1], 'OTHER', transform.no_status_clarity],\n",
    "    [3, 71, 'ACTIVE', transform.active_substatus_code, transform.active_hierarchy],\n",
    "    [3, 72, transform.cancel_discontinue_status_code[0], 'OTHER', transform.active_hierarchy],\n",
    "    [3, 73, transform.cancel_discontinue_status_code[0], transform.bvpa_cancel_discontinue_substatus[0], transform.active_hierarchy]\n",
    "])\n",
    "\n",
    "test_df = (\n",
    "    pd.DataFrame(test_data, columns = [transform.patient_id, transform.status_date, transform.status, transform.substatus, 'expected_hierarchy'])\n",
    "    .assign(**{\n",
    "        transform.pharmacy : 'ABC',\n",
    "        transform.brand_col : 'A',\n",
    "        transform.status_date : lambda x: (\n",
    "            pd.to_datetime('2019-01-01', format='%Y-%m-%d') + pd.to_timedelta(x[transform.status_date], unit='d')\n",
    "        ),\n",
    "        transform.hierarchy : lambda x: (\n",
    "            x[transform.status] + ' - ' + x[transform.substatus]\n",
    "        )\n",
    "    })\n",
    "    \n",
    ")\n",
    "\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply transform to test dataframe\n",
    "\n",
    "pj_test = pj(test_df)\n",
    "\n",
    "test_output = (\n",
    "    pj_test\n",
    "    .pipe(cancel_before_active)\n",
    "    .pipe(prior_status)\n",
    "    .pipe(hierarchy)\n",
    ")\n",
    "\n",
    "final_dataframe_test = (\n",
    "    pd.merge(\n",
    "        pj_test.rename(columns = {transform.hierarchy:'old_hierarchy'}),\n",
    "        test_output.loc[:,['pj_id','pj_step', transform.hierarchy]],\n",
    "        how='left',\n",
    "        on=['pj_id', 'pj_step']\n",
    "    )\n",
    "    .assign(**{\n",
    "        transform.hierarchy : lambda x:(\n",
    "            np.where(\n",
    "                x[transform.hierarchy].isnull(),\n",
    "                x['old_hierarchy'],\n",
    "                x[transform.hierarchy]\n",
    "            )\n",
    "        )}\n",
    "    )\n",
    "    .drop(['pj_id', 'pj_step', 'old_hierarchy'], axis=1)\n",
    ")\n",
    "\n",
    "final_dataframe_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check that results match expectations\n",
    "\n",
    "test5 = (\n",
    "    final_dataframe_test\n",
    "    .assign(passfail = lambda x: np.where(\n",
    "        (x[transform.hierarchy] == x['expected_hierarchy']) | (x[transform.hierarchy].isnull() & x['expected_hierarchy'].isnull()),\n",
    "        True,\n",
    "        False\n",
    "    ))\n",
    "    .passfail\n",
    "    .all()\n",
    ")\n",
    "\n",
    "test5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINAL TEST: Did all 5 tests pass?\n",
    "\n",
    "test1 & test2 & test3 & test4 & test5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Publish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## that's it - just provide the final dataframe to the var final_dataframe and we take it from there\n",
    "transform.publish_contract.publish(final_dataframe, run_id, session, publish_to_redshift=False) # Remove publish_to_redshift=False before pipeline integration!\n",
    "session.close()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
