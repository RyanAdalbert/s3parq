{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-07-09 20:49:42,400 - core.helpers.session_helper.SessionHelper - INFO - Creating session for dev environment...\n",
      "2019-07-09 20:49:42,427 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating administrator mocks.\n",
      "2019-07-09 20:49:42,431 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating administrator mocks.\n",
      "2019-07-09 20:49:42,432 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating pharmaceutical company mocks.\n",
      "2019-07-09 20:49:42,437 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating pharmaceutical company mocks.\n",
      "2019-07-09 20:49:42,440 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating brand mocks.\n",
      "2019-07-09 20:49:42,443 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating brand mocks.\n",
      "2019-07-09 20:49:42,444 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating segment mocks.\n",
      "2019-07-09 20:49:42,448 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating segment mocks.\n",
      "2019-07-09 20:49:42,449 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating pipeline type mocks.\n",
      "2019-07-09 20:49:42,457 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating pipeline type mocks.\n",
      "2019-07-09 20:49:42,459 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating pipeline mocks.\n",
      "2019-07-09 20:49:42,463 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating pipeline mocks.\n",
      "2019-07-09 20:49:42,467 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating pipeline state type mocks.\n",
      "2019-07-09 20:49:42,479 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating pipeline state type mocks.\n",
      "2019-07-09 20:49:42,480 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating pipeline state mocks.\n",
      "2019-07-09 20:49:42,485 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating pipeline state mocks.\n",
      "2019-07-09 20:49:42,486 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating tag mocks.\n",
      "2019-07-09 20:49:42,491 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating tag mocks.\n",
      "2019-07-09 20:49:42,493 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating transformation_template mocks.\n",
      "2019-07-09 20:49:42,497 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating transformation_template mocks.\n",
      "2019-07-09 20:49:42,498 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating bridge table mocks for transformation_templates <=> tags.\n",
      "2019-07-09 20:49:42,502 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating transformation_templates_tags mocks.\n",
      "2019-07-09 20:49:42,503 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating transformation mocks.\n",
      "2019-07-09 20:49:42,507 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating transformation mocks.\n",
      "2019-07-09 20:49:42,508 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating transformation_variables mocks\n",
      "2019-07-09 20:49:42,511 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating transformation_variables mocks.\n",
      "2019-07-09 20:49:42,514 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating run_events mocks.\n",
      "2019-07-09 20:49:42,519 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating run_events mocks.\n",
      "2019-07-09 20:49:42,521 - core.helpers.session_helper.SessionHelper - INFO - Done. Created dev session with mock data.\n"
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "session = SessionHelper().session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
=======
    "transform_id = 3\n",
>>>>>>> 140455bc61a7858faddd838e7c09b0981933e405
    "\"\"\"\n",
    "************ SETUP - DON'T TOUCH **************\n",
    "This section imports data from the configuration database\n",
    "and should not need to be altered, molested or otherwise messed with. \n",
    "~~These are not the droids you are looking for~~\n",
    "\"\"\"\n",
    "from core.constants import BRANCH_NAME, ENV_BUCKET\n",
    "from core.helpers.session_helper import SessionHelper\n",
    "from core.models.configuration import Transformation\n",
    "from dataclasses import dataclass\n",
    "from core.raw_contract import RawContract, download_s3_object\n",
    "from core.dataset_contract import DatasetContract\n",
    "\n",
    "db_transform = session.query(Transformation).filter(Transformation.id == transform_id).one()\n",
    "\n",
    "@dataclass\n",
    "class DbTransform:\n",
    "    id: int = db_transform.id ## the instance id of the transform in the config app\n",
    "    name: str = db_transform.transformation_template.name ## the transform name in the config app\n",
    "    state: str = db_transform.pipeline_state.pipeline_state_type.name ## the pipeline state, one of raw, ingest, master, enhance, enrich, metrics, dimensional\n",
    "    branch:str = BRANCH_NAME ## the git branch for this execution \n",
    "    brand: str = db_transform.pipeline_state.pipeline.brand.name ## the pharma brand name\n",
    "    pharmaceutical_company: str = db_transform.pipeline_state.pipeline.brand.pharmaceutical_company.name # the pharma company name\n",
    "    publish_contract: DatasetContract = DatasetContract(branch=BRANCH_NAME,\n",
    "                            parent=db_transform.pipeline_state.pipeline.brand.pharmaceutical_company.name,\n",
    "                            child=db_transform.pipeline_state.pipeline.brand.name,\n",
    "                            state=db_transform.pipeline_state.pipeline_state_type.name,\n",
    "                            dataset=db_transform.transformation_template.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DbTransform(id=1, name='extract_from_ftp', state='raw', branch='DS-291', brand='Cornballer', pharmaceutical_company='Sitwell', publish_contract=<core.dataset_contract.DatasetContract object at 0x7fbf77709e80>)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DbTransform()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CORE Cartridge Notebook::[transform name here]\n",
    "![CORE Logo](assets/coreLogo.png) \n",
    "\n",
    "---\n",
    "## Keep in Mind\n",
    "Good Transforms Are...\n",
    "- **singular in purpose:** good transforms do one and only one thing, and handle all known cases for that thing. \n",
    "- **repeatable:** transforms should be written in a way that they can be run against the same dataset an infinate number of times and get the same result every time. \n",
    "- **easy to read:** 99 times out of 100, readable, clear code that runs a little slower is more valuable than a mess that runs quickly. \n",
    "- **No 'magic numbers':** if a variable or function is not instantly obvious as to what it is or does, without context, maybe consider renaming it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow - how to use this notebook to make science\n",
    "#### Data Science\n",
    "1. **Document your transform.** Fill out the _description_ cell below describing what it is this transform does; this will appear in the configuration application where Ops will create, configure and update pipelines. \n",
    "1. **Define your config object.** Fill out the _configuration_ cell below the commented-out guide to define the variables you want ops to set in the configuration application (these will populate here for every pipeline). \n",
    "2. **Build your transformation logic.** Use the transformation cell to do that magic that you do. \n",
    "![caution](assets/cautionTape.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "MissingTransformationVariableError",
     "evalue": "Missing transform variable filesystem_path in Transformation 1.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/usr/src/app/core/models/configuration.py\u001b[0m in \u001b[0;36mvariables\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 200\u001b[0;31m                 \u001b[0mtyped\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    201\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'filesystem_path'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMissingTransformationVariableError\u001b[0m        Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-1e688d093599>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m \"\"\"\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mTransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDbTransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m         \u001b[0mfilesystem_path\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdb_transform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilesystem_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m         \u001b[0mdelimiter\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdb_transform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelimiter\u001b[0m \u001b[0;31m# The input file delimiter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-1e688d093599>\u001b[0m in \u001b[0;36mTransform\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mTransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDbTransform\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0mfilesystem_path\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdb_transform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilesystem_path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mdelimiter\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdb_transform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdelimiter\u001b[0m \u001b[0;31m# The input file delimiter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mskip_rows\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdb_transform\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mskip_rows\u001b[0m \u001b[0;31m# the number of rows to skip before reading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/src/app/core/models/configuration.py\u001b[0m in \u001b[0;36mvariables\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    201\u001b[0m             \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m                 \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34mf\"Missing transform variable {key} in Transformation {self.id}.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mMissingTransformationVariableError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdot_notated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMissingTransformationVariableError\u001b[0m: Missing transform variable filesystem_path in Transformation 1."
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "********* CONFIGURATION - PLEASE TOUCH ********* \n",
    "This section defines what you expect to get from the configuration application \n",
    "in a single \"transform\" object. Define the vars you need here, and comment inline to the right of them \n",
    "for all-in-one documentation. \n",
    "Engineering will build a production \"transform\" object for every pipeline that matches what you define here.\n",
    "\n",
    "@@@ FORMAT OF THE DATA CLASS IS: @@@ \n",
    "\n",
    "<value_name>: <data_type> #<comment explaining what the value is to future us>\n",
    "\n",
    "~~These ARE the droids you are looking for~~\n",
    "\"\"\"\n",
    "\n",
    "class Transform(DbTransform):\n",
    "        filesystem_path: str = db_transform.variables.filesystem_path\n",
    "        delimiter: str = db_transform.variables.delimiter # The input file delimiter\n",
    "        skip_rows: int = db_transform.variables.skip_rows # the number of rows to skip before reading\n",
    "        encoding: str = db_transform.variables.encoding # The file encoding\n",
    "        input_file_prefix: str = db_transform.variables.input_file_prefix # The prefix of input files to read in"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Please place your value assignments for development here!!\n",
    "## This cell will be turned off in production and Engineering will set to pull form the configuration application instead\n",
    "transform = Transform()\n",
    "transform.delimiter = \", \"\n",
    "transform.skip_rows = 0\n",
    "transform.encoding = \"utf8\"\n",
    "transform.input_file_prefix = \"BRIOVA_\"\n",
    "transform.dataset_name = \"init_ingest_patient_status\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description\n",
    "What does this transformation do? be specific.\n",
    "\n",
    "![what does your transform do](assets/what.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This transformation takes a collection of raw files based on location and their prefix, then creates a dataset from the data and outputs it to S3. The delimiter and encodings can be set, as well as a number of rows at the top to be skipped."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Setup important imports\n",
    "import pandas as pd\n",
    "from pandas.errors import EmptyDataError\n",
    "import os\n",
    "import tempfile\n",
    "from os import path\n",
    "from encodings.aliases import aliases\n",
    "from core.logging import get_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Setup for transformation object\n",
    "transform = Transform()\n",
    "logger = get_logger(f\"core.transforms.{transform.state}.{transform.name}\")\n",
    "final_dataframe = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform.publish_contract.dataset = transform.name + \"/\" + transform.input_file_prefix\n",
    "\n",
    "input_contract = RawContract(branch=BRANCH_NAME,\n",
    "                            parent=transform.pharmaceutical_company,\n",
    "                            child=transform.brand)\n",
    "\n",
    "logger.debug(f\"Ingesting files from path : {input_contract.s3_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ingest_file(f, filename, input_contract):\n",
    "    input_s3_url = input_contract.s3_path_with_filename(filename)\n",
    "    logger.debug(f\"Ingesting file: {filename}\")\n",
    "    df = pd.read_csv(f, dtype=\"str\", encoding=transform.encoding, compression=\"infer\", sep=transform.delimiter, skiprows=transform.skip_rows)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Use the variables above to execute your transformation. the final output needs to be a variable named final_dataframe\n",
    "valid_encodings = set(aliases.keys()) | set(aliases.values())\n",
    "if transform.encoding not in valid_encodings:\n",
    "    invalid_encoding_message = f\"initial_ingest_configuration {transform.id} has invalid encoding: {transform.encoding}\"\n",
    "    logger.critical(invalid_encoding_message)\n",
    "    raise ValueError(invalid_encoding_message)\n",
    "if len(transform.delimiter) < 1:\n",
    "    invalid_delimiter_message = f\"initial_ingest_configuration {transform.id} has no delimiter\"\n",
    "    logger.critical(invalid_delimiter_message)\n",
    "    raise ValueError(invalid_delimiter_message)\n",
    "\n",
    "in_files = input_contract.list_files(transform.input_file_prefix)\n",
    "\n",
    "for f in in_files:\n",
    "    filename = path.basename(f)\n",
    "    with input_contract.download_raw_file(filename) as fn:\n",
    "        try:\n",
    "            df = ingest_file(fn, filename, input_contract)\n",
    "            final_dataframe = final_dataframe.append(df)\n",
    "        except EmptyDataError as e:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## That's it - just provide the final dataframe to the var final_dataframe and we take it from there\n",
    "transform.publish_contract.publish(final_dataframe, run_id, session)\n",
    "session.close()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
