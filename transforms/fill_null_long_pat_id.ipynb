<<<<<<< HEAD
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.helpers.session_helper import SessionHelper\n",
    "session = SessionHelper().session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "************ CONFIGURATION - PLEASE TOUCH **************\n",
    "Pipeline Builder configuration: creates configurations from variables specified here!!\n",
    "This cell will be off in production as configurations will come from the configuration postgres DB.\n",
    "\"\"\"\n",
    "# config vars: this dataset\n",
    "config_pharma = \"sun\" # the pharmaceutical company which owns {brand}\n",
    "config_brand = \"ilumya\" # the brand this pipeline operates on\n",
    "config_state = \"enrich\" # the state this transform runs in\n",
    "config_name = \"fill_null_ref_date\" # the name of this transform, which is the name of this notebook without .ipynb\n",
    "\n",
    "# input vars: dataset to fetch. Recall that a contract published to S3 has a key format branch/pharma/brand/state/name\n",
    "input_pharma = \"sun\"\n",
    "input_brand = \"ilumya\"\n",
    "input_state = \"ingest\"\n",
    "input_name = \"symphony_health_association_ingest_column_mapping\"\n",
    "input_branch = 'sun-extract-validation' # if None, input_branch is automagically set to your working branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "************ SETUP - DON'T TOUCH **************\n",
    "Populating config mocker based on config parameters...\n",
    "\"\"\"\n",
    "import core.helpers.pipeline_builder as builder\n",
    "\n",
    "ids = builder.build(config_pharma, config_brand, config_state, config_name, session)\n",
    "transform_id = ids[0]\n",
    "run_id = ids[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "************ SETUP - DON'T TOUCH **************\n",
    "This section imports data from the configuration database\n",
    "and should not need to be altered or otherwise messed with. \n",
    "~~These are not the droids you are looking for~~\n",
    "\"\"\"\n",
    "from core.constants import BRANCH_NAME, ENV_BUCKET\n",
    "from core.helpers.session_helper import SessionHelper\n",
    "from core.models.configuration import Transformation\n",
    "from dataclasses import dataclass\n",
    "from core.dataset_contract import DatasetContract\n",
    "\n",
    "db_transform = session.query(Transformation).filter(Transformation.id == transform_id).one()\n",
    "\n",
    "@dataclass\n",
    "class DbTransform:\n",
    "    id: int = db_transform.id ## the instance id of the transform in the config app\n",
    "    name: str = db_transform.transformation_template.name ## the transform name in the config app\n",
    "    state: str = db_transform.pipeline_state.pipeline_state_type.name ## the pipeline state, one of raw, ingest, master, enhance, enrich, metrics, dimensional\n",
    "    branch:str = BRANCH_NAME ## the git branch for this execution \n",
    "    brand: str = db_transform.pipeline_state.pipeline.brand.name ## the pharma brand name\n",
    "    pharmaceutical_company: str = db_transform.pipeline_state.pipeline.brand.pharmaceutical_company.name # the pharma company name\n",
    "    publish_contract: DatasetContract = DatasetContract(branch=BRANCH_NAME,\n",
    "                            state=db_transform.pipeline_state.pipeline_state_type.name,\n",
    "                            parent=db_transform.pipeline_state.pipeline.brand.pharmaceutical_company.name,\n",
    "                            child=db_transform.pipeline_state.pipeline.brand.name,\n",
    "                            dataset=db_transform.transformation_template.name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CORE Cartridge Notebook::[transform name here]\n",
    "![CORE Logo](assets/coreLogo.png) \n",
    "\n",
    "---\n",
    "## Keep in Mind\n",
    "Good Transforms Are...\n",
    "- **singular in purpose:** good transforms do one and only one thing, and handle all known cases for that thing. \n",
    "- **repeatable:** transforms should be written in a way that they can be run against the same dataset an infinate number of times and get the same result every time. \n",
    "- **easy to read:** 99 times out of 100, readable, clear code that runs a little slower is more valuable than a mess that runs quickly. \n",
    "- **No 'magic numbers':** if a variable or function is not instantly obvious as to what it is or does, without context, maybe consider renaming it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow - how to use this notebook to make science\n",
    "#### Data Science\n",
    "1. **Document your transform.** Fill out the _description_ cell below describing what it is this transform does; this will appear in the configuration application where Ops will create, configure and update pipelines. \n",
    "1. **Define your config object.** Fill out the _configuration_ cell below the commented-out guide to define the variables you want ops to set in the configuration application (these will populate here for every pipeline). \n",
    "2. **Build your transformation logic.** Use the transformation cell to do that magic that you do. \n",
    "![caution](assets/cautionTape.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "********* VARIABLES - PLEASE TOUCH ********* \n",
    "This section defines what you expect to get from the configuration application \n",
    "in a single \"transform\" object. Define the vars you need here, and comment inline to the right of them \n",
    "for all-in-one documentation. \n",
    "Engineering will build a production \"transform\" object for every pipeline that matches what you define here.\n",
    "\n",
    "@@@ FORMAT OF THE DATA CLASS IS: @@@ \n",
    "\n",
    "<variable_name>: <data_type> #<comment explaining what the value is to future us>\n",
    "\n",
    "e.g.\n",
    "\n",
    "class Transform(DbTransform):\n",
    "    some_ratio: float\n",
    "    site_name: str\n",
    "\n",
    "~~These ARE the droids you are looking for~~\n",
    "\"\"\"\n",
    "\n",
    "class Transform(DbTransform):\n",
    "    '''\n",
    "    YOUR properties go here!!\n",
    "    Variable properties should be assigned to the exact name of\n",
    "    the transformation as it appears in the Jupyter notebook filename.\n",
    "    '''\n",
    "    \n",
    "    col_1: str #This column is for the brand/medication. Used for identification purposes\n",
    "    col_2: str #This column is the for the pharmacy code  Used for identification purposes\n",
    "    col_3: str #This column is for the SP-ID.  Used for identification purposes and to fill in null values where there is no Long-ID\n",
    "    col_null: str #This column is for the Long-ID I.E. the column where null values are to be filled in\n",
    "    \n",
    "    def fill_null_long_pat_id(self,df):\n",
    "        \n",
    "        # Creates a dictionary of all variables used as identifiers where Long-ID is null\n",
    "        unique_id_dict = (\n",
    "            df[df[self.col_null].isna()]\n",
    "            [[self.col_1,self.col_2,self.col_3]]\n",
    "            .dropna()\n",
    "            .drop_duplicates()\n",
    "            .reset_index(drop=True)\n",
    "            .to_dict(orient='index')\n",
    "        )\n",
    "        \n",
    "        for key in unique_id_dict.keys():\n",
    "            \n",
    "            mask = (\n",
    "                (df[self.col_1] == unique_id_dict[key][self.col_1])\n",
    "                & (df[self.col_2] == unique_id_dict[key][self.col_2])\n",
    "                & (df[self.col_3] == unique_id_dict[key][self.col_3])\n",
    "            )\n",
    "            \n",
    "            if (df.loc[mask,self.col_null].unique().shape[0] == 1) & (df.loc[mask,self.col_null].unique()[0] == None):\n",
    "                df.loc[mask,self.col_null] = (\n",
    "                    unique_id_dict[key][self.col_3]\n",
    "                )\n",
    "\n",
    "            else:\n",
    "                df.loc[mask,self.col_null] = (\n",
    "                    df\n",
    "                    .loc[mask,self.col_null]\n",
    "                    .bfill()\n",
    "                    .ffill()\n",
    "                )\n",
    "\n",
    "        return df\n",
    "    \n",
    "transform = Transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Please place your value assignments for development here!!\n",
    "## This cell will be turned off in production and Engineering will set to pull from the configuration application instead\n",
    "## For the last example, this could look like...\n",
    "## transform.some_ratio = 0.6\n",
    "## transform.site_name = \"WALGREENS\"\n",
    "\n",
    "transform.col_1 = 'medication'\n",
    "transform.col_2 = 'pharm_code'\n",
    "transform.col_3 = 'pharmacy_id'\n",
    "transform.col_null = 'msa_patient_id'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. If L-ID is null through history use SP-ID. If L-ID is null in past backfill with current L-ID\n",
    "\n",
    "2. If null and two L-ID use the most recent next status"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description\n",
    "What does this transformation do? be specific.\n",
    "\n",
    "![what does your transform do](assets/what.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Null L-Patient ID](assets/NullLPatientID.png)\n",
    "\n",
    "\n",
    "Replaces Null values in Longitudinal Patient ID with either the SP-ID or with the most closest following Longitudinal Patient ID, except when Null Longitudinal Patient ID is the last Longitudinal Patient ID, in which case it uses the closest previous Longitudinal Patient ID."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "************ FETCH DATA - TOUCH, BUT CAREFULLY **************\n",
    "This cell will be turned off in production, as the input_contract will be handled by the pipeline.\n",
    "\"\"\"\n",
    "\n",
    "run_id = 4\n",
    "\n",
    "if not input_branch:\n",
    "    input_branch = BRANCH_NAME\n",
    "input_contract = DatasetContract(branch=input_branch,\n",
    "                                 state=input_state,\n",
    "                                 parent=input_pharma,\n",
    "                                 child=input_brand,\n",
    "                                 dataset=input_name)\n",
    "run_filter = []\n",
    "run_filter.append(dict(partition=\"__metadata_run_id\", comparison=\"==\", values=[run_id]))\n",
    "# IF YOU HAVE PUBLISHED DATA MULTIPLE TIMES, uncomment the above line and change the int to the run_id to fetch.\n",
    "# Otherwise, you will have duplicate values in your fetched dataset!\n",
    "df = input_contract.fetch(filters=run_filter)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "datetime = '%Y%m%d'\n",
    "df.status_date = df.status_date.str[:8].astype(str)\n",
    "df.ref_date = df.ref_date.str[:8].astype(str)\n",
    "\n",
    "df.status_date = pd.to_datetime(df.status_date, format=datetime, errors='coerce')\n",
    "df.ref_date = pd.to_datetime(df.ref_date, format=datetime, errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Use the variables above to execute your transformation. the final output needs to be a variable named final_dataframe\n",
    "final_dataframe = transform.fill_null_long_pat_id(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import unittest\n",
    "\n",
    "def shape_status(final_dataframe,df):\n",
    "    \"\"\"\n",
    "    Make sure df shape doesn't change,\n",
    "    This is a test:\n",
    "    >>> shape_status(final_dataframe,df)\n",
    "    True\n",
    "    \"\"\"\n",
    "    return final_dataframe.shape == df.shape\n",
    "    \n",
    "def nulls_removed(final_dataframe):\n",
    "    \"\"\"\n",
    "    Make sure df does not contain Null Values\n",
    "    This is a test:\n",
    "    >>> shape_status(final_dataframe,df)\n",
    "    True\n",
    "    \"\"\"\n",
    "    return final_dataframe[final_dataframe.msa_patient_id.isna()].shape[0] == 0\n",
    "\n",
    "class TestNotebook(unittest.TestCase):\n",
    "\n",
    "    def test_shape_status(self):\n",
    "        self.assertEqual(shape_status(final_dataframe,df),True)\n",
    "    \n",
    "    def test_nulls_removed(self):\n",
    "        self.assertEqual(nulls_removed(final_dataframe),True)\n",
    "    \n",
    "unittest.main(argv=[''], verbosity=2, exit=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Publish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## that's it - just provide the final dataframe to the var final_dataframe and we take it from there\n",
    "transform.publish_contract.publish(final_dataframe, run_id, session)\n",
    "session.close()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
||||||| merged common ancestors
=======
{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-07-15 16:40:33,750 - core.helpers.session_helper.SessionHelper - INFO - Creating session for dev environment...\n",
      "2019-07-15 16:40:33,771 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating administrator mocks.\n",
      "2019-07-15 16:40:33,804 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating administrator mocks.\n",
      "2019-07-15 16:40:33,805 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating pharmaceutical company mocks.\n",
      "2019-07-15 16:40:33,809 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating pharmaceutical company mocks.\n",
      "2019-07-15 16:40:33,809 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating brand mocks.\n",
      "2019-07-15 16:40:33,813 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating brand mocks.\n",
      "2019-07-15 16:40:33,815 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating segment mocks.\n",
      "2019-07-15 16:40:33,819 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating segment mocks.\n",
      "2019-07-15 16:40:33,821 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating pipeline type mocks.\n",
      "2019-07-15 16:40:33,825 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating pipeline type mocks.\n",
      "2019-07-15 16:40:33,826 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating pipeline mocks.\n",
      "2019-07-15 16:40:33,832 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating pipeline mocks.\n",
      "2019-07-15 16:40:33,834 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating pipeline state type mocks.\n",
      "2019-07-15 16:40:33,841 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating pipeline state type mocks.\n",
      "2019-07-15 16:40:33,843 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating pipeline state mocks.\n",
      "2019-07-15 16:40:33,846 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating pipeline state mocks.\n",
      "2019-07-15 16:40:33,847 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating tag mocks.\n",
      "2019-07-15 16:40:33,851 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating tag mocks.\n",
      "2019-07-15 16:40:33,852 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating transformation_template mocks.\n",
      "2019-07-15 16:40:33,856 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating transformation_template mocks.\n",
      "2019-07-15 16:40:33,857 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating bridge table mocks for transformation_templates <=> tags.\n",
      "2019-07-15 16:40:33,863 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating transformation_templates_tags mocks.\n",
      "2019-07-15 16:40:33,864 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating transformation mocks.\n",
      "2019-07-15 16:40:33,872 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating transformation mocks.\n",
      "2019-07-15 16:40:33,874 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating transformation_variables mocks\n",
      "2019-07-15 16:40:33,877 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating transformation_variables mocks.\n",
      "2019-07-15 16:40:33,878 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating run_events mocks.\n",
      "2019-07-15 16:40:33,882 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating run_events mocks.\n",
      "2019-07-15 16:40:33,883 - core.helpers.session_helper.SessionHelper - INFO - Done. Created dev session with mock data.\n"
     ]
    }
   ],
   "source": [
    "from core.helpers.session_helper import SessionHelper\n",
    "session = SessionHelper().session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "************ CONFIGURATION - PLEASE TOUCH **************\n",
    "Pipeline Builder configuration: creates configurations from variables specified here!!\n",
    "This cell will be off in production as configurations will come from the configuration postgres DB.\n",
    "\"\"\"\n",
    "# config vars: this dataset\n",
    "config_pharma = \"sun\" # the pharmaceutical company which owns {brand}\n",
    "config_brand = \"ilumya\" # the brand this pipeline operates on\n",
    "config_state = \"raw\" # the state this transform runs in\n",
    "config_name = \"fill_null_long_pat_id\" # the name of this transform, which is the name of this notebook without .ipynb\n",
    "\n",
    "# input vars: dataset to fetch. Recall that a contract published to S3 has a key format branch/pharma/brand/state/name\n",
    "input_pharma = \"sun\"\n",
    "input_brand = \"ilumya\"\n",
    "input_state = \"raw\"\n",
    "input_name = \"upstream\"\n",
    "input_branch = None # if None, input_branch is automagically set to your working branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-07-15 16:40:37,548 - core.logging - DEBUG - Adding/getting mocks for specified configurations...\n",
      "2019-07-15 16:40:37,572 - core.logging - DEBUG - Done. Creating mock run event and committing results to configuration mocker.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "************ SETUP - DON'T TOUCH **************\n",
    "Populating config mocker based on config parameters...\n",
    "\"\"\"\n",
    "import core.helpers.pipeline_builder as builder\n",
    "\n",
    "ids = builder.build(config_pharma, config_brand, config_state, config_name, session)\n",
    "transform_id = ids[0]\n",
    "run_id = ids[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "************ SETUP - DON'T TOUCH **************\n",
    "This section imports data from the configuration database\n",
    "and should not need to be altered or otherwise messed with. \n",
    "~~These are not the droids you are looking for~~\n",
    "\"\"\"\n",
    "from core.constants import BRANCH_NAME, ENV_BUCKET\n",
    "from core.helpers.session_helper import SessionHelper\n",
    "from core.models.configuration import Transformation\n",
    "from dataclasses import dataclass\n",
    "from core.dataset_contract import DatasetContract\n",
    "\n",
    "db_transform = session.query(Transformation).filter(Transformation.id == transform_id).one()\n",
    "\n",
    "@dataclass\n",
    "class DbTransform:\n",
    "    id: int = db_transform.id ## the instance id of the transform in the config app\n",
    "    name: str = db_transform.transformation_template.name ## the transform name in the config app\n",
    "    state: str = db_transform.pipeline_state.pipeline_state_type.name ## the pipeline state, one of raw, ingest, master, enhance, enrich, metrics, dimensional\n",
    "    branch:str = BRANCH_NAME ## the git branch for this execution \n",
    "    brand: str = db_transform.pipeline_state.pipeline.brand.name ## the pharma brand name\n",
    "    pharmaceutical_company: str = db_transform.pipeline_state.pipeline.brand.pharmaceutical_company.name # the pharma company name\n",
    "    publish_contract: DatasetContract = DatasetContract(branch=BRANCH_NAME,\n",
    "                            state=db_transform.pipeline_state.pipeline_state_type.name,\n",
    "                            parent=db_transform.pipeline_state.pipeline.brand.pharmaceutical_company.name,\n",
    "                            child=db_transform.pipeline_state.pipeline.brand.name,\n",
    "                            dataset=db_transform.transformation_template.name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CORE Cartridge Notebook::[transform name here]\n",
    "![CORE Logo](assets/coreLogo.png) \n",
    "\n",
    "---\n",
    "## Keep in Mind\n",
    "Good Transforms Are...\n",
    "- **singular in purpose:** good transforms do one and only one thing, and handle all known cases for that thing. \n",
    "- **repeatable:** transforms should be written in a way that they can be run against the same dataset an infinate number of times and get the same result every time. \n",
    "- **easy to read:** 99 times out of 100, readable, clear code that runs a little slower is more valuable than a mess that runs quickly. \n",
    "- **No 'magic numbers':** if a variable or function is not instantly obvious as to what it is or does, without context, maybe consider renaming it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow - how to use this notebook to make science\n",
    "#### Data Science\n",
    "1. **Document your transform.** Fill out the _description_ cell below describing what it is this transform does; this will appear in the configuration application where Ops will create, configure and update pipelines. \n",
    "1. **Define your config object.** Fill out the _configuration_ cell below the commented-out guide to define the variables you want ops to set in the configuration application (these will populate here for every pipeline). \n",
    "2. **Build your transformation logic.** Use the transformation cell to do that magic that you do. \n",
    "![caution](assets/cautionTape.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. If L-ID is null through history use SP-ID. If L-ID is null in past backfill with current L-ID\n",
    "\n",
    "2. If null and two L-ID use the most recent next status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "run_id = 5\n",
    "\n",
    "from s3parq import fetch\n",
    "\n",
    "ingest_contract = DatasetContract(branch='sun-extract-prod-vars',\n",
    "                            parent='sun',\n",
    "                            child='ilumya',\n",
    "                            state='ingest',\n",
    "                            dataset='symphony_health_association_ingest_column_mapping')\n",
    "\n",
    "run_filter = [{\"partition\": \"__metadata_run_id\", \"comparison\": \"==\", \"values\": [run_id]}]\n",
    "\n",
    "df = fetch(bucket=ingest_contract.bucket, key=ingest_contract.key, filters=run_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.options.display.max_columns = 999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['rec_date', 'pharm_code', 'pharm_npi', 'transtype',\n",
       "       'pharm_transaction_id', 'trans_seq', 'ref_source', 'ref_date',\n",
       "       'program_id', 'pharmacy_id', 'pat_last_name', 'pat_first_name',\n",
       "       'pat_dob', 'pat_gender', 'pat_addr1', 'pat_addr2', 'pat_city',\n",
       "       'pat_state', 'pat_zip', 'dx1_code', 'dx2_code', 'status_date',\n",
       "       'status_code', 'sub_status', 'pres_last_name', 'pres_first_name',\n",
       "       'pres_addr1', 'pres_addr2', 'pres_city', 'pres_state', 'pres_zip',\n",
       "       'pres_phone', 'pres_npi', 'pres_dea', 'facility_name', 'rxdate',\n",
       "       'rxnumber', 'rxrefills', 'rxfill', 'refill_remaining', 'prev_disp',\n",
       "       'rx_ndc_number', 'medication', 'quantity', 'day_supply',\n",
       "       'ship_date', 'ship_carrier', 'shiptracking_num', 'ship_location',\n",
       "       'ship_address', 'ship_city', 'ship_state', 'ship_zip',\n",
       "       'has_medical', 'primary_coverage_type', 'primary_payer_name',\n",
       "       'primary_payer_type', 'secondary_coverage_type',\n",
       "       'secondary_payer_name', 'secondary_payer_type', 'plan_paid_amt',\n",
       "       'pat_copay', 'copay_assist_amount', 'oth_payer_amt',\n",
       "       'xfer_pharmname', 'msa_patient_id', 'msa_patient_bmap',\n",
       "       '__metadata_run_timestamp', '__metadata_app_version',\n",
       "       '__metadata_transform_timestamp', '__metadata_output_contract',\n",
       "       '__metadata_run_id'], dtype=object)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "null_df = df[df.msa_patient_id.isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rec_date</th>\n",
       "      <th>pharm_code</th>\n",
       "      <th>pharm_npi</th>\n",
       "      <th>transtype</th>\n",
       "      <th>pharm_transaction_id</th>\n",
       "      <th>trans_seq</th>\n",
       "      <th>ref_source</th>\n",
       "      <th>ref_date</th>\n",
       "      <th>program_id</th>\n",
       "      <th>pharmacy_id</th>\n",
       "      <th>pat_last_name</th>\n",
       "      <th>pat_first_name</th>\n",
       "      <th>pat_dob</th>\n",
       "      <th>pat_gender</th>\n",
       "      <th>pat_addr1</th>\n",
       "      <th>pat_addr2</th>\n",
       "      <th>pat_city</th>\n",
       "      <th>pat_state</th>\n",
       "      <th>pat_zip</th>\n",
       "      <th>dx1_code</th>\n",
       "      <th>dx2_code</th>\n",
       "      <th>status_date</th>\n",
       "      <th>status_code</th>\n",
       "      <th>sub_status</th>\n",
       "      <th>pres_last_name</th>\n",
       "      <th>pres_first_name</th>\n",
       "      <th>pres_addr1</th>\n",
       "      <th>pres_addr2</th>\n",
       "      <th>pres_city</th>\n",
       "      <th>pres_state</th>\n",
       "      <th>pres_zip</th>\n",
       "      <th>pres_phone</th>\n",
       "      <th>pres_npi</th>\n",
       "      <th>pres_dea</th>\n",
       "      <th>facility_name</th>\n",
       "      <th>rxdate</th>\n",
       "      <th>rxnumber</th>\n",
       "      <th>rxrefills</th>\n",
       "      <th>rxfill</th>\n",
       "      <th>refill_remaining</th>\n",
       "      <th>prev_disp</th>\n",
       "      <th>rx_ndc_number</th>\n",
       "      <th>medication</th>\n",
       "      <th>quantity</th>\n",
       "      <th>day_supply</th>\n",
       "      <th>ship_date</th>\n",
       "      <th>ship_carrier</th>\n",
       "      <th>shiptracking_num</th>\n",
       "      <th>ship_location</th>\n",
       "      <th>ship_address</th>\n",
       "      <th>ship_city</th>\n",
       "      <th>ship_state</th>\n",
       "      <th>ship_zip</th>\n",
       "      <th>has_medical</th>\n",
       "      <th>primary_coverage_type</th>\n",
       "      <th>primary_payer_name</th>\n",
       "      <th>primary_payer_type</th>\n",
       "      <th>secondary_coverage_type</th>\n",
       "      <th>secondary_payer_name</th>\n",
       "      <th>secondary_payer_type</th>\n",
       "      <th>plan_paid_amt</th>\n",
       "      <th>pat_copay</th>\n",
       "      <th>copay_assist_amount</th>\n",
       "      <th>oth_payer_amt</th>\n",
       "      <th>xfer_pharmname</th>\n",
       "      <th>msa_patient_id</th>\n",
       "      <th>msa_patient_bmap</th>\n",
       "      <th>__metadata_run_timestamp</th>\n",
       "      <th>__metadata_app_version</th>\n",
       "      <th>__metadata_transform_timestamp</th>\n",
       "      <th>__metadata_output_contract</th>\n",
       "      <th>__metadata_run_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20181024115959</td>\n",
       "      <td>ACCREDO</td>\n",
       "      <td>1346208949</td>\n",
       "      <td>COM</td>\n",
       "      <td>279133432018102401</td>\n",
       "      <td>0</td>\n",
       "      <td>DIRECT</td>\n",
       "      <td>20181019120000</td>\n",
       "      <td>None</td>\n",
       "      <td>27913343</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>00</td>\n",
       "      <td>L40.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20181024115959</td>\n",
       "      <td>CANCELLED</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>99999</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ILUMYA</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Y</td>\n",
       "      <td>MEDICAL</td>\n",
       "      <td>GENERAL DIRECT</td>\n",
       "      <td>COMMERCIAL</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NNNNV</td>\n",
       "      <td>2019-07-09 14:06:06</td>\n",
       "      <td>0.0.11</td>\n",
       "      <td>2019-07-09 14:09:34</td>\n",
       "      <td>s3://ichain-dev/sun-extract-prod-vars/sun/ilum...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20181025115959</td>\n",
       "      <td>ACCREDO</td>\n",
       "      <td>1346208949</td>\n",
       "      <td>COM</td>\n",
       "      <td>278370982018102502</td>\n",
       "      <td>0</td>\n",
       "      <td>DIRECT</td>\n",
       "      <td>20181022120000</td>\n",
       "      <td>None</td>\n",
       "      <td>27837098</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>00</td>\n",
       "      <td>L40.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20181025115959</td>\n",
       "      <td>CANCELLED</td>\n",
       "      <td>INSURANCE OON</td>\n",
       "      <td>GREENBERG</td>\n",
       "      <td>ROBERT</td>\n",
       "      <td>5201 NORRIS CANYON RD</td>\n",
       "      <td>None</td>\n",
       "      <td>SAN RAMON</td>\n",
       "      <td>CA</td>\n",
       "      <td>94583</td>\n",
       "      <td>9252771300</td>\n",
       "      <td>1639195316</td>\n",
       "      <td>BG0616043</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ILUMYA</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Y</td>\n",
       "      <td>MEDICAL</td>\n",
       "      <td>BROWN &amp; TOLAND MEDICAL GRP</td>\n",
       "      <td>COMMERCIAL</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NNNVV</td>\n",
       "      <td>2019-07-09 14:06:06</td>\n",
       "      <td>0.0.11</td>\n",
       "      <td>2019-07-09 14:09:34</td>\n",
       "      <td>s3://ichain-dev/sun-extract-prod-vars/sun/ilum...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20181029115959</td>\n",
       "      <td>ACCREDO</td>\n",
       "      <td>1346208949</td>\n",
       "      <td>COM</td>\n",
       "      <td>279181482018102903</td>\n",
       "      <td>0</td>\n",
       "      <td>DIRECT</td>\n",
       "      <td>20181024120000</td>\n",
       "      <td>None</td>\n",
       "      <td>27918148</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>00</td>\n",
       "      <td>L40.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20181029115959</td>\n",
       "      <td>CANCELLED</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>SCIURBA</td>\n",
       "      <td>SALVATORE</td>\n",
       "      <td>111 WEST WATER ST</td>\n",
       "      <td>None</td>\n",
       "      <td>TOMS RIVER</td>\n",
       "      <td>NJ</td>\n",
       "      <td>08753</td>\n",
       "      <td>7322444700</td>\n",
       "      <td>1093765307</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ILUMYA</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Y</td>\n",
       "      <td>MEDICAL</td>\n",
       "      <td>GENERAL HORIZON BCBS NJ</td>\n",
       "      <td>COMMERCIAL</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NNNVV</td>\n",
       "      <td>2019-07-09 14:06:06</td>\n",
       "      <td>0.0.11</td>\n",
       "      <td>2019-07-09 14:09:34</td>\n",
       "      <td>s3://ichain-dev/sun-extract-prod-vars/sun/ilum...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20181102115959</td>\n",
       "      <td>ACCREDO</td>\n",
       "      <td>1346208949</td>\n",
       "      <td>COM</td>\n",
       "      <td>267244982018110204</td>\n",
       "      <td>0</td>\n",
       "      <td>DIRECT</td>\n",
       "      <td>20181030120000</td>\n",
       "      <td>None</td>\n",
       "      <td>26724498</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>00</td>\n",
       "      <td>Q84</td>\n",
       "      <td>L40.0</td>\n",
       "      <td>20181102115959</td>\n",
       "      <td>CANCELLED</td>\n",
       "      <td>INSURANCE OON</td>\n",
       "      <td>KNUCKLES</td>\n",
       "      <td>MELISSA</td>\n",
       "      <td>1101 EAST MASTER STREET</td>\n",
       "      <td>None</td>\n",
       "      <td>CORBIN</td>\n",
       "      <td>KY</td>\n",
       "      <td>40701</td>\n",
       "      <td>6065282881</td>\n",
       "      <td>1821074360</td>\n",
       "      <td>BK0531562</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ILUMYA</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Y</td>\n",
       "      <td>MEDICAL</td>\n",
       "      <td>ANTHEM BCBS OF KENTUCKY</td>\n",
       "      <td>MEDICARE</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NNNVV</td>\n",
       "      <td>2019-07-09 14:06:06</td>\n",
       "      <td>0.0.11</td>\n",
       "      <td>2019-07-09 14:09:34</td>\n",
       "      <td>s3://ichain-dev/sun-extract-prod-vars/sun/ilum...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20181106115959</td>\n",
       "      <td>ACCREDO</td>\n",
       "      <td>1346208949</td>\n",
       "      <td>COM</td>\n",
       "      <td>160618142018110605</td>\n",
       "      <td>0</td>\n",
       "      <td>DIRECT</td>\n",
       "      <td>20181102120000</td>\n",
       "      <td>None</td>\n",
       "      <td>16061814</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>00</td>\n",
       "      <td>696.1</td>\n",
       "      <td>None</td>\n",
       "      <td>20181106115959</td>\n",
       "      <td>CANCELLED</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>KORY</td>\n",
       "      <td>MARK</td>\n",
       "      <td>16216 BAXTER ROAD</td>\n",
       "      <td>SUITE 200</td>\n",
       "      <td>CHESTERFIELD</td>\n",
       "      <td>MO</td>\n",
       "      <td>63017</td>\n",
       "      <td>6365321000</td>\n",
       "      <td>1326034489</td>\n",
       "      <td>BK1220045</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>ILUMYA</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Y</td>\n",
       "      <td>MEDICAL</td>\n",
       "      <td>EXPRESS SCRIPTS</td>\n",
       "      <td>COMMERCIAL</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NNNVV</td>\n",
       "      <td>2019-07-09 14:06:06</td>\n",
       "      <td>0.0.11</td>\n",
       "      <td>2019-07-09 14:09:34</td>\n",
       "      <td>s3://ichain-dev/sun-extract-prod-vars/sun/ilum...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         rec_date pharm_code   pharm_npi transtype pharm_transaction_id  \\\n",
       "0  20181024115959    ACCREDO  1346208949       COM   279133432018102401   \n",
       "1  20181025115959    ACCREDO  1346208949       COM   278370982018102502   \n",
       "2  20181029115959    ACCREDO  1346208949       COM   279181482018102903   \n",
       "3  20181102115959    ACCREDO  1346208949       COM   267244982018110204   \n",
       "4  20181106115959    ACCREDO  1346208949       COM   160618142018110605   \n",
       "\n",
       "  trans_seq ref_source        ref_date program_id pharmacy_id pat_last_name  \\\n",
       "0         0     DIRECT  20181019120000       None    27913343          None   \n",
       "1         0     DIRECT  20181022120000       None    27837098          None   \n",
       "2         0     DIRECT  20181024120000       None    27918148          None   \n",
       "3         0     DIRECT  20181030120000       None    26724498          None   \n",
       "4         0     DIRECT  20181102120000       None    16061814          None   \n",
       "\n",
       "  pat_first_name pat_dob pat_gender pat_addr1 pat_addr2 pat_city pat_state  \\\n",
       "0           None    None       None      None      None     None      None   \n",
       "1           None    None          F      None      None     None      None   \n",
       "2           None    None          M      None      None     None      None   \n",
       "3           None    None          F      None      None     None      None   \n",
       "4           None    None          F      None      None     None      None   \n",
       "\n",
       "  pat_zip dx1_code dx2_code     status_date status_code     sub_status  \\\n",
       "0      00    L40.0     None  20181024115959   CANCELLED          OTHER   \n",
       "1      00    L40.0     None  20181025115959   CANCELLED  INSURANCE OON   \n",
       "2      00    L40.0     None  20181029115959   CANCELLED          OTHER   \n",
       "3      00      Q84    L40.0  20181102115959   CANCELLED  INSURANCE OON   \n",
       "4      00    696.1     None  20181106115959   CANCELLED          OTHER   \n",
       "\n",
       "  pres_last_name pres_first_name               pres_addr1 pres_addr2  \\\n",
       "0           None            None                     None       None   \n",
       "1      GREENBERG          ROBERT    5201 NORRIS CANYON RD       None   \n",
       "2        SCIURBA       SALVATORE        111 WEST WATER ST       None   \n",
       "3       KNUCKLES         MELISSA  1101 EAST MASTER STREET       None   \n",
       "4           KORY            MARK        16216 BAXTER ROAD  SUITE 200   \n",
       "\n",
       "      pres_city pres_state pres_zip  pres_phone    pres_npi   pres_dea  \\\n",
       "0          None       None    99999        None        None       None   \n",
       "1     SAN RAMON         CA    94583  9252771300  1639195316  BG0616043   \n",
       "2    TOMS RIVER         NJ    08753  7322444700  1093765307       None   \n",
       "3        CORBIN         KY    40701  6065282881  1821074360  BK0531562   \n",
       "4  CHESTERFIELD         MO    63017  6365321000  1326034489  BK1220045   \n",
       "\n",
       "  facility_name rxdate rxnumber rxrefills rxfill refill_remaining prev_disp  \\\n",
       "0          None   None     None      None   None             None      None   \n",
       "1          None   None     None      None   None             None      None   \n",
       "2          None   None     None      None   None             None      None   \n",
       "3          None   None     None      None   None             None      None   \n",
       "4          None   None     None      None   None             None      None   \n",
       "\n",
       "  rx_ndc_number medication quantity day_supply ship_date ship_carrier  \\\n",
       "0          None     ILUMYA     None       None      None         None   \n",
       "1          None     ILUMYA     None       None      None         None   \n",
       "2          None     ILUMYA     None       None      None         None   \n",
       "3          None     ILUMYA     None       None      None         None   \n",
       "4          None     ILUMYA     None       None      None         None   \n",
       "\n",
       "  shiptracking_num ship_location ship_address ship_city ship_state ship_zip  \\\n",
       "0             None          None         None      None       None     None   \n",
       "1             None          None         None      None       None     None   \n",
       "2             None          None         None      None       None     None   \n",
       "3             None          None         None      None       None     None   \n",
       "4             None          None         None      None       None     None   \n",
       "\n",
       "  has_medical primary_coverage_type          primary_payer_name  \\\n",
       "0           Y               MEDICAL              GENERAL DIRECT   \n",
       "1           Y               MEDICAL  BROWN & TOLAND MEDICAL GRP   \n",
       "2           Y               MEDICAL     GENERAL HORIZON BCBS NJ   \n",
       "3           Y               MEDICAL     ANTHEM BCBS OF KENTUCKY   \n",
       "4           Y               MEDICAL             EXPRESS SCRIPTS   \n",
       "\n",
       "  primary_payer_type secondary_coverage_type secondary_payer_name  \\\n",
       "0         COMMERCIAL                    None                 None   \n",
       "1         COMMERCIAL                    None                 None   \n",
       "2         COMMERCIAL                    None                 None   \n",
       "3           MEDICARE                    None                 None   \n",
       "4         COMMERCIAL                    None                 None   \n",
       "\n",
       "  secondary_payer_type plan_paid_amt pat_copay copay_assist_amount  \\\n",
       "0                 None          None      None                None   \n",
       "1                 None          None      None                None   \n",
       "2                 None          None      None                None   \n",
       "3                 None          None      None                None   \n",
       "4                 None          None      None                None   \n",
       "\n",
       "  oth_payer_amt xfer_pharmname msa_patient_id msa_patient_bmap  \\\n",
       "0          None           None           None            NNNNV   \n",
       "1          None           None           None            NNNVV   \n",
       "2          None           None           None            NNNVV   \n",
       "3          None           None           None            NNNVV   \n",
       "4          None           None           None            NNNVV   \n",
       "\n",
       "  __metadata_run_timestamp __metadata_app_version  \\\n",
       "0      2019-07-09 14:06:06                 0.0.11   \n",
       "1      2019-07-09 14:06:06                 0.0.11   \n",
       "2      2019-07-09 14:06:06                 0.0.11   \n",
       "3      2019-07-09 14:06:06                 0.0.11   \n",
       "4      2019-07-09 14:06:06                 0.0.11   \n",
       "\n",
       "  __metadata_transform_timestamp  \\\n",
       "0            2019-07-09 14:09:34   \n",
       "1            2019-07-09 14:09:34   \n",
       "2            2019-07-09 14:09:34   \n",
       "3            2019-07-09 14:09:34   \n",
       "4            2019-07-09 14:09:34   \n",
       "\n",
       "                          __metadata_output_contract  __metadata_run_id  \n",
       "0  s3://ichain-dev/sun-extract-prod-vars/sun/ilum...                  5  \n",
       "1  s3://ichain-dev/sun-extract-prod-vars/sun/ilum...                  5  \n",
       "2  s3://ichain-dev/sun-extract-prod-vars/sun/ilum...                  5  \n",
       "3  s3://ichain-dev/sun-extract-prod-vars/sun/ilum...                  5  \n",
       "4  s3://ichain-dev/sun-extract-prod-vars/sun/ilum...                  5  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "null_df[['']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "********* VARIABLES - PLEASE TOUCH ********* \n",
    "This section defines what you expect to get from the configuration application \n",
    "in a single \"transform\" object. Define the vars you need here, and comment inline to the right of them \n",
    "for all-in-one documentation. \n",
    "Engineering will build a production \"transform\" object for every pipeline that matches what you define here.\n",
    "\n",
    "@@@ FORMAT OF THE DATA CLASS IS: @@@ \n",
    "\n",
    "<variable_name>: <data_type> #<comment explaining what the value is to future us>\n",
    "\n",
    "e.g.\n",
    "\n",
    "class Transform(DbTransform):\n",
    "    some_ratio: float\n",
    "    site_name: str\n",
    "\n",
    "~~These ARE the droids you are looking for~~\n",
    "\"\"\"\n",
    "\n",
    "class Transform(DbTransform):\n",
    "    '''\n",
    "    YOUR properties go here!!\n",
    "    Variable properties should be assigned to the exact name of\n",
    "    the transformation as it appears in the Jupyter notebook filename.\n",
    "    '''\n",
    "\n",
    "    def fill_null_long_pat_id(df):\n",
    "    \n",
    "transform = Transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Please place your value assignments for development here!!\n",
    "## This cell will be turned off in production and Engineering will set to pull from the configuration application instead\n",
    "## For the last example, this could look like...\n",
    "## transform.some_ratio = 0.6\n",
    "## transform.site_name = \"WALGREENS\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description\n",
    "What does this transformation do? be specific.\n",
    "\n",
    "![what does your transform do](assets/what.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(clear out and replace with your description)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "************ FETCH DATA - TOUCH, BUT CAREFULLY **************\n",
    "This cell will be turned off in production, as the input_contract will be handled by the pipeline.\n",
    "\"\"\"\n",
    "\n",
    "if not input_branch:\n",
    "    input_branch = BRANCH_NAME\n",
    "input_contract = DatasetContract(branch=input_branch, state=input_state, parent=input_pharma, child=input_brand, dataset=input_name)\n",
    "run_filter = []\n",
    "# run_filter.append(dict(partition=\"run_id\", comparison=\"==\", values=[1]))\n",
    "# IF YOU HAVE PUBLISHED DATA MULTIPLE TIMES, uncomment the above line and change the int to the run_id to fetch.\n",
    "# Otherwise, you will have duplicate values in your fetched dataset!\n",
    "final_dataframe = input_contract.fetch(filters=run_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Use the variables above to execute your transformation. the final output needs to be a variable named final_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Publish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## that's it - just provide the final dataframe to the var final_dataframe and we take it from there\n",
    "transform.publish_contract.publish(final_dataframe, run_id, session)\n",
    "session.close()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
>>>>>>> waiting for column info
