{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:The 'log_level' trait of an IPKernelApp instance must be any of (0, 10, 20, 30, 40, 50, 'DEBUG', 'INFO', 'WARN', 'ERROR', 'CRITICAL'), but a value of 'WORKAROUND' <class 'str'> was specified.\n",
      "DEBUG:root:Test debug\n"
     ]
    }
   ],
   "source": [
    "# workaround via specifying an invalid value first\n",
    "%config Application.log_level='WORKAROUND'\n",
    "# => fails, necessary on Fedora 27, ipython3 6.2.1\n",
    "%config Application.log_level='DEBUG'\n",
    "import logging\n",
    "logging.getLogger().setLevel(logging.DEBUG)\n",
    "log = logging.getLogger()\n",
    "log.debug('Test debug')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_id=40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:git.cmd:Popen(['git', 'version'], cwd=/host/core/transforms, universal_newlines=False, shell=None)\n",
      "DEBUG:git.cmd:Popen(['git', 'version'], cwd=/host/core/transforms, universal_newlines=False, shell=None)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-28 18:15:29,520 - core.helpers.session_helper.SessionHelper - INFO - Creating session for dev environment...\n",
      "2019-05-28 18:15:29,542 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating administrator mocks.\n",
      "2019-05-28 18:15:29,575 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating administrator mocks.\n",
      "2019-05-28 18:15:29,576 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating pharmaceutical company mocks.\n",
      "2019-05-28 18:15:29,579 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating pharmaceutical company mocks.\n",
      "2019-05-28 18:15:29,580 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating brand mocks.\n",
      "2019-05-28 18:15:29,583 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating brand mocks.\n",
      "2019-05-28 18:15:29,584 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating segment mocks.\n",
      "2019-05-28 18:15:29,588 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating segment mocks.\n",
      "2019-05-28 18:15:29,589 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating pipeline type mocks.\n",
      "2019-05-28 18:15:29,593 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating pipeline type mocks.\n",
      "2019-05-28 18:15:29,595 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating pipeline mocks.\n",
      "2019-05-28 18:15:29,601 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating pipeline mocks.\n",
      "2019-05-28 18:15:29,602 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating pipeline state type mocks.\n",
      "2019-05-28 18:15:29,606 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating pipeline state type mocks.\n",
      "2019-05-28 18:15:29,607 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating pipeline state mocks.\n",
      "2019-05-28 18:15:29,615 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating pipeline state mocks.\n",
      "2019-05-28 18:15:29,616 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating tag mocks.\n",
      "2019-05-28 18:15:29,619 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating tag mocks.\n",
      "2019-05-28 18:15:29,620 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating transformation_template mocks.\n",
      "2019-05-28 18:15:29,627 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating transformation_template mocks.\n",
      "2019-05-28 18:15:29,628 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating bridge table mocks for transformation_templates <=> tags.\n",
      "2019-05-28 18:15:29,631 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating transformation_templates_tags mocks.\n",
      "2019-05-28 18:15:29,632 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating transformation mocks.\n",
      "2019-05-28 18:15:29,650 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating transformation mocks.\n",
      "2019-05-28 18:15:29,651 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating transformation_variables mocks\n",
      "2019-05-28 18:15:29,712 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating transformation_variables mocks.\n",
      "2019-05-28 18:15:29,714 - core.helpers.session_helper.SessionHelper - INFO - Done. Created dev session with mock data.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "************ SETUP - DON'T TOUCH **************\n",
    "This section imports data from the configuration database\n",
    "and should not need to be altered, molested or otherwise messed with. \n",
    "~~These are not the droids you are looking for~~\n",
    "\"\"\"\n",
    "from core.constants import BRANCH_NAME, ENV_BUCKET\n",
    "from core.helpers.session_helper import SessionHelper\n",
    "from core.models.configuration import Transformation\n",
    "from dataclasses import dataclass\n",
    "from core.dataset_contract import DatasetContract\n",
    "\n",
    "db_transform = SessionHelper().session.query(Transformation).filter(Transformation.id == transform_id).one()\n",
    "\n",
    "@dataclass\n",
    "class DbTransform:\n",
    "    id: int = db_transform.id ## the instance id of the transform in the config app\n",
    "    name: str = db_transform.transformation_template.name ## the transform name in the config app\n",
    "    state: str = db_transform.pipeline_state.pipeline_state_type.name ## the pipeline state, one of raw, ingest, master, enhance, enrich, metrics, dimensional\n",
    "    branch:str = BRANCH_NAME ## the git branch for this execution \n",
    "    brand: str = db_transform.pipeline_state.pipeline.brand.name ## the pharma brand name\n",
    "    pharmaceutical_company: str = db_transform.pipeline_state.pipeline.brand.pharmaceutical_company.name # the pharma company name\n",
    "    publish_contract: DatasetContract = DatasetContract(branch=BRANCH_NAME,\n",
    "                            parent=db_transform.pipeline_state.pipeline.brand.pharmaceutical_company.name,\n",
    "                            child=db_transform.pipeline_state.pipeline.brand.name,\n",
    "                            state=db_transform.pipeline_state.pipeline_state_type.name,\n",
    "                            dataset=db_transform.transformation_template.name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CORE Cartridge Notebook :: symphony_health_association_refinement\n",
    "![CORE Logo](assets/coreLogo.png) \n",
    "\n",
    "---\n",
    "## Keep in Mind\n",
    "Good Transforms Are...\n",
    "- **singular in purpose:** good transforms do one and only one thing, and handle all known cases for that thing. \n",
    "- **repeatable:** transforms should be written in a way that they can be run against the same dataset an infinate number of times and get the same result every time. \n",
    "- **easy to read:** 99 times out of 100, readable, clear code that runs a little slower is more valuable than a mess that runs quickly. \n",
    "- **No 'magic numbers':** if a variable or function is not instantly obvious as to what it is or does, without context, maybe consider renaming it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow - how to use this notebook to make science\n",
    "#### Data Science\n",
    "1. **Document your transform.** Fill out the _description_ cell below describing what it is this transform does; this will appear in the configuration application where Ops will create, configure and update pipelines. \n",
    "1. **Define your config object.** Fill out the _configuration_ cell below the commented-out guide to define the variables you want ops to set in the configuration application (these will populate here for every pipeline). \n",
    "2. **Build your transformation logic.** Use the transformation cell to do that magic that you do. \n",
    "![caution](assets/cautionTape.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "********* CONFIGURATION - PLEASE TOUCH ********* \n",
    "This section defines what you expect to get from the configuration application \n",
    "in a single \"transform\" object. Define the vars you need here, and comment inline to the right of them \n",
    "for all-in-one documentation. \n",
    "Engineering will build a production \"transform\" object for every pipeline that matches what you define here.\n",
    "\n",
    "@@@ FORMAT OF THE DATA CLASS IS: @@@ \n",
    "\n",
    "<value_name>: <data_type> #<comment explaining what the value is to future us>\n",
    "\n",
    "~~These ARE the droids you are looking for~~\n",
    "\"\"\"\n",
    "\n",
    "class Transform(DbTransform):\n",
    "        ## YOUR properties go here!!\n",
    "        ingest_source_transform: str = db_transform.variables.ingest_source_transform # The name of the dataset to pull from\n",
    "        ingest_source_file_prefix: str = db_transform.variables.ingest_source_file_prefix # If from initial ingest, the file prefix name\n",
    "        # The following follows possible approach of ingest mapping by individual vars\n",
    "        rec_date_col: str = db_transform.variables.rec_date_col\n",
    "        pharm_code_col: str = db_transform.variables.pharm_code_col\n",
    "        pharm_npi: str = db_transform.variables.pharm_npi\n",
    "        transtype: str = db_transform.variables.transtype\n",
    "        pharm_transaction_id: str = db_transform.variables.pharm_transaction_id\n",
    "        trans_seq: str = db_transform.variables.trans_seq\n",
    "        ref_source: str = db_transform.variables.ref_source\n",
    "        ref_date: str = db_transform.variables.ref_date\n",
    "        program_id: str = db_transform.variables.program_id\n",
    "        pharmacy_id: str = db_transform.variables.pharmacy_id\n",
    "        pat_last_name: str = db_transform.variables.pat_last_name\n",
    "        pat_first_name: str = db_transform.variables.pat_first_name\n",
    "        pat_dob: str = db_transform.variables.pat_dob\n",
    "        pat_gender: str = db_transform.variables.pat_gender\n",
    "        pat_addr1: str = db_transform.variables.pat_addr1\n",
    "        pat_addr2: str = db_transform.variables.pat_addr2\n",
    "        pat_city: str = db_transform.variables.pat_city\n",
    "        pat_state: str = db_transform.variables.pat_state\n",
    "        pat_zip: str = db_transform.variables.pat_zip\n",
    "        dx1_code: str = db_transform.variables.dx1_code\n",
    "        dx2_code: str = db_transform.variables.dx2_code\n",
    "        status_date: str = db_transform.variables.status_date\n",
    "        status_code: str = db_transform.variables.status_code\n",
    "        sub_status: str = db_transform.variables.sub_status\n",
    "        pres_last_name: str = db_transform.variables.pres_last_name\n",
    "        pres_first_name: str = db_transform.variables.pres_first_name\n",
    "        pres_addr1: str = db_transform.variables.pres_addr1\n",
    "        pres_addr2: str = db_transform.variables.pres_addr2\n",
    "        pres_city: str = db_transform.variables.pres_city\n",
    "        pres_state: str = db_transform.variables.pres_state\n",
    "        pres_zip: str = db_transform.variables.pres_zip\n",
    "        pres_phone: str = db_transform.variables.pres_phone\n",
    "        pres_npi: str = db_transform.variables.pres_npi\n",
    "        pres_dea: str = db_transform.variables.pres_dea\n",
    "        facility_name: str = db_transform.variables.facility_name\n",
    "        rxdate: str = db_transform.variables.rxdate\n",
    "        rxnumber: str = db_transform.variables.rxnumber\n",
    "        rxrefills: str = db_transform.variables.rxrefills\n",
    "        rxfill: str = db_transform.variables.rxfill\n",
    "        refill_remaining: str = db_transform.variables.refill_remaining\n",
    "        prev_disp: str = db_transform.variables.prev_disp\n",
    "        rx_ndc_number: str = db_transform.variables.rx_ndc_number\n",
    "        medication: str = db_transform.variables.medication\n",
    "        quantity: str = db_transform.variables.quantity\n",
    "        day_supply: str = db_transform.variables.day_supply\n",
    "        ship_date: str = db_transform.variables.ship_date\n",
    "        ship_carrier: str = db_transform.variables.ship_carrier\n",
    "        shiptracking_num: str = db_transform.variables.shiptracking_num\n",
    "        ship_location: str = db_transform.variables.ship_location\n",
    "        ship_address: str = db_transform.variables.ship_address\n",
    "        ship_city: str = db_transform.variables.ship_city\n",
    "        ship_state: str = db_transform.variables.ship_state\n",
    "        ship_zip: str = db_transform.variables.ship_zip\n",
    "        has_medical: str = db_transform.variables.has_medical\n",
    "        primary_coverage_type: str = db_transform.variables.primary_coverage_type\n",
    "        primary_payer_name: str = db_transform.variables.primary_payer_name\n",
    "        primary_payer_type: str = db_transform.variables.primary_payer_type\n",
    "        secondary_coverage_type: str = db_transform.variables.secondary_coverage_type\n",
    "        secondary_payer_name: str = db_transform.variables.secondary_payer_name\n",
    "        secondary_payer_type: str = db_transform.variables.secondary_payer_type\n",
    "        plan_paid_amt: str = db_transform.variables.plan_paid_amt\n",
    "        pat_copay: str = db_transform.variables.pat_copay\n",
    "        copay_assist_amount: str = db_transform.variables.copay_assist_amount\n",
    "        oth_payer_amt: str = db_transform.variables.oth_payer_amt\n",
    "        xfer_pharmname: str = db_transform.variables.xfer_pharmname\n",
    "        msa_patient_id: str = db_transform.variables.msa_patient_id\n",
    "        msa_patient_bmap: str = db_transform.variables.msa_patient_bmap\n",
    "        metadata_run_timestamp: str = db_transform.variables.metadata_run_timestamp\n",
    "        metadata_app_version: str = db_transform.variables.metadata_app_version\n",
    "        metadata_output_contract: str = db_transform.variables.metadata_output_contract"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.logging import get_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = Transform()\n",
    "logger = get_logger(f\"core.transforms.{transform.state}.{transform.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_renames = {\n",
    "    transform.rec_date_col : 'rec_date',\n",
    "    transform.pharm_code_col : 'pharm_code',\n",
    "    transform.pharm_npi : 'pharm_npi',\n",
    "    transform.transtype : 'transtype',\n",
    "    transform.pharm_transaction_id : 'pharm_transaction_id',\n",
    "    transform.trans_seq : 'trans_seq',\n",
    "    transform.ref_source : 'ref_source',\n",
    "    transform.ref_date : 'ref_date',\n",
    "    transform.program_id : 'program_id',\n",
    "    transform.pharmacy_id : 'pharmacy_id',\n",
    "    transform.pat_last_name : 'pat_last_name',\n",
    "    transform.pat_first_name : 'pat_first_name',\n",
    "    transform.pat_dob : 'pat_dob',\n",
    "    transform.pat_gender : 'pat_gender',\n",
    "    transform.pat_addr1 : 'pat_addr1',\n",
    "    transform.pat_addr2 : 'pat_addr2',\n",
    "    transform.pat_city : 'pat_city',\n",
    "    transform.pat_state : 'pat_state',\n",
    "    transform.pat_zip : 'pat_zip',\n",
    "    transform.dx1_code : 'dx1_code',\n",
    "    transform.dx2_code : 'dx2_code',\n",
    "    transform.status_date : 'status_date',\n",
    "    transform.status_code : 'status_code',\n",
    "    transform.sub_status : 'sub_status',\n",
    "    transform.pres_last_name : 'pres_last_name',\n",
    "    transform.pres_first_name : 'pres_first_name',\n",
    "    transform.pres_addr1 : 'pres_addr1',\n",
    "    transform.pres_addr2 : 'pres_addr2',\n",
    "    transform.pres_city : 'pres_city',\n",
    "    transform.pres_state : 'pres_state',\n",
    "    transform.pres_zip : 'pres_zip',\n",
    "    transform.pres_phone : 'pres_phone',\n",
    "    transform.pres_npi : 'pres_npi',\n",
    "    transform.pres_dea : 'pres_dea',\n",
    "    transform.facility_name : 'facility_name',\n",
    "    transform.rxdate : 'rxdate',\n",
    "    transform.rxnumber : 'rxnumber',\n",
    "    transform.rxrefills : 'rxrefills',\n",
    "    transform.rxfill : 'rxfill',\n",
    "    transform.refill_remaining : 'refill_remaining',\n",
    "    transform.prev_disp : 'prev_disp',\n",
    "    transform.rx_ndc_number : 'rx_ndc_number',\n",
    "    transform.medication : 'medication',\n",
    "    transform.quantity : 'quantity',\n",
    "    transform.day_supply : 'day_supply',\n",
    "    transform.ship_date : 'ship_date',\n",
    "    transform.ship_carrier : 'ship_carrier',\n",
    "    transform.shiptracking_num : 'shiptracking_num',\n",
    "    transform.ship_location : 'ship_location',\n",
    "    transform.ship_address : 'ship_address',\n",
    "    transform.ship_city : 'ship_city',\n",
    "    transform.ship_state : 'ship_state',\n",
    "    transform.ship_zip : 'ship_zip',\n",
    "    transform.has_medical : 'has_medical',\n",
    "    transform.primary_coverage_type : 'primary_coverage_type',\n",
    "    transform.primary_payer_name : 'primary_payer_name',\n",
    "    transform.primary_payer_type : 'primary_payer_type',\n",
    "    transform.secondary_coverage_type : 'secondary_coverage_type',\n",
    "    transform.secondary_payer_name : 'secondary_payer_name',\n",
    "    transform.secondary_payer_type : 'secondary_payer_type',\n",
    "    transform.plan_paid_amt : 'plan_paid_amt',\n",
    "    transform.pat_copay : 'pat_copay',\n",
    "    transform.copay_assist_amount : 'copay_assist_amount',\n",
    "    transform.oth_payer_amt : 'oth_payer_amt',\n",
    "    transform.xfer_pharmname : 'xfer_pharmname',\n",
    "    transform.msa_patient_id : 'msa_patient_id',\n",
    "    transform.msa_patient_bmap : 'msa_patient_bmap',\n",
    "    transform.metadata_run_timestamp : '__metadata_run_timestamp',\n",
    "    transform.metadata_app_version : '__metadata_app_version',\n",
    "    transform.metadata_output_contract : '__metadata_output_contract'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description\n",
    "What does this transformation do? be specific.\n",
    "\n",
    "![what does your transform do](assets/what.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This transform takes the Symphony Health Association base ingested data and separates out useful columns and uppercases all the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from s3parq import fetch_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-28 18:15:29,904 - core.transforms.ingest.symphony_health_association_refinement - DEBUG - Retrieving data from path : s3://ichain-dev/stephanie/stephanie/ilumya/ingest/initial_ingest/INTEGRICHAIN_SUN_WALGREENS_STATUSDISPENSE\n"
     ]
    }
   ],
   "source": [
    "# Place your import contracts here\n",
    "ingest_dataset = transform.ingest_source_transform + \"/\" + transform.ingest_source_file_prefix\n",
    "\n",
    "ingest_contract = DatasetContract(branch=BRANCH_NAME,\n",
    "                            parent=transform.pharmaceutical_company,\n",
    "                            child=transform.brand,\n",
    "                            state=\"ingest\",\n",
    "                            dataset=ingest_dataset)\n",
    "\n",
    "logger.debug(f\"Retrieving data from path : {ingest_contract.s3_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-28 18:15:30,275 - core.transforms.ingest.symphony_health_association_refinement - DEBUG - Difference fetched, fetched dataframe shape : (0, 0)\n"
     ]
    }
   ],
   "source": [
    "# Using only the run timestamp at this point in time\n",
    "diff_partition = \"__metadata_run_timestamp\"\n",
    "\n",
    "# This transform must call s3parq directly as it is still working off of the initial ingest schema\n",
    "final_dataframe = fetch_diff(input_bucket=ENV_BUCKET, \n",
    "                             input_key=ingest_contract.key, \n",
    "                             comparison_bucket=ENV_BUCKET, \n",
    "                             comparison_key=transform.publish_contract.key, \n",
    "                             partition=diff_partition)\n",
    "\n",
    "logger.debug(f\"Difference fetched, fetched dataframe shape : {final_dataframe.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-28 18:15:30,287 - core.transforms.ingest.symphony_health_association_refinement - DEBUG - Expecting the following columns : ['Rec Date', 'Pharm Code', 'Pharm NPI', 'transType', 'Pharm Transaction Id', 'Trans Seq', 'Ref Source', 'Ref Date', 'Program ID', 'Pharmacy ID', 'Pat Last Name', 'Pat First Name', 'Pat DOB', 'PatGender', 'Pat Addr1', 'Pat Addr2', 'Pat City', 'Pat State', 'Pat Zip', 'Dx1 Code', 'Dx2 Code', 'Status Date', 'Status Code', 'Sub Status', 'Pres Last Name', 'Pres First Name', 'Pres Addr1', 'Pres Addr2', 'Pres City', 'Pres State', 'Pres Zip', 'Pres Phone', 'Pres NPI', 'Pres DEA', 'Facility Name', 'RxDate', 'RxNumber', 'RxRefills', 'RxFill', 'Refill Remaining', 'prev Disp', 'Rx NDC Number', 'Medication', 'Quantity', 'Day Supply', 'Ship Date', 'Ship Carrier', 'shipTracking Num', 'Ship Location', 'Ship Address', 'Ship City', 'Ship State', 'Ship Zip', 'Has Medical', 'Primary CoverageType', 'Primary Payer Name', 'Primary Payer Type', 'Secondary CoverageType', 'Secondary PayerName', 'Secondary PayerType', 'Plan Paid Amt', 'Pat Copay', 'Copay Assist Amount', 'Oth Payer Amt', 'Xfer PharmName', 'MSA PATIENT ID', 'MSA PATIENT BMAP', '__metadata_run_timestamp', '__metadata_app_version', '__metadata_output_contract']\n",
      "2019-05-28 18:15:30,288 - core.transforms.ingest.symphony_health_association_refinement - DEBUG - Dataframe has these columns : []\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index(['Rec Date', 'Pharm Code', 'Pharm NPI', 'transType',\\n       'Pharm Transaction Id', 'Trans Seq', 'Ref Source', 'Ref Date',\\n       'Program ID', 'Pharmacy ID', 'Pat Last Name', 'Pat First Name',\\n       'Pat DOB', 'PatGender', 'Pat Addr1', 'Pat Addr2', 'Pat City',\\n       'Pat State', 'Pat Zip', 'Dx1 Code', 'Dx2 Code', 'Status Date',\\n       'Status Code', 'Sub Status', 'Pres Last Name', 'Pres First Name',\\n       'Pres Addr1', 'Pres Addr2', 'Pres City', 'Pres State', 'Pres Zip',\\n       'Pres Phone', 'Pres NPI', 'Pres DEA', 'Facility Name', 'RxDate',\\n       'RxNumber', 'RxRefills', 'RxFill', 'Refill Remaining', 'prev Disp',\\n       'Rx NDC Number', 'Medication', 'Quantity', 'Day Supply', 'Ship Date',\\n       'Ship Carrier', 'shipTracking Num', 'Ship Location', 'Ship Address',\\n       'Ship City', 'Ship State', 'Ship Zip', 'Has Medical',\\n       'Primary CoverageType', 'Primary Payer Name', 'Primary Payer Type',\\n       'Secondary CoverageType', 'Secondary PayerName', 'Secondary PayerType',\\n       'Plan Paid Amt', 'Pat Copay', 'Copay Assist Amount', 'Oth Payer Amt',\\n       'Xfer PharmName', 'MSA PATIENT ID', 'MSA PATIENT BMAP',\\n       '__metadata_run_timestamp', '__metadata_app_version',\\n       '__metadata_output_contract'],\\n      dtype='object')] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-4693ae6daecf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# First cut down to the necesarry columns in case of accidental extras - Pandas wont catch those\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mfinal_dataframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_dataframe\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolumn_renames\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Rename based on above created configuration variables\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2932\u001b[0m                 \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2933\u001b[0m             indexer = self.loc._convert_to_indexer(key, axis=1,\n\u001b[0;32m-> 2934\u001b[0;31m                                                    raise_missing=True)\n\u001b[0m\u001b[1;32m   2935\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2936\u001b[0m         \u001b[0;31m# take() does not accept boolean indexers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_convert_to_indexer\u001b[0;34m(self, obj, axis, is_setter, raise_missing)\u001b[0m\n\u001b[1;32m   1352\u001b[0m                 kwargs = {'raise_missing': True if is_setter else\n\u001b[1;32m   1353\u001b[0m                           raise_missing}\n\u001b[0;32m-> 1354\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_listlike_indexer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1355\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1356\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_get_listlike_indexer\u001b[0;34m(self, key, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1159\u001b[0m         self._validate_read_indexer(keyarr, indexer,\n\u001b[1;32m   1160\u001b[0m                                     \u001b[0mo\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_axis_number\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1161\u001b[0;31m                                     raise_missing=raise_missing)\n\u001b[0m\u001b[1;32m   1162\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mkeyarr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindexer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/indexing.py\u001b[0m in \u001b[0;36m_validate_read_indexer\u001b[0;34m(self, key, indexer, axis, raise_missing)\u001b[0m\n\u001b[1;32m   1244\u001b[0m                 raise KeyError(\n\u001b[1;32m   1245\u001b[0m                     u\"None of [{key}] are in the [{axis}]\".format(\n\u001b[0;32m-> 1246\u001b[0;31m                         key=key, axis=self.obj._get_axis_name(axis)))\n\u001b[0m\u001b[1;32m   1247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1248\u001b[0m             \u001b[0;31m# We (temporarily) allow for some missing keys with .loc, except in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of [Index(['Rec Date', 'Pharm Code', 'Pharm NPI', 'transType',\\n       'Pharm Transaction Id', 'Trans Seq', 'Ref Source', 'Ref Date',\\n       'Program ID', 'Pharmacy ID', 'Pat Last Name', 'Pat First Name',\\n       'Pat DOB', 'PatGender', 'Pat Addr1', 'Pat Addr2', 'Pat City',\\n       'Pat State', 'Pat Zip', 'Dx1 Code', 'Dx2 Code', 'Status Date',\\n       'Status Code', 'Sub Status', 'Pres Last Name', 'Pres First Name',\\n       'Pres Addr1', 'Pres Addr2', 'Pres City', 'Pres State', 'Pres Zip',\\n       'Pres Phone', 'Pres NPI', 'Pres DEA', 'Facility Name', 'RxDate',\\n       'RxNumber', 'RxRefills', 'RxFill', 'Refill Remaining', 'prev Disp',\\n       'Rx NDC Number', 'Medication', 'Quantity', 'Day Supply', 'Ship Date',\\n       'Ship Carrier', 'shipTracking Num', 'Ship Location', 'Ship Address',\\n       'Ship City', 'Ship State', 'Ship Zip', 'Has Medical',\\n       'Primary CoverageType', 'Primary Payer Name', 'Primary Payer Type',\\n       'Secondary CoverageType', 'Secondary PayerName', 'Secondary PayerType',\\n       'Plan Paid Amt', 'Pat Copay', 'Copay Assist Amount', 'Oth Payer Amt',\\n       'Xfer PharmName', 'MSA PATIENT ID', 'MSA PATIENT BMAP',\\n       '__metadata_run_timestamp', '__metadata_app_version',\\n       '__metadata_output_contract'],\\n      dtype='object')] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "logger.debug(f\"Expecting the following columns : {list(column_renames.keys())}\")\n",
    "logger.debug(f\"Dataframe has these columns : {list(final_dataframe.columns)}\")\n",
    "\n",
    "# First cut down to the necesarry columns in case of accidental extras - Pandas wont catch those\n",
    "final_dataframe = final_dataframe[list(column_renames.keys())]\n",
    "\n",
    "# Rename based on above created configuration variables\n",
    "final_dataframe = final_dataframe.rename(column_renames, axis=\"columns\")\n",
    "\n",
    "# Uppercase any string columns in the dataframe\n",
    "final_dataframe = final_dataframe.apply(lambda x: x.str.upper().str.strip() if isinstance(x, object) else x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Publish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## that's it - just provide the final dataframe to the var final_dataframe and we take it from there\n",
    "transform.publish_contract.publish(final_dataframe)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
