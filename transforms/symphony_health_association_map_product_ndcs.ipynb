{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_id = 14"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "schafrn/seed-data/sun-data-seed/ingest/symphony_health_association_refinement -> when you make the contract, its branch=schafrn,parent=seed-data,child=sun-data-seed,state=ingest,dataset=symphony_health_association_refinement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-20 18:33:26,542 - core.helpers.session_helper.SessionHelper - INFO - Creating session for dev environment...\n",
      "2019-05-20 18:33:26,567 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating administrator mocks.\n",
      "2019-05-20 18:33:26,598 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating administrator mocks.\n",
      "2019-05-20 18:33:26,599 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating pharmaceutical company mocks.\n",
      "2019-05-20 18:33:26,603 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating pharmaceutical company mocks.\n",
      "2019-05-20 18:33:26,604 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating brand mocks.\n",
      "2019-05-20 18:33:26,608 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating brand mocks.\n",
      "2019-05-20 18:33:26,609 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating segment mocks.\n",
      "2019-05-20 18:33:26,613 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating segment mocks.\n",
      "2019-05-20 18:33:26,614 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating pipeline type mocks.\n",
      "2019-05-20 18:33:26,618 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating pipeline type mocks.\n",
      "2019-05-20 18:33:26,620 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating pipeline mocks.\n",
      "2019-05-20 18:33:26,627 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating pipeline mocks.\n",
      "2019-05-20 18:33:26,628 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating pipeline state type mocks.\n",
      "2019-05-20 18:33:26,631 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating pipeline state type mocks.\n",
      "2019-05-20 18:33:26,632 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating pipeline state mocks.\n",
      "2019-05-20 18:33:26,638 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating pipeline state mocks.\n",
      "2019-05-20 18:33:26,639 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating tag mocks.\n",
      "2019-05-20 18:33:26,643 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating tag mocks.\n",
      "2019-05-20 18:33:26,644 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating transformation_template mocks.\n",
      "2019-05-20 18:33:26,649 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating transformation_template mocks.\n",
      "2019-05-20 18:33:26,651 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating bridge table mocks for transformation_templates <=> tags.\n",
      "2019-05-20 18:33:26,654 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating transformation_templates_tags mocks.\n",
      "2019-05-20 18:33:26,655 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating transformation mocks.\n",
      "2019-05-20 18:33:26,671 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating transformation mocks.\n",
      "2019-05-20 18:33:26,672 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating transformation_variables mocks\n",
      "2019-05-20 18:33:26,691 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating transformation_variables mocks.\n",
      "2019-05-20 18:33:26,692 - core.helpers.session_helper.SessionHelper - INFO - Done. Created dev session with mock data.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "************ SETUP - DON'T TOUCH **************\n",
    "This section imports data from the configuration database\n",
    "and should not need to be altered, molested or otherwise messed with. \n",
    "~~These are not the droids you are looking for~~\n",
    "\"\"\"\n",
    "from core.constants import BRANCH_NAME, ENV_BUCKET\n",
    "from core.helpers.session_helper import SessionHelper\n",
    "from core.models.configuration import Transformation\n",
    "from dataclasses import dataclass\n",
    "from core.dataset_contract import DatasetContract\n",
    "#import pandas as pd\n",
    "\n",
    "db_transform = SessionHelper().session.query(Transformation).filter(Transformation.id == transform_id).one()\n",
    "\n",
    "@dataclass\n",
    "class DbTransform:\n",
    "    id: int = db_transform.id ## the instance id of the transform in the config app\n",
    "    name: str = db_transform.transformation_template.name ## the transform name in the config app\n",
    "    state: str = db_transform.pipeline_state.pipeline_state_type.name ## the pipeline state, one of raw, ingest, master, enhance, enrich, metrics, dimensional\n",
    "    branch: str = \"schafrn\"\n",
    "    #branch: str = BRANCH_NAME ## the git branch for this execution \n",
    "    brand: str = db_transform.pipeline_state.pipeline.brand.name ## the pharma brand name\n",
    "    pharmaceutical_company: str = db_transform.pipeline_state.pipeline.brand.pharmaceutical_company.name # the pharma company name\n",
    "    publish_contract: DatasetContract = DatasetContract(branch=BRANCH_NAME,\n",
    "                            state=db_transform.pipeline_state.pipeline_state_type.name,\n",
    "                            parent=db_transform.pipeline_state.pipeline.brand.pharmaceutical_company.name,\n",
    "                            child=db_transform.pipeline_state.pipeline.brand.name,\n",
    "                            dataset=db_transform.transformation_template.name)\n",
    "    fetch_contract: DatasetContract = DatasetContract(branch=\"schafrn\", # TURN THIS OFF IN PROD, used to fetch rayne's mock data\n",
    "                            state=db_transform.pipeline_state.pipeline_state_type.name,\n",
    "                            parent=\"seed-data\",\n",
    "                            child=\"sun-data-seed\",\n",
    "                            dataset=db_transform.transformation_template.name)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CORE Cartridge Notebook::[transform name here]\n",
    "![CORE Logo](assets/coreLogo.png) \n",
    "\n",
    "---\n",
    "## Keep in Mind\n",
    "Good Transforms Are...\n",
    "- **singular in purpose:** good transforms do one and only one thing, and handle all known cases for that thing. \n",
    "- **repeatable:** transforms should be written in a way that they can be run against the same dataset an infinate number of times and get the same result every time. \n",
    "- **easy to read:** 99 times out of 100, readable, clear code that runs a little slower is more valuable than a mess that runs quickly. \n",
    "- **No 'magic numbers':** if a variable or function is not instantly obvious as to what it is or does, without context, maybe consider renaming it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow - how to use this notebook to make science\n",
    "#### Data Science\n",
    "1. **Document your transform.** Fill out the _description_ cell below describing what it is this transform does; this will appear in the configuration application where Ops will create, configure and update pipelines. \n",
    "1. **Define your config object.** Fill out the _configuration_ cell below the commented-out guide to define the variables you want ops to set in the configuration application (these will populate here for every pipeline). \n",
    "2. **Build your transformation logic.** Use the transformation cell to do that magic that you do. \n",
    "![caution](assets/cautionTape.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "********* CONFIGURATION - PLEASE TOUCH ********* \n",
    "This section defines what you expect to get from the configuration application \n",
    "in a single \"transform\" object. Define the vars you need here, and comment inline to the right of them \n",
    "for all-in-one documentation. \n",
    "Engineering will build a production \"transform\" object for every pipeline that matches what you define here.\n",
    "\n",
    "@@@ FORMAT OF THE DATA CLASS IS: @@@ \n",
    "\n",
    "<value_name>: <data_type> #<comment explaining what the value is to future us>\n",
    "\n",
    "~~These ARE the droids you are looking for~~\n",
    "\"\"\"\n",
    "\n",
    "class Transform(DbTransform):\n",
    "        input_transform: str = db_transform.variables.input_transform # The name of the transform to input source data from\n",
    "        index_col: str = db_transform.variables.index_col # The index column to map NDCs in the source dataset (default is rx_ndc_number)\n",
    "        secret_name: str = db_transform.variables.secret_name # The name of the secret in Secret Manager for platform2\n",
    "        secret_type_of: str = db_transform.variables.secret_type_of # The type of the secret in Secret Manager for platform2\n",
    "        ## YOUR properties go here!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Please place your value assignments for development here!!\n",
    "## This cell will be turned off in production and Engineering will set to pull form the configuration application instead\n",
    "\n",
    "transform = Transform()\n",
    "transform.input_transform = \"symphony_health_association_refinement\" # final ingest transform not written by me\n",
    "transform.index_col = \"rx_ndc_number\"\n",
    "transform.secret_name = \"platform2\"\n",
    "transform.secret_type_of = \"database\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description\n",
    "What does this transformation do? be specific.\n",
    "\n",
    "![what does your transform do](assets/what.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This transformation maps the NDC IDs found in a source dataset to product information found in IC master on platform2. The credentials used for platform2 are stored and read from an AWS secret."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-20 18:33:26,778 - core.helpers.session_helper.SessionHelper - INFO - Creating session for dev environment...\n",
      "2019-05-20 18:33:26,798 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating administrator mocks.\n",
      "2019-05-20 18:33:26,803 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating administrator mocks.\n",
      "2019-05-20 18:33:26,804 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating pharmaceutical company mocks.\n",
      "2019-05-20 18:33:26,808 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating pharmaceutical company mocks.\n",
      "2019-05-20 18:33:26,809 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating brand mocks.\n",
      "2019-05-20 18:33:26,814 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating brand mocks.\n",
      "2019-05-20 18:33:26,814 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating segment mocks.\n",
      "2019-05-20 18:33:26,818 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating segment mocks.\n",
      "2019-05-20 18:33:26,818 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating pipeline type mocks.\n",
      "2019-05-20 18:33:26,821 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating pipeline type mocks.\n",
      "2019-05-20 18:33:26,822 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating pipeline mocks.\n",
      "2019-05-20 18:33:26,827 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating pipeline mocks.\n",
      "2019-05-20 18:33:26,828 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating pipeline state type mocks.\n",
      "2019-05-20 18:33:26,832 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating pipeline state type mocks.\n",
      "2019-05-20 18:33:26,833 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating pipeline state mocks.\n",
      "2019-05-20 18:33:26,842 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating pipeline state mocks.\n",
      "2019-05-20 18:33:26,843 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating tag mocks.\n",
      "2019-05-20 18:33:26,846 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating tag mocks.\n",
      "2019-05-20 18:33:26,847 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating transformation_template mocks.\n",
      "2019-05-20 18:33:26,853 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating transformation_template mocks.\n",
      "2019-05-20 18:33:26,854 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating bridge table mocks for transformation_templates <=> tags.\n",
      "2019-05-20 18:33:26,858 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating transformation_templates_tags mocks.\n",
      "2019-05-20 18:33:26,860 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating transformation mocks.\n",
      "2019-05-20 18:33:26,869 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating transformation mocks.\n",
      "2019-05-20 18:33:26,870 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating transformation_variables mocks\n",
      "2019-05-20 18:33:26,882 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating transformation_variables mocks.\n",
      "2019-05-20 18:33:26,883 - core.helpers.session_helper.SessionHelper - INFO - Done. Created dev session with mock data.\n"
     ]
    }
   ],
   "source": [
    "### Retrieve current dataset from contract\n",
    "\n",
    "import core.helpers.contract_creator as cc\n",
    "from core.dataset_diff import DatasetDiff\n",
    "import s3parq\n",
    "\n",
    "deleteme = cc.get_relative_contract(t_name=transform.input_transform, contract=transform.fetch_contract)\n",
    "df = s3parq.fetch_parq.fetch(bucket=deleteme.bucket, key=deleteme.key)\n",
    "#diff = DatasetDiff(db_transform.id)\n",
    "#df = diff.get_diff(transform_name=transform.input_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-20 18:33:29,041 - core.secret.Secret - DEBUG - Secret idenditifier dev/database/platform2/read.\n"
     ]
    }
   ],
   "source": [
    "### Use the variables above to execute your transformation. the final output needs to be a variable named final_dataframe\n",
    "\n",
    "from core.secret import Secret\n",
    "import pandas as pd\n",
    "import mysql.connector\n",
    "\n",
    "secret = Secret(name=transform.secret_name, type_of=transform.secret_type_of, mode=\"read\").__dict__\n",
    "HOSTNAME = 'platform2.integrichain.com'\n",
    "\n",
    "# stub call to platform2 until we have a sandbox equivalent of platform2\n",
    "def product_master_details(unique_ndcs):\n",
    "    data = {'brand':['ILUMYA', 'ODOMZO', 'YONSA'], 'strength':['100mg/1mL', '200mg', '125mg'], 'prod_grp_id':[54826, 51105, 52813]}\n",
    "    df = pd.DataFrame(data, index=['47335017795', '47335030383', '47335040181'])\n",
    "    df.index.name = \"rx_ndc_number\"\n",
    "    return df\n",
    "\n",
    "    '''\n",
    "def product_master_details(unique_ndcs):\n",
    "    platform2 = mysql.connector.connect(host=HOSTNAME, user=secret['user'], passwd=secret['password'], port=secret['port'], charset='utf8')\n",
    "    sql = (\"\"\"\n",
    "                select pg.brand\n",
    "                    , pg.strength\n",
    "                    #, pg.packsize\n",
    "                    , pm.prod_grp_id\n",
    "                    , pm.prod_cust_id as rx_ndc_number\n",
    "                from pts.product_master as pm\n",
    "                    inner join pts.product_group as pg\n",
    "                        on pm.prod_grp_id = pg.id\n",
    "                where pm.cust_id = 'SUN' \n",
    "                    and pm.prod_cust_id in {}\n",
    "    \"\"\".format(unique_ndcs))\n",
    "    df = pd.read_sql(sql=sql, con=platform2, index_col=transform.index_col)\n",
    "    platform2.close()\n",
    "    return df\n",
    "\n",
    "    try:\n",
    "        platform2 = mysql.connector.connect(host=HOSTNAME, user=secret['user'], passwd=secret['password'], port=secret['port'], charset='utf8')\n",
    "        sql = (\"\"\"\n",
    "                select pg.brand\n",
    "                    , pg.strength\n",
    "                    #, pg.packsize\n",
    "                    , pm.prod_grp_id\n",
    "                    , pm.prod_cust_id as rx_ndc_number\n",
    "                from pts.product_master as pm\n",
    "                    inner join pts.product_group as pg\n",
    "                        on pm.prod_grp_id = pg.id\n",
    "                where pm.cust_id = 'SUN' \n",
    "                    and pm.prod_cust_id in {}\n",
    "        \"\"\".format(unique_ndcs))\n",
    "        df = pd.read_sql(sql=sql, con=HOSTNAME, index_col=transform.index_col)\n",
    "        platform2.close()\n",
    "        return df\n",
    "    \n",
    "    except:\n",
    "        print('Operation Aborted: Encountered an error.')\n",
    "        pass\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                brand   strength  prod_grp_id\n",
      "rx_ndc_number                                \n",
      "47335017795    ILUMYA  100mg/1mL        54826\n",
      "47335030383    ODOMZO      200mg        51105\n",
      "47335040181     YONSA      125mg        52813\n"
     ]
    }
   ],
   "source": [
    "unique_ndcs = tuple(df[~pd.isnull(df[transform.index_col])][transform.index_col].unique())\n",
    "product_details = product_master_details(unique_ndcs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         rec_date pharm_code   pharm_npi transtype pharm_transaction_id  \\\n",
      "0  20181024115959    ACCREDO  1346208949       COM   279133432018102401   \n",
      "1  20181025115959    ACCREDO  1346208949       COM   278370982018102502   \n",
      "2  20181029115959    ACCREDO  1346208949       COM   279181482018102903   \n",
      "3  20181102115959    ACCREDO  1346208949       COM   267244982018110204   \n",
      "4  20181106115959    ACCREDO  1346208949       COM   160618142018110605   \n",
      "\n",
      "  trans_seq ref_source        ref_date program_id pharmacy_id  ...  \\\n",
      "0         0     DIRECT  20181019120000       None    27913343  ...   \n",
      "1         0     DIRECT  20181022120000       None    27837098  ...   \n",
      "2         0     DIRECT  20181024120000       None    27918148  ...   \n",
      "3         0     DIRECT  20181030120000       None    26724498  ...   \n",
      "4         0     DIRECT  20181102120000       None    16061814  ...   \n",
      "\n",
      "  oth_payer_amt xfer_pharmname msa_patient_id msa_patient_bmap  \\\n",
      "0          None           None           None            NNNNV   \n",
      "1          None           None           None            NNNVV   \n",
      "2          None           None           None            NNNVV   \n",
      "3          None           None           None            NNNVV   \n",
      "4          None           None           None            NNNVV   \n",
      "\n",
      "  __metadata_app_version                         __metadata_output_contract  \\\n",
      "0                 0.0.11  s3://ichain-dev/schafrn/seed-data/sun-data-see...   \n",
      "1                 0.0.11  s3://ichain-dev/schafrn/seed-data/sun-data-see...   \n",
      "2                 0.0.11  s3://ichain-dev/schafrn/seed-data/sun-data-see...   \n",
      "3                 0.0.11  s3://ichain-dev/schafrn/seed-data/sun-data-see...   \n",
      "4                 0.0.11  s3://ichain-dev/schafrn/seed-data/sun-data-see...   \n",
      "\n",
      "  __metadata_run_timestamp brand strength prod_grp_id  \n",
      "0      2019-05-14 12:21:36   NaN      NaN         NaN  \n",
      "1      2019-05-14 12:21:36   NaN      NaN         NaN  \n",
      "2      2019-05-14 12:21:36   NaN      NaN         NaN  \n",
      "3      2019-05-14 12:21:36   NaN      NaN         NaN  \n",
      "4      2019-05-14 12:21:36   NaN      NaN         NaN  \n",
      "\n",
      "[5 rows x 73 columns]\n"
     ]
    }
   ],
   "source": [
    "df = df.merge(right=product_details, on='rx_ndc_number', how='left')\n",
    "final_dataframe = df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Publish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-05-20 18:33:29,280 - core.dataset_contract.DatasetContract - INFO - Publishing dataframe to s3 location s3://ichain-dev/stephanie/stephanie/ilumya/master/symphony_health_association_map_product_ndcs.\n",
      "2019-05-20 18:33:29,284 - s3parq.publish_parq - INFO - Checking params...\n",
      "2019-05-20 18:33:29,287 - s3parq.publish_parq - INFO - Params valid.\n",
      "2019-05-20 18:33:29,315 - s3parq.publish_parq - INFO - Writing to S3...\n"
     ]
    }
   ],
   "source": [
    "## that's it - just provide the final dataframe to the var final_dataframe and we take it from there\n",
    "transform.publish_contract.publish(final_dataframe)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
