{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-07-22 17:26:40,752 - core.helpers.session_helper.SessionHelper - INFO - Creating session for dev environment...\n",
      "2019-07-22 17:26:40,780 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating administrator mocks.\n",
      "2019-07-22 17:26:40,788 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating administrator mocks.\n",
      "2019-07-22 17:26:40,790 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating pharmaceutical company mocks.\n",
      "2019-07-22 17:26:40,798 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating pharmaceutical company mocks.\n",
      "2019-07-22 17:26:40,800 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating brand mocks.\n",
      "2019-07-22 17:26:40,805 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating brand mocks.\n",
      "2019-07-22 17:26:40,808 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating segment mocks.\n",
      "2019-07-22 17:26:40,812 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating segment mocks.\n",
      "2019-07-22 17:26:40,814 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating pipeline type mocks.\n",
      "2019-07-22 17:26:40,819 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating pipeline type mocks.\n",
      "2019-07-22 17:26:40,820 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating pipeline mocks.\n",
      "2019-07-22 17:26:40,829 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating pipeline mocks.\n",
      "2019-07-22 17:26:40,830 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating pipeline state type mocks.\n",
      "2019-07-22 17:26:40,834 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating pipeline state type mocks.\n",
      "2019-07-22 17:26:40,836 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating pipeline state mocks.\n",
      "2019-07-22 17:26:40,840 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating pipeline state mocks.\n",
      "2019-07-22 17:26:40,841 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating tag mocks.\n",
      "2019-07-22 17:26:40,847 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating tag mocks.\n",
      "2019-07-22 17:26:40,850 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating transformation_template mocks.\n",
      "2019-07-22 17:26:40,856 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating transformation_template mocks.\n",
      "2019-07-22 17:26:40,858 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating bridge table mocks for transformation_templates <=> tags.\n",
      "2019-07-22 17:26:40,865 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating transformation_templates_tags mocks.\n",
      "2019-07-22 17:26:40,875 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating transformation mocks.\n",
      "2019-07-22 17:26:40,879 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating transformation mocks.\n",
      "2019-07-22 17:26:40,882 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating transformation_variables mocks\n",
      "2019-07-22 17:26:40,885 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating transformation_variables mocks.\n",
      "2019-07-22 17:26:40,893 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating run_events mocks.\n",
      "2019-07-22 17:26:40,896 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating run_events mocks.\n",
      "2019-07-22 17:26:40,897 - core.helpers.session_helper.SessionHelper - INFO - Done. Created dev session with mock data.\n"
     ]
    }
   ],
   "source": [
    "from core.helpers.session_helper import SessionHelper\n",
    "session = SessionHelper().session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "************ CONFIGURATION - PLEASE TOUCH **************\n",
    "Pipeline Builder configuration: creates configurations from variables specified here!!\n",
    "This cell will be off in production as configurations will come from the configuration postgres DB.\n",
    "\"\"\"\n",
    "# config vars: this dataset\n",
    "config_pharma = \"bi\" # the pharmaceutical company which owns {brand}\n",
    "config_brand = \"bi_test3\" # the brand this pipeline operates on\n",
    "config_state = \"raw\" # the state this transform runs in\n",
    "config_name = \"extract_from_ftp\" # the name of this transform, which is the name of this notebook without .ipynb\n",
    "\n",
    "# input vars: dataset to fetch. Recall that a contract published to S3 has a key format branch/pharma/brand/state/name\n",
    "input_pharma = \"pharma\"\n",
    "input_brand = \"brand\"\n",
    "input_state = \"raw\"\n",
    "input_name = \"upstream\"\n",
    "input_branch = None # if None, input_branch is automagically set to your working branch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-07-22 17:27:59,934 - core.logging - DEBUG - Adding/getting mocks for specified configurations...\n",
      "2019-07-22 17:27:59,959 - core.logging - DEBUG - Done. Creating mock run event and committing results to configuration mocker.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "************ SETUP - DON'T TOUCH **************\n",
    "Populating config mocker based on config parameters...\n",
    "\"\"\"\n",
    "import core.helpers.pipeline_builder as builder\n",
    "\n",
    "ids = builder.build(config_pharma, config_brand, config_state, config_name, session)\n",
    "transform_id = ids[0]\n",
    "run_id = ids[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "************ SETUP - DON'T TOUCH **************\n",
    "This section imports data from the configuration database\n",
    "and should not need to be altered, molested or otherwise messed with. \n",
    "~~These are not the droids you are looking for~~\n",
    "\"\"\"\n",
    "from core.constants import BRANCH_NAME, ENV_BUCKET\n",
    "from core.helpers.session_helper import SessionHelper\n",
    "from core.models.configuration import Transformation\n",
    "from dataclasses import dataclass\n",
    "from core.raw_contract import RawContract\n",
    "\n",
    "db_transform = session.query(Transformation).filter(Transformation.id == transform_id).one()\n",
    "\n",
    "@dataclass\n",
    "class DbTransform:\n",
    "    id: int = db_transform.id ## the instance id of the transform in the config app\n",
    "    name: str = db_transform.transformation_template.name ## the transform name in the config app\n",
    "    state: str = db_transform.pipeline_state.pipeline_state_type.name ## the pipeline state, one of raw, ingest, master, enhance, enrich, metrics, dimensional\n",
    "    branch:str = BRANCH_NAME ## the git branch for this execution \n",
    "    brand: str = db_transform.pipeline_state.pipeline.brand.name ## the pharma brand name\n",
    "    pharmaceutical_company: str = db_transform.pipeline_state.pipeline.brand.pharmaceutical_company.name # the pharma company name\n",
    "    publish_contract: RawContract = RawContract(branch=BRANCH_NAME,\n",
    "                            parent=db_transform.pipeline_state.pipeline.brand.pharmaceutical_company.name,\n",
    "                            child=db_transform.pipeline_state.pipeline.brand.name,\n",
    "                            state=state)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CORE Cartridge Notebook::[Extract Transform]\n",
    "![CORE Logo](assets/coreLogo.png) \n",
    "\n",
    "---\n",
    "## Keep in Mind\n",
    "Good Transforms Are...\n",
    "- **singular in purpose:** good transforms do one and only one thing, and handle all known cases for that thing. \n",
    "- **repeatable:** transforms should be written in a way that they can be run against the same dataset an infinate number of times and get the same result every time. \n",
    "- **easy to read:** 99 times out of 100, readable, clear code that runs a little slower is more valuable than a mess that runs quickly. \n",
    "- **No 'magic numbers':** if a variable or function is not instantly obvious as to what it is or does, without context, maybe consider renaming it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow - how to use this notebook to make science\n",
    "#### Data Science\n",
    "1. **Document your transform.** Fill out the _description_ cell below describing what it is this transform does; this will appear in the configuration application where Ops will create, configure and update pipelines. \n",
    "1. **Define your config object.** Fill out the _configuration_ cell below the commented-out guide to define the variables you want ops to set in the configuration application (these will populate here for every pipeline). \n",
    "2. **Build your transformation logic.** Use the transformation cell to do that magic that you do. \n",
    "![caution](assets/cautionTape.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "********* CONFIGURATION - PLEASE TOUCH ********* \n",
    "This section defines what you expect to get from the configuration application \n",
    "in a single \"transform\" object. Define the vars you need here, and comment inline to the right of them \n",
    "for all-in-one documentation. \n",
    "Engineering will build a production \"transform\" object for every pipeline that matches what you define here.\n",
    "\n",
    "@@@ FORMAT OF THE DATA CLASS IS: @@@ \n",
    "\n",
    "<value_name>: <data_type> #<comment explaining what the value is to future us>\n",
    "\n",
    "~~These ARE the droids you are looking for~~\n",
    "\"\"\"\n",
    "\n",
    "class Transform(DbTransform):\n",
    "    pass\n",
    "        ## YOUR properties go here!!\n",
    "#         remote_path: str = db_transform.variables.remote_path # The path to follow on the remote server\n",
    "#         prefix: str = db_transform.variables.prefix # The prefix of files to get on the remote server\n",
    "#         secret_name: str = db_transform.variables.secret_name # The name of the secret in Secret Manager for the remote server\n",
    "#         secret_type_of: str = db_transform.variables.secret_type_of # The type of the secret in Secret Manager for the remote server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Please place your value assignments for development here!!\n",
    "## This cell will be turned off in production and Engineering will set to pull form the configuration application instead\n",
    "#*****************************\n",
    "#This is an example of how we are going to go about this for now \n",
    "transform = Transform()\n",
    "transform.remote_path = \"/home/bi/SpecilatyAnalytics\"\n",
    "#transform.prefix = \"IPF_PAT_20190404\"\n",
    "transform.prefix = \"IPF_PAT_20190\"\n",
    "transform.secret_name = \"bi\"\n",
    "transform.secret_type_of = \"FTP\"\n",
    "#****************************\n",
    "# This is a more abstract example\n",
    "# transform = Transform()\n",
    "# transform.remote_path = \"/test/\"\n",
    "# transform.prefix = \"important_file_\"\n",
    "# transform.secret_name = \"dev_sftp\"\n",
    "# transform.secret_type_of = \"FTP\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description\n",
    "What does this transformation do? be specific.\n",
    "\n",
    "![what does your transform do](assets/what.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This transform gets raw files from the client's remote server and places them in our S3 Bucket. Configurations specify the remote path to the files and a prefix to filter the files by before fetching, as well as the secret name and secret type so it can get the connection info for the remote server out of Secrets Manager."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Setup important outside imports here! (pandas, etc)\n",
    "from core.helpers import file_mover\n",
    "from core.logging import get_logger\n",
    "from core import secret\n",
    "import os\n",
    "import tempfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-07-22 17:43:27,526 - core.secret.Secret - DEBUG - Secret idenditifier dev/FTP/bi/read.\n",
      "2019-07-22 17:43:27,704 - core.helpers.file_mover.FileMover - DEBUG - Connecting to host: 192.168.201.202 on port: 22\n",
      "2019-07-22 17:43:27,722 - paramiko.transport - INFO - Connected (version 1.99, client OpenSSH_3.9p1)\n",
      "2019-07-22 17:43:27,847 - paramiko.transport - INFO - Authentication (password) successful!\n",
      "2019-07-22 17:43:27,896 - paramiko.transport.sftp - INFO - [chan 0] Opened sftp connection (server version 3)\n",
      "2019-07-22 17:43:27,991 - paramiko.transport.sftp - INFO - [chan 0] sftp session closed.\n",
      "REMOTE FILE:  1532701309\n",
      "2019-07-22 17:43:27,996 - core.helpers.file_mover.FileMover - DEBUG - Connecting to host: 192.168.201.202 on port: 22\n",
      "2019-07-22 17:43:28,013 - paramiko.transport - INFO - Connected (version 1.99, client OpenSSH_3.9p1)\n",
      "2019-07-22 17:43:28,182 - paramiko.transport - INFO - Authentication (password) successful!\n",
      "2019-07-22 17:43:28,232 - paramiko.transport.sftp - INFO - [chan 0] Opened sftp connection (server version 3)\n",
      "2019-07-22 17:43:28,234 - paramiko.transport.sftp - INFO - [chan 0] sftp session closed.\n",
      "REMOTE FILE:  1536944654\n",
      "2019-07-22 17:43:28,236 - core.helpers.file_mover.FileMover - DEBUG - Connecting to host: 192.168.201.202 on port: 22\n",
      "2019-07-22 17:43:28,253 - paramiko.transport - INFO - Connected (version 1.99, client OpenSSH_3.9p1)\n",
      "2019-07-22 17:43:28,408 - paramiko.transport - INFO - Authentication (password) successful!\n",
      "2019-07-22 17:43:28,457 - paramiko.transport.sftp - INFO - [chan 0] Opened sftp connection (server version 3)\n",
      "2019-07-22 17:43:28,459 - paramiko.transport.sftp - INFO - [chan 0] sftp session closed.\n",
      "REMOTE FILE:  1545407169\n",
      "2019-07-22 17:43:28,461 - core.helpers.file_mover.FileMover - DEBUG - Connecting to host: 192.168.201.202 on port: 22\n",
      "2019-07-22 17:43:28,481 - paramiko.transport - INFO - Connected (version 1.99, client OpenSSH_3.9p1)\n",
      "2019-07-22 17:43:28,617 - paramiko.transport - INFO - Authentication (password) successful!\n",
      "2019-07-22 17:43:28,668 - paramiko.transport.sftp - INFO - [chan 0] Opened sftp connection (server version 3)\n",
      "2019-07-22 17:43:28,671 - paramiko.transport.sftp - INFO - [chan 0] sftp session closed.\n",
      "REMOTE FILE:  1520006938\n",
      "2019-07-22 17:43:28,676 - core.helpers.file_mover.FileMover - DEBUG - Connecting to host: 192.168.201.202 on port: 22\n",
      "2019-07-22 17:43:28,693 - paramiko.transport - INFO - Connected (version 1.99, client OpenSSH_3.9p1)\n",
      "2019-07-22 17:43:28,831 - paramiko.transport - INFO - Authentication (password) successful!\n",
      "2019-07-22 17:43:28,878 - paramiko.transport.sftp - INFO - [chan 0] Opened sftp connection (server version 3)\n",
      "2019-07-22 17:43:28,880 - paramiko.transport.sftp - INFO - [chan 0] sftp session closed.\n",
      "REMOTE FILE:  1549033183\n",
      "2019-07-22 17:43:28,881 - core.helpers.file_mover.FileMover - DEBUG - Connecting to host: 192.168.201.202 on port: 22\n",
      "2019-07-22 17:43:28,903 - paramiko.transport - INFO - Connected (version 1.99, client OpenSSH_3.9p1)\n",
      "2019-07-22 17:43:29,032 - paramiko.transport - INFO - Authentication (password) successful!\n",
      "2019-07-22 17:43:29,080 - paramiko.transport.sftp - INFO - [chan 0] Opened sftp connection (server version 3)\n",
      "2019-07-22 17:43:44,557 - paramiko.transport.sftp - INFO - [chan 0] sftp session closed.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-42868100f541>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0mremote_path\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mextract\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mremote_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m             \u001b[0mremote_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mremote_file\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m             \u001b[0msecret\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msource_secret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m         )\n\u001b[1;32m     39\u001b[0m         \u001b[0;31m# Once the local file has been transferred, check if it needs to be pushed to s3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/src/app/core/helpers/file_mover.py\u001b[0m in \u001b[0;36mget_file\u001b[0;34m(tmp_dir, prefix, remote_path, remote_file, secret)\u001b[0m\n\u001b[1;32m     98\u001b[0m             \u001b[0mlocal_file_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_file_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m             \u001b[0mfm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_raw_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mremote_file_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlocal_file_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtmp_dir\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprefix\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremote_path\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msecret\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mSecret\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/src/app/core/helpers/file_mover.py\u001b[0m in \u001b[0;36mget_raw_file\u001b[0;34m(self, remote_path, local_path)\u001b[0m\n\u001b[1;32m     46\u001b[0m                 \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlocal\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m                     \u001b[0;32mfor\u001b[0m \u001b[0mline\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mremote\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m                         \u001b[0mlocal\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/paramiko/file.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    123\u001b[0m             \u001b[0;34m:\u001b[0m\u001b[0mreturns\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0ma\u001b[0m \u001b[0mline\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;31m`\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mread\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    124\u001b[0m             \"\"\"\n\u001b[0;32m--> 125\u001b[0;31m             \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreadline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    126\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mline\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/paramiko/file.py\u001b[0m in \u001b[0;36mreadline\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    289\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m                 \u001b[0mnew_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    292\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mEOFError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    293\u001b[0m                 \u001b[0mnew_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/paramiko/sftp_file.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(self, size)\u001b[0m\n\u001b[1;32m    184\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m         t, msg = self.sftp._request(\n\u001b[0;32m--> 186\u001b[0;31m             \u001b[0mCMD_READ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_realpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    187\u001b[0m         )\n\u001b[1;32m    188\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mCMD_DATA\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/paramiko/sftp_client.py\u001b[0m in \u001b[0;36m_request\u001b[0;34m(self, t, *arg)\u001b[0m\n\u001b[1;32m    811\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[0mnum\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_async_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 813\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    814\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    815\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_async_request\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfileobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/paramiko/sftp_client.py\u001b[0m in \u001b[0;36m_read_response\u001b[0;34m(self, waitfor)\u001b[0m\n\u001b[1;32m    841\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    842\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 843\u001b[0;31m                 \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_packet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    844\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mEOFError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mSSHException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Server connection dropped: {}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/paramiko/sftp.py\u001b[0m in \u001b[0;36m_read_packet\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    199\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_read_packet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read_all\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m         \u001b[0;31m# most sftp servers won't accept packets larger than about 32k, so\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m         \u001b[0;31m# anything with the high byte set (> 16MB) is just garbage.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/paramiko/sftp.py\u001b[0m in \u001b[0;36m_read_all\u001b[0;34m(self, n)\u001b[0m\n\u001b[1;32m    183\u001b[0m                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    184\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 185\u001b[0;31m                 \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/paramiko/channel.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self, nbytes)\u001b[0m\n\u001b[1;32m    697\u001b[0m         \"\"\"\n\u001b[1;32m    698\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0min_buffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mPipeTimeout\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    701\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0msocket\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/paramiko/buffered_pipe.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nbytes, timeout)\u001b[0m\n\u001b[1;32m    158\u001b[0m                 \u001b[0;32mwhile\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_closed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m                     \u001b[0mthen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 160\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    161\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m                         \u001b[0mtimeout\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mthen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    293\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "### Setup your transform dataclass object\n",
    "extract = transform\n",
    "logger = get_logger(f\"core.transforms.{transform.state}.{transform.name}\")\n",
    "\n",
    "### Use the variables above to execute your transformation. the final output needs to be a variable named final_dataframe\n",
    "def file_needs_update(output_contract: RawContract,local_file_path: str,local_file_modified_time: str)-> bool:\n",
    "        \"\"\" Check if file needs to be pushed\n",
    "            File is only considered to need to be pushed if it does not exist or has been modified since last push\n",
    "        \"\"\"\n",
    "        try:\n",
    "            s3_last_modified = output_contract.get_raw_file_metadata(local_file_path)['source_modified_time']\n",
    "            logger.info(f\"File last modified on S3 at {s3_last_modified}\")\n",
    "            logger.info(f\"File last modified on SFTP at {local_file_modified_time}\")\n",
    "            if (float(s3_last_modified) < float(local_file_modified_time)):\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "        except KeyError as e:\n",
    "            logger.info(f\"File not found on S3, uploading.\")\n",
    "            return True\n",
    "\n",
    "source_secret = secret.Secret(name=extract.secret_name, type_of=extract.secret_type_of, mode=\"read\")\n",
    "\n",
    "# Get list of remote files\n",
    "remote_files = file_mover.list_remote_files(extract.remote_path, secret=source_secret)\n",
    "\n",
    "# Loop through each remote file and get/move to local\n",
    "with tempfile.TemporaryDirectory() as tmp_dir:\n",
    "    for remote_file in remote_files:\n",
    "        file_mover.get_file(\n",
    "            tmp_dir=tmp_dir,\n",
    "            prefix=extract.prefix,\n",
    "            remote_path=extract.remote_path,\n",
    "            remote_file=remote_file,\n",
    "            secret=source_secret\n",
    "        )\n",
    "        # Once the local file has been transferred, check if it needs to be pushed to s3\n",
    "        # TODO: Clear temp dir after each file goes to s3\n",
    "        # TODO: Validate timestamp against sftp server file to avoid sftp of files again \n",
    "        # TODO: Try using Python's get file method to transfer files in file_mover instead of moving them line by line\n",
    "        for local_file in os.listdir(f\"{tmp_dir}\"):\n",
    "            if remote_file.filename in local_file:\n",
    "                local_file_path = os.path.join(tmp_dir,local_file)\n",
    "                local_file_modified_time = os.stat(local_file_path).st_mtime\n",
    "\n",
    "                if (file_needs_update(output_contract=extract.publish_contract,\n",
    "                                        local_file_path=local_file_path,\n",
    "                                        local_file_modified_time=local_file_modified_time\n",
    "                                        )):\n",
    "                    extract.publish_contract.publish_raw_file(local_file_path)\n",
    "\n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Publish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "***** This does not apply to extract *****\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
