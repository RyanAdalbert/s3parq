{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-15 20:31:58,475 - core.helpers.session_helper.SessionHelper - INFO - Creating session for dev environment...\n",
      "2019-08-15 20:31:58,500 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating administrator mocks.\n",
      "2019-08-15 20:31:58,581 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating administrator mocks.\n",
      "2019-08-15 20:31:58,583 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating pharmaceutical company mocks.\n",
      "2019-08-15 20:31:58,591 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating pharmaceutical company mocks.\n",
      "2019-08-15 20:31:58,592 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating brand mocks.\n",
      "2019-08-15 20:31:58,597 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating brand mocks.\n",
      "2019-08-15 20:31:58,598 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating segment mocks.\n",
      "2019-08-15 20:31:58,605 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating segment mocks.\n",
      "2019-08-15 20:31:58,606 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating pipeline type mocks.\n",
      "2019-08-15 20:31:58,612 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating pipeline type mocks.\n",
      "2019-08-15 20:31:58,614 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating pipeline mocks.\n",
      "2019-08-15 20:31:58,621 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating pipeline mocks.\n",
      "2019-08-15 20:31:58,622 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating pipeline state type mocks.\n",
      "2019-08-15 20:31:58,627 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating pipeline state type mocks.\n",
      "2019-08-15 20:31:58,631 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating pipeline state mocks.\n",
      "2019-08-15 20:31:58,641 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating pipeline state mocks.\n",
      "2019-08-15 20:31:58,644 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating tag mocks.\n",
      "2019-08-15 20:31:58,650 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating tag mocks.\n",
      "2019-08-15 20:31:58,652 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating transformation_template mocks.\n",
      "2019-08-15 20:31:58,656 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating transformation_template mocks.\n",
      "2019-08-15 20:31:58,657 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating bridge table mocks for transformation_templates <=> tags.\n",
      "2019-08-15 20:31:58,663 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating transformation_templates_tags mocks.\n",
      "2019-08-15 20:31:58,665 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating transformation mocks.\n",
      "2019-08-15 20:31:58,672 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating transformation mocks.\n",
      "2019-08-15 20:31:58,673 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating transformation_variables mocks\n",
      "2019-08-15 20:31:58,683 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating transformation_variables mocks.\n",
      "2019-08-15 20:31:58,684 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating run_events mocks.\n",
      "2019-08-15 20:31:58,688 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating run_events mocks.\n",
      "2019-08-15 20:31:58,689 - core.helpers.session_helper.SessionHelper - INFO - Done. Created dev session with mock data.\n"
     ]
    }
   ],
   "source": [
    "from core.helpers.session_helper import SessionHelper\n",
    "session = SessionHelper().session\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "************ CONFIGURATION - PLEASE TOUCH **************\n",
    "Pipeline Builder configuration: creates configurations from variables specified here!!\n",
    "This cell will be off in production as configurations will come from the configuration postgres DB.\n",
    "\"\"\"\n",
    "# config vars: this dataset\n",
    "config_pharma = \"sun\" # the pharmaceutical company which owns {brand}\n",
    "config_brand = \"ilumya\" # the brand this pipeline operates on\n",
    "config_state = \"enrich\" # the state this transform runs in\n",
    "config_name = \"accredo_cancel_before_active\" # the name of this transform, which is the name of this notebook without .ipynb\n",
    "\n",
    "# input vars: dataset to fetch. Recall that a contract published to S3 has a key format branch/pharma/brand/state/name\n",
    "input_pharma = \"sun\"\n",
    "input_brand = \"ilumya\"\n",
    "input_state = \"ingest\"\n",
    "input_name = \"symphony_health_association_ingest_column_mapping\"\n",
    "input_branch = \"sun-extract-validation\" # if None, input_branch is automagically set to your working branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-15 20:31:59,380 - core.logging - DEBUG - Adding/getting mocks for specified configurations...\n",
      "2019-08-15 20:31:59,411 - core.logging - DEBUG - Done. Creating mock run event and committing results to configuration mocker.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "************ SETUP - DON'T TOUCH **************\n",
    "Populating config mocker based on config parameters...\n",
    "\"\"\"\n",
    "import core.helpers.pipeline_builder as builder\n",
    "\n",
    "ids = builder.build(config_pharma, config_brand, config_state, config_name, session)\n",
    "transform_id = ids[0]\n",
    "run_id = ids[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "************ SETUP - DON'T TOUCH **************\n",
    "This section imports data from the configuration database\n",
    "and should not need to be altered or otherwise messed with. \n",
    "~~These are not the droids you are looking for~~\n",
    "\"\"\"\n",
    "from core.constants import BRANCH_NAME, ENV_BUCKET\n",
    "from core.models.configuration import Transformation\n",
    "from dataclasses import dataclass\n",
    "from core.dataset_contract import DatasetContract\n",
    "\n",
    "db_transform = session.query(Transformation).filter(Transformation.id == transform_id).one()\n",
    "\n",
    "@dataclass\n",
    "class DbTransform:\n",
    "    id: int = db_transform.id ## the instance id of the transform in the config app\n",
    "    name: str = db_transform.transformation_template.name ## the transform name in the config app\n",
    "    state: str = db_transform.pipeline_state.pipeline_state_type.name ## the pipeline state, one of raw, ingest, master, enhance, enrich, metrics, dimensional\n",
    "    branch:str = BRANCH_NAME ## the git branch for this execution \n",
    "    brand: str = db_transform.pipeline_state.pipeline.brand.name ## the pharma brand name\n",
    "    pharmaceutical_company: str = db_transform.pipeline_state.pipeline.brand.pharmaceutical_company.name # the pharma company name\n",
    "    publish_contract: DatasetContract = DatasetContract(branch=BRANCH_NAME,\n",
    "                            state=db_transform.pipeline_state.pipeline_state_type.name,\n",
    "                            parent=db_transform.pipeline_state.pipeline.brand.pharmaceutical_company.name,\n",
    "                            child=db_transform.pipeline_state.pipeline.brand.name,\n",
    "                            dataset=db_transform.transformation_template.name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CORE Cartridge Notebook::accredo_cancel_before_active\n",
    "![CORE Logo](assets/coreLogo.png) \n",
    "\n",
    "---\n",
    "## Keep in Mind\n",
    "Good Transforms Are...\n",
    "- **singular in purpose:** good transforms do one and only one thing, and handle all known cases for that thing. \n",
    "- **repeatable:** transforms should be written in a way that they can be run against the same dataset an infinate number of times and get the same result every time. \n",
    "- **easy to read:** 99 times out of 100, readable, clear code that runs a little slower is more valuable than a mess that runs quickly. \n",
    "- **No 'magic numbers':** if a variable or function is not instantly obvious as to what it is or does, without context, maybe consider renaming it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow - how to use this notebook to make science\n",
    "#### Data Science\n",
    "1. **Document your transform.** Fill out the _description_ cell below describing what it is this transform does; this will appear in the configuration application where Ops will create, configure and update pipelines. \n",
    "1. **Define your config object.** Fill out the _configuration_ cell below the commented-out guide to define the variables you want ops to set in the configuration application (these will populate here for every pipeline). \n",
    "2. **Build your transformation logic.** Use the transformation cell to do that magic that you do. \n",
    "![caution](assets/cautionTape.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "********* VARIABLES - PLEASE TOUCH ********* \n",
    "This section defines what you expect to get from the configuration application \n",
    "in a single \"transform\" object. Define the vars you need here, and comment inline to the right of them \n",
    "for all-in-one documentation. \n",
    "Engineering will build a production \"transform\" object for every pipeline that matches what you define here.\n",
    "\n",
    "@@@ FORMAT OF THE DATA CLASS IS: @@@ \n",
    "\n",
    "<variable_name>: <data_type> #<comment explaining what the value is to future us>\n",
    "\n",
    "e.g.\n",
    "\n",
    "class Transform(DbTransform):\n",
    "    some_ratio: float\n",
    "    site_name: str\n",
    "\n",
    "~~These ARE the droids you are looking for~~\n",
    "\"\"\"\n",
    "\n",
    "class Transform(DbTransform):\n",
    "    '''\n",
    "    YOUR properties go here!!\n",
    "    Variable properties should be assigned to the exact name of\n",
    "    the transformation as it appears in the Jupyter notebook filename.\n",
    "    '''\n",
    "    # Column headers\n",
    "    status_date: str = 'status_date'# Status date column\n",
    "    ref_date: str = 'rec_date'# Referral date column\n",
    "    patient: str = 'msa_patient_id' # Patient ID column\n",
    "    pharm: str = 'pharm_code' # Pharmacy Name column\n",
    "    product: str = 'medication' # Medication Name column\n",
    "    status: str = 'status_code' # Status column\n",
    "    substatus: str = 'sub_status' # Substatus column\n",
    "    ic_status: str = 'integrichain_status' # IntegriChain Status column\n",
    "    ic_substatus: str = 'integrichain_sub_status' # IntegriChain Substatus column\n",
    "    pjh: str = 'Patient_Journey_Hierarchy' # Patient Journey Hierarchy column\n",
    "    brand: str = 'brand' # Brand column (medication without strength)\n",
    "        \n",
    "    # Possible status values\n",
    "    pending: str = 'PENDING' # Pending status 'PENDING'\n",
    "    active: str = 'ACTIVE' # Active status 'ACTIVE'\n",
    "    cancelled: str = 'CANCELLED' # Cancelled status 'CANCELLED'\n",
    "    discontinued: str = 'DISCONTINUED' # Discontinued status 'DISCONTINUED'\n",
    "        \n",
    "    # Possible substatus values\n",
    "    pending_new: str = 'NEW' # New substatus when status is 'PENDING'\n",
    "    active_shipped: str = 'SHIPMENT'# Shipment substatus when status is 'ACTIVE'\n",
    "    \n",
    "    # Possible PJH values\n",
    "    bvpa: str = 'BV/PA' # BV/PA pjh\n",
    "    intake: str = 'Intake' # Intake pjh\n",
    "    fulfillment: str = 'Fulfillment' # Fulfillment pjh\n",
    "    transfer: str = 'Transferred' # Transferred pjh\n",
    "    payer: str = 'Payer' # Payer pjh\n",
    "    no_clarity: str = 'NO STATUS CLARITY' # Final result of enrichment\n",
    "        \n",
    "    # Pharmacy in question\n",
    "    accredo: str = 'ACCREDO'\n",
    "\n",
    "transform = Transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Please place your value assignments for development here!!\n",
    "## This cell will be turned off in production and Engineering will set to pull from the configuration application instead\n",
    "## For the last example, this could look like...\n",
    "## transform.some_ratio = 0.6\n",
    "## transform.site_name = \"WALGREENS\"\n",
    "\n",
    "# Vars\n",
    "patient = transform.patient\n",
    "pharm = transform.pharm\n",
    "product = transform.product\n",
    "ref_date = transform.ref_date\n",
    "status_date = transform.status_date\n",
    "status = transform.status\n",
    "substatus = transform.substatus\n",
    "ic_status = transform.ic_status\n",
    "ic_substatus = transform.ic_substatus\n",
    "pjh = transform.pjh\n",
    "brand = transform.brand\n",
    "\n",
    "# Values\n",
    "pending = transform.pending\n",
    "active = transform.active\n",
    "cancelled = transform.cancelled\n",
    "discontinued = transform.discontinued\n",
    "pending_new = transform.pending_new\n",
    "active_shipped = transform.active_shipped\n",
    "bvpa = transform.bvpa\n",
    "intake = transform.intake\n",
    "fulfillment = transform.fulfillment\n",
    "transfer = transform.transfer\n",
    "payer = transform.payer\n",
    "no_clarity = transform.no_clarity\n",
    "accredo = transform.accredo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description\n",
    "What does this transformation do? be specific.\n",
    "\n",
    "![what does your transform do](assets/what.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-15 20:31:59,652 - core.dataset_contract.DatasetContract - INFO - Fetching dataframe from s3 location s3://ichain-dev/sun-extract-validation/sun/ilumya/ingest/symphony_health_association_ingest_column_mapping.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "************ FETCH DATA - TOUCH, BUT CAREFULLY **************\n",
    "This cell will be turned off in production, as the input_contract will be handled by the pipeline.\n",
    "\"\"\"\n",
    "\n",
    "if not input_branch:\n",
    "    input_branch = BRANCH_NAME\n",
    "input_contract = DatasetContract(branch=input_branch, state=input_state, parent=input_pharma, child=input_brand, dataset=input_name)\n",
    "run_filter = []\n",
    "run_filter.append(dict(partition=\"__metadata_run_id\", comparison=\"==\", values=[3]))\n",
    "# IF YOU HAVE PUBLISHED DATA MULTIPLE TIMES, uncomment the above line and change the int to the run_id to fetch.\n",
    "# Otherwise, you will have duplicate values in your fetched dataset!\n",
    "final_dataframe = input_contract.fetch(filters=run_filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy ingested data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = final_dataframe.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Impute PJH and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This cell brings in the Patient Journey Hierarchy information from a local file.\n",
    "This is just a placeholder to ensure data processes work as expected until the\n",
    "true ingest data can be used.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "\n",
    "pd.options.display.max_columns=999\n",
    "\n",
    "os.chdir('{}'.format(os.path.expanduser('~')))\n",
    "status_config = pd.read_csv('status_mapping.csv')\n",
    "\n",
    "status_config = (\n",
    "    status_config\n",
    "    .assign(**{\n",
    "        status: lambda x:(\n",
    "            x['statusCode'].str.upper()\n",
    "        ),\n",
    "        substatus: lambda x:(\n",
    "            x['subStatus'].str.upper()\n",
    "        ),\n",
    "        ic_status: lambda x:(\n",
    "            x['integrichain_status'].str.upper()\n",
    "        ),\n",
    "        ic_substatus: lambda x:(\n",
    "            x['integrichain_sub_status'].str.upper()\n",
    "        ),\n",
    "        pjh: lambda x:(\n",
    "            x['Patient_Journey_Hierarchy'].str.upper()\n",
    "        )\n",
    "    })\n",
    "    .drop(columns=[\n",
    "        'statusCode',\n",
    "        'subStatus'\n",
    "    ])\n",
    ")\n",
    "\n",
    "df = (\n",
    "    df\n",
    "    .loc[:,\n",
    "        [ref_date,\n",
    "         patient,\n",
    "         pharm,\n",
    "         product,\n",
    "         status_date,\n",
    "         status,\n",
    "         substatus]\n",
    "        ]\n",
    "    .fillna('NONE')\n",
    "    .assign(**{\n",
    "        brand: lambda x:(\n",
    "            x[product].apply(lambda x: x.split()[0].strip())\n",
    "        ),\n",
    "        status: lambda x:(\n",
    "            x[status].str.upper()\n",
    "        ),\n",
    "        substatus: lambda x:(\n",
    "            x[substatus].str.upper()\n",
    "        )\n",
    "    })\n",
    "    .assign(**{\n",
    "        status_date: lambda x:(\n",
    "            pd.to_datetime(\n",
    "                x[status_date].str[:8].astype(str),\n",
    "                errors='coerce'\n",
    "        )),\n",
    "        ref_date: lambda x:(\n",
    "            pd.to_datetime(\n",
    "                x[ref_date].str[:8].astype(str),\n",
    "                errors='coerce'\n",
    "        )),\n",
    "        'min_status_date': lambda x:(\n",
    "            x.groupby([patient, pharm, brand])[status_date].transform(min)\n",
    "        )\n",
    "    })\n",
    "    .fillna(value={ref_date: 'min_status_date'})\n",
    "    .drop(columns=['min_status_date'])\n",
    "    .merge(status_config, how='left', on=[status, substatus])\n",
    "    .drop_duplicates()\n",
    "    .sort_values(\n",
    "        [patient, pharm, brand, status_date]\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort and reset index to join on later\n",
    "df = (\n",
    "    df\n",
    "    .sort_values([patient, pharm, brand, status_date, ref_date, status])\n",
    "    .reset_index(drop=False)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create secondary df to find the first active shipment date for\n",
    "# each patient journey\n",
    "min_shipped_df = (\n",
    "    df\n",
    "    .loc[\n",
    "        (df[ic_status] == active) &\n",
    "        (df[ic_substatus] == active_shipped)\n",
    "    ]\n",
    "    .groupby([patient, pharm, brand])\n",
    "    [status_date]\n",
    "    .min()\n",
    "    .reset_index()\n",
    "    .rename(columns={status_date: 'first_shipped_date'})\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Join to main df to get first active shipment date for every\n",
    "# patient that has one\n",
    "df = (\n",
    "    df\n",
    "    .merge(\n",
    "        min_shipped_df,\n",
    "        how='left'\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a column that can be grouped on later to determine the\n",
    "# first date where a desired care occurs\n",
    "df = (\n",
    "    df\n",
    "    .assign(status_spree=(\n",
    "    ~(\n",
    "        (df[patient].eq(df[patient].shift(1))) &\n",
    "        (df[pharm].eq(df[pharm].shift(1))) &\n",
    "        (df[brand].eq(df[brand].shift(1))) &\n",
    "        (df[ic_status].eq(df[ic_status].shift(1))) &\n",
    "        (df[ic_substatus].eq(df[ic_substatus].shift(1)))\n",
    "    )\n",
    "    ).cumsum())\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create column denoting the min status date of each spree\n",
    "df = (\n",
    "    df\n",
    "    .assign(min_status_date=lambda x:(\n",
    "        x.groupby('status_spree')[status_date].transform(min)\n",
    "    ))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bool column to denote row being right above active shipment row\n",
    "df = (\n",
    "    df\n",
    "    .assign(above_shipment_step=lambda x:(\n",
    "        (x[patient].eq(x[patient].shift(1))) &\n",
    "        (x[pharm].eq(x[pharm].shift(1))) &\n",
    "        (x[brand].eq(x[brand].shift(1))) &\n",
    "        (x[ic_status].shift(-1) == active) &\n",
    "        (x[ic_substatus].shift(-1) == active_shipped)\n",
    "    ))\n",
    ")\n",
    "\n",
    "# Pick out sprees that are above a shipment step\n",
    "above_shipment_series = df.groupby('status_spree').above_shipment_step.any()\n",
    "\n",
    "df = (\n",
    "    df\n",
    "    .assign(above_shipment=lambda x:(\n",
    "        x.status_spree.isin(above_shipment_series[above_shipment_series].index)\n",
    "    ))\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Denote how many days between min_status_date and first_shipped_date\n",
    "df = (\n",
    "    df\n",
    "    .assign(day_diff=(df['min_status_date'] - df['first_shipped_date']))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['index', 'rec_date', 'msa_patient_id', 'pharm_code', 'medication',\n",
       "       'status_date', 'status_code', 'sub_status', 'ilumya',\n",
       "       'integrichain_sub_status', 'integrichain_status',\n",
       "       'Patient_Journey_Hierarchy', 'first_shipped_date', 'status_spree',\n",
       "       'min_status_date', 'above_shipment_step', 'above_shipment', 'day_diff'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rec_date</th>\n",
       "      <th>msa_patient_id</th>\n",
       "      <th>pharm_code</th>\n",
       "      <th>ilumya</th>\n",
       "      <th>status_date</th>\n",
       "      <th>integrichain_status</th>\n",
       "      <th>integrichain_sub_status</th>\n",
       "      <th>Patient_Journey_Hierarchy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>150</th>\n",
       "      <td>2019-03-19 00:00:00</td>\n",
       "      <td>2140024</td>\n",
       "      <td>WAG</td>\n",
       "      <td>ILUMYA</td>\n",
       "      <td>2019-03-18</td>\n",
       "      <td>DISCONTINUED</td>\n",
       "      <td>PATIENT END</td>\n",
       "      <td>PATIENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>2018-12-07 00:00:00</td>\n",
       "      <td>2140025</td>\n",
       "      <td>BRV</td>\n",
       "      <td>ILUMYA</td>\n",
       "      <td>2018-12-06</td>\n",
       "      <td>DISCONTINUED</td>\n",
       "      <td>PRESCRIBER END</td>\n",
       "      <td>PROVIDER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>160</th>\n",
       "      <td>2019-02-22 00:00:00</td>\n",
       "      <td>2140025</td>\n",
       "      <td>BRV</td>\n",
       "      <td>ILUMYA</td>\n",
       "      <td>2019-02-21</td>\n",
       "      <td>DISCONTINUED</td>\n",
       "      <td>INSURANCE DENIED</td>\n",
       "      <td>PAYER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>161</th>\n",
       "      <td>2019-02-28 00:00:00</td>\n",
       "      <td>2140025</td>\n",
       "      <td>BRV</td>\n",
       "      <td>ILUMYA</td>\n",
       "      <td>2019-02-27</td>\n",
       "      <td>DISCONTINUED</td>\n",
       "      <td>INSURANCE DENIED</td>\n",
       "      <td>PAYER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>2019-02-26 00:00:00</td>\n",
       "      <td>2190002</td>\n",
       "      <td>WAG</td>\n",
       "      <td>ILUMYA</td>\n",
       "      <td>2019-02-25</td>\n",
       "      <td>DISCONTINUED</td>\n",
       "      <td>PATIENT END</td>\n",
       "      <td>PATIENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>2019-02-27 00:00:00</td>\n",
       "      <td>2190002</td>\n",
       "      <td>WAG</td>\n",
       "      <td>ILUMYA</td>\n",
       "      <td>2019-02-26</td>\n",
       "      <td>DISCONTINUED</td>\n",
       "      <td>PATIENT END</td>\n",
       "      <td>PATIENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>2019-03-06 00:00:00</td>\n",
       "      <td>2220002</td>\n",
       "      <td>WAG</td>\n",
       "      <td>ILUMYA</td>\n",
       "      <td>2019-03-05</td>\n",
       "      <td>DISCONTINUED</td>\n",
       "      <td>PATIENT RESPONSE</td>\n",
       "      <td>PATIENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>385</th>\n",
       "      <td>2019-05-15 00:00:00</td>\n",
       "      <td>2220004</td>\n",
       "      <td>BRV</td>\n",
       "      <td>ILUMYA</td>\n",
       "      <td>2019-05-14</td>\n",
       "      <td>DISCONTINUED</td>\n",
       "      <td>PATIENT RESPONSE</td>\n",
       "      <td>PATIENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>616</th>\n",
       "      <td>2019-01-11 00:00:00</td>\n",
       "      <td>2380000</td>\n",
       "      <td>BRV</td>\n",
       "      <td>ODOMZO</td>\n",
       "      <td>2019-01-10</td>\n",
       "      <td>DISCONTINUED</td>\n",
       "      <td>INSURANCE DENIED</td>\n",
       "      <td>PAYER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>2019-01-17 00:00:00</td>\n",
       "      <td>2380001</td>\n",
       "      <td>BRV</td>\n",
       "      <td>ODOMZO</td>\n",
       "      <td>2019-01-16</td>\n",
       "      <td>DISCONTINUED</td>\n",
       "      <td>PATIENT RESPONSE</td>\n",
       "      <td>PATIENT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                rec_date msa_patient_id pharm_code  ilumya status_date  \\\n",
       "150  2019-03-19 00:00:00        2140024        WAG  ILUMYA  2019-03-18   \n",
       "157  2018-12-07 00:00:00        2140025        BRV  ILUMYA  2018-12-06   \n",
       "160  2019-02-22 00:00:00        2140025        BRV  ILUMYA  2019-02-21   \n",
       "161  2019-02-28 00:00:00        2140025        BRV  ILUMYA  2019-02-27   \n",
       "334  2019-02-26 00:00:00        2190002        WAG  ILUMYA  2019-02-25   \n",
       "335  2019-02-27 00:00:00        2190002        WAG  ILUMYA  2019-02-26   \n",
       "377  2019-03-06 00:00:00        2220002        WAG  ILUMYA  2019-03-05   \n",
       "385  2019-05-15 00:00:00        2220004        BRV  ILUMYA  2019-05-14   \n",
       "616  2019-01-11 00:00:00        2380000        BRV  ODOMZO  2019-01-10   \n",
       "638  2019-01-17 00:00:00        2380001        BRV  ODOMZO  2019-01-16   \n",
       "\n",
       "    integrichain_status integrichain_sub_status Patient_Journey_Hierarchy  \n",
       "150        DISCONTINUED             PATIENT END                   PATIENT  \n",
       "157        DISCONTINUED          PRESCRIBER END                  PROVIDER  \n",
       "160        DISCONTINUED        INSURANCE DENIED                     PAYER  \n",
       "161        DISCONTINUED        INSURANCE DENIED                     PAYER  \n",
       "334        DISCONTINUED             PATIENT END                   PATIENT  \n",
       "335        DISCONTINUED             PATIENT END                   PATIENT  \n",
       "377        DISCONTINUED        PATIENT RESPONSE                   PATIENT  \n",
       "385        DISCONTINUED        PATIENT RESPONSE                   PATIENT  \n",
       "616        DISCONTINUED        INSURANCE DENIED                     PAYER  \n",
       "638        DISCONTINUED        PATIENT RESPONSE                   PATIENT  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.loc[\n",
    "    (df.day_diff > np.timedelta64(2, 'D')) &\n",
    "    (df.above_shipment == True) &\n",
    "    (\n",
    "        (df[ic_status].isin([cancelled, discontinued])) |\n",
    "        (\n",
    "            (df[ic_status] == pending) &\n",
    "            (df[ic_substatus] == pending_new)\n",
    "        )\n",
    "    )\n",
    "][[ref_date, patient, pharm, brand, status_date, ic_status, ic_substatus, pjh]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rec_date</th>\n",
       "      <th>msa_patient_id</th>\n",
       "      <th>pharm_code</th>\n",
       "      <th>ilumya</th>\n",
       "      <th>status_date</th>\n",
       "      <th>integrichain_status</th>\n",
       "      <th>integrichain_sub_status</th>\n",
       "      <th>Patient_Journey_Hierarchy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>633</th>\n",
       "      <td>2018-11-13 00:00:00</td>\n",
       "      <td>2380001</td>\n",
       "      <td>BRV</td>\n",
       "      <td>ODOMZO</td>\n",
       "      <td>2018-11-12</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>SHIPMENT</td>\n",
       "      <td>FULFILLMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>634</th>\n",
       "      <td>2018-11-28 00:00:00</td>\n",
       "      <td>2380001</td>\n",
       "      <td>BRV</td>\n",
       "      <td>ODOMZO</td>\n",
       "      <td>2018-11-27</td>\n",
       "      <td>DISCONTINUED</td>\n",
       "      <td>INSURANCE DENIED</td>\n",
       "      <td>PAYER</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>635</th>\n",
       "      <td>2018-12-06 00:00:00</td>\n",
       "      <td>2380001</td>\n",
       "      <td>BRV</td>\n",
       "      <td>ODOMZO</td>\n",
       "      <td>2018-12-05</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>HOLD RTS</td>\n",
       "      <td>FULFILLMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>636</th>\n",
       "      <td>2018-12-12 00:00:00</td>\n",
       "      <td>2380001</td>\n",
       "      <td>BRV</td>\n",
       "      <td>ODOMZO</td>\n",
       "      <td>2018-12-11</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>SHIPMENT</td>\n",
       "      <td>FULFILLMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>637</th>\n",
       "      <td>2019-01-04 00:00:00</td>\n",
       "      <td>2380001</td>\n",
       "      <td>BRV</td>\n",
       "      <td>ODOMZO</td>\n",
       "      <td>2019-01-03</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>HOLD RTS</td>\n",
       "      <td>FULFILLMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>638</th>\n",
       "      <td>2019-01-17 00:00:00</td>\n",
       "      <td>2380001</td>\n",
       "      <td>BRV</td>\n",
       "      <td>ODOMZO</td>\n",
       "      <td>2019-01-16</td>\n",
       "      <td>DISCONTINUED</td>\n",
       "      <td>PATIENT RESPONSE</td>\n",
       "      <td>PATIENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>639</th>\n",
       "      <td>2019-01-19 00:00:00</td>\n",
       "      <td>2380001</td>\n",
       "      <td>BRV</td>\n",
       "      <td>ODOMZO</td>\n",
       "      <td>2019-01-18</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>SHIPMENT</td>\n",
       "      <td>FULFILLMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>640</th>\n",
       "      <td>2019-02-08 00:00:00</td>\n",
       "      <td>2380001</td>\n",
       "      <td>BRV</td>\n",
       "      <td>ODOMZO</td>\n",
       "      <td>2019-02-07</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>HOLD RTS</td>\n",
       "      <td>FULFILLMENT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>641</th>\n",
       "      <td>2019-04-04 00:00:00</td>\n",
       "      <td>2380001</td>\n",
       "      <td>BRV</td>\n",
       "      <td>ODOMZO</td>\n",
       "      <td>2019-04-03</td>\n",
       "      <td>DISCONTINUED</td>\n",
       "      <td>PATIENT RESPONSE</td>\n",
       "      <td>PATIENT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                rec_date msa_patient_id pharm_code  ilumya status_date  \\\n",
       "633  2018-11-13 00:00:00        2380001        BRV  ODOMZO  2018-11-12   \n",
       "634  2018-11-28 00:00:00        2380001        BRV  ODOMZO  2018-11-27   \n",
       "635  2018-12-06 00:00:00        2380001        BRV  ODOMZO  2018-12-05   \n",
       "636  2018-12-12 00:00:00        2380001        BRV  ODOMZO  2018-12-11   \n",
       "637  2019-01-04 00:00:00        2380001        BRV  ODOMZO  2019-01-03   \n",
       "638  2019-01-17 00:00:00        2380001        BRV  ODOMZO  2019-01-16   \n",
       "639  2019-01-19 00:00:00        2380001        BRV  ODOMZO  2019-01-18   \n",
       "640  2019-02-08 00:00:00        2380001        BRV  ODOMZO  2019-02-07   \n",
       "641  2019-04-04 00:00:00        2380001        BRV  ODOMZO  2019-04-03   \n",
       "\n",
       "    integrichain_status integrichain_sub_status Patient_Journey_Hierarchy  \n",
       "633              ACTIVE                SHIPMENT               FULFILLMENT  \n",
       "634        DISCONTINUED        INSURANCE DENIED                     PAYER  \n",
       "635              ACTIVE                HOLD RTS               FULFILLMENT  \n",
       "636              ACTIVE                SHIPMENT               FULFILLMENT  \n",
       "637              ACTIVE                HOLD RTS               FULFILLMENT  \n",
       "638        DISCONTINUED        PATIENT RESPONSE                   PATIENT  \n",
       "639              ACTIVE                SHIPMENT               FULFILLMENT  \n",
       "640              ACTIVE                HOLD RTS               FULFILLMENT  \n",
       "641        DISCONTINUED        PATIENT RESPONSE                   PATIENT  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[ref_date, patient, pharm, brand, status_date, ic_status, ic_substatus, pjh]][df[patient] == '2380001']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IMPACT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df[pjh] == no_clarity]) / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[df[pjh] == no_clarity])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataframe = (\n",
    "    df\n",
    "    .set_index('index')\n",
    "    .sort_index()\n",
    "    .drop(columns=['max_status_date', 'last_status', 'last_substatus', 'day_difference', 'prev_status', 'prev_substatus', 'prev_check'])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Use the variables above to execute your transformation. the final output needs to be a variable named final_dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Publish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## that's it - just provide the final dataframe to the var final_dataframe and we take it from there\n",
    "transform.publish_contract.publish(final_dataframe, run_id, session)\n",
    "session.close()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
