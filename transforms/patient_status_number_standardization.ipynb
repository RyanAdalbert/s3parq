{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_id = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-09 15:09:43,409 - core.helpers.session_helper.SessionHelper - INFO - Creating session for dev environment...\n",
      "2019-08-09 15:09:43,411 - core.helpers.session_helper.SessionHelper - INFO - Forcing postgres instead of configuration mocker...\n",
      "2019-08-09 15:09:43,415 - core.helpers.session_helper.SessionHelper - INFO - Done. Created dev session.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "************ SETUP - DON'T TOUCH **************\n",
    "This section imports data from the configuration database\n",
    "and should not need to be altered, molested or otherwise messed with. \n",
    "~~These are not the droids you are looking for~~\n",
    "\"\"\"\n",
    "from core.constants import BRANCH_NAME, ENV_BUCKET\n",
    "from core.helpers.session_helper import SessionHelper\n",
    "from core.models.configuration import Transformation\n",
    "from dataclasses import dataclass\n",
    "from core.dataset_contract import DatasetContract\n",
    "\n",
    "session = SessionHelper().session\n",
    "db_transform = session.query(Transformation).filter(Transformation.id == transform_id).one()\n",
    "\n",
    "@dataclass\n",
    "class DbTransform:\n",
    "    id: int = db_transform.id ## the instance id of the transform in the config app\n",
    "    name: str = db_transform.transformation_template.name ## the transform name in the config app\n",
    "    state: str = db_transform.pipeline_state.pipeline_state_type.name ## the pipeline state, one of raw, ingest, master, enhance, enrich, metrics, dimensional\n",
    "    branch:str = BRANCH_NAME ## the git branch for this execution \n",
    "    brand: str = db_transform.pipeline_state.pipeline.brand.name ## the pharma brand name\n",
    "    pharmaceutical_company: str = db_transform.pipeline_state.pipeline.brand.pharmaceutical_company.name # the pharma company name\n",
    "    publish_contract: DatasetContract = DatasetContract(branch=BRANCH_NAME,\n",
    "                            parent=db_transform.pipeline_state.pipeline.brand.pharmaceutical_company.name,\n",
    "                            child=db_transform.pipeline_state.pipeline.brand.name,\n",
    "                            state=db_transform.pipeline_state.pipeline_state_type.name,\n",
    "                            dataset=db_transform.transformation_template.name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CORE Cartridge Notebook :: symphony_health_association_refinement\n",
    "![CORE Logo](assets/coreLogo.png) \n",
    "\n",
    "---\n",
    "## Keep in Mind\n",
    "Good Transforms Are...\n",
    "- **singular in purpose:** good transforms do one and only one thing, and handle all known cases for that thing. \n",
    "- **repeatable:** transforms should be written in a way that they can be run against the same dataset an infinate number of times and get the same result every time. \n",
    "- **easy to read:** 99 times out of 100, readable, clear code that runs a little slower is more valuable than a mess that runs quickly. \n",
    "- **No 'magic numbers':** if a variable or function is not instantly obvious as to what it is or does, without context, maybe consider renaming it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow - how to use this notebook to make science\n",
    "#### Data Science\n",
    "1. **Document your transform.** Fill out the _description_ cell below describing what it is this transform does; this will appear in the configuration application where Ops will create, configure and update pipelines. \n",
    "1. **Define your config object.** Fill out the _configuration_ cell below the commented-out guide to define the variables you want ops to set in the configuration application (these will populate here for every pipeline). \n",
    "2. **Build your transformation logic.** Use the transformation cell to do that magic that you do. \n",
    "![caution](assets/cautionTape.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "********* CONFIGURATION - PLEASE TOUCH ********* \n",
    "This section defines what you expect to get from the configuration application \n",
    "in a single \"transform\" object. Define the vars you need here, and comment inline to the right of them \n",
    "for all-in-one documentation. \n",
    "Engineering will build a production \"transform\" object for every pipeline that matches what you define here.\n",
    "\n",
    "@@@ FORMAT OF THE DATA CLASS IS: @@@ \n",
    "\n",
    "<value_name>: <data_type> #<comment explaining what the value is to future us>\n",
    "\n",
    "~~These ARE the droids you are looking for~~\n",
    "\"\"\"\n",
    "\n",
    "class Transform(DbTransform):\n",
    "        ## YOUR properties go here!!\n",
    "        ingest_source_transform: str = db_transform.variables.ingest_source_transform # The name of the dataset to pull from"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.logging import get_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Transform' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-844f3c6933b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtransform\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mlogger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_logger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"core.transforms.{transform.state}.{transform.name}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Transform' is not defined"
     ]
    }
   ],
   "source": [
    "transform = Transform()\n",
    "logger = get_logger(f\"core.transforms.{transform.state}.{transform.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "int_columns = ['pharm_npi', 'pharm_ncpdp', 'pharm_zip', 'txn_id', 'txn_seq', 'long_pat_id', 'pat_zip', 'hcp_zip', 'hcp_phone', 'hcp_npi', 'rx_fills', 'rx_fill_num', 'rx_refills_rem', 'prev_disp', 'ndc', 'qty_disp', 'days_supply', 'ship_zip', 'prim_payer_bin', 'prim_payer_iin', 'prim_payer_pcn', 'sec_payer_bin', 'sec_payer_iin', 'sec_payer_pcn', 'agg_ship_id', 'ref_num']\n",
    "int_as_type = {col: 'int64' for col in int_columns}\n",
    "# e.g.: int_as_type = {'pharm_npi': 'int64', 'pharm_ncpdp': 'int64', etc...}\n",
    "\n",
    "float_columns = ['prim_plan_paid', 'sec_plan_paid', 'prim_copay', 'prim_coins', 'prim_deductible', 'prim_pat_resp', 'sec_copay', 'sec_coins', 'sec_deductible', 'sec_pat_resp', 'copay_as_amt', 'oth_payer_amt', 'prim_ cost_amt']\n",
    "float_as_type = {col: 'float64' for col in int_columns}\n",
    "# e.g.: float_as_type = {'prim_plan_paid': 'float64', 'sec_plan_paid': 'float64', etc...}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description\n",
    "What does this transformation do? be specific.\n",
    "\n",
    "![what does your transform do](assets/what.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This transform takes patient status data and converts all number columns to either int or float.  We have a specified mapping of columns to their data types here: https://docs.google.com/spreadsheets/d/18MRVquLrHSNarSjXLtJF_igiEPMnjBRX\n",
    "\n",
    "The reason we need this is because we pull in all data as a string, so number columns need to be converted back to their respective types."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import boto3\n",
    "from s3parq import fetch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Retrieve current dataset from contract\n",
    "from core.dataset_diff import DatasetDiff\n",
    "\n",
    "diff = DatasetDiff(db_transform.id)\n",
    "final_dataframe = diff.get_diff(transform_name=transform.input_transform, values=[run_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "ingest_contract = DatasetContract(branch='dc-628_fix_sun_mappings',\n",
    "                                  parent='sun',\n",
    "                                  child='ilumya',\n",
    "                                  state='ingest',\n",
    "                                  dataset='symphony_health_association_ingest_column_mapping')\n",
    "\n",
    "run_filter = [{'partition':'__metadata_run_id', 'comparison':'==', 'values':[10]}]\n",
    "\n",
    "final_dataframe = fetch(bucket=ingest_contract.bucket, key=ingest_contract.key, filters=run_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['rec_date', 'pharm_code', 'pharm_npi', 'transtype',\n",
       "       'pharm_transaction_id', 'trans_seq', 'ref_source', 'ref_date',\n",
       "       'program_id', 'pharmacy_id', 'pat_last_name', 'pat_first_name',\n",
       "       'pat_dob', 'pat_gender', 'pat_addr1', 'pat_addr2', 'pat_city',\n",
       "       'pat_state', 'pat_zip', 'dx1_code', 'dx2_code', 'status_date',\n",
       "       'status_code', 'sub_status', 'pres_last_name', 'pres_first_name',\n",
       "       'pres_addr1', 'pres_addr2', 'pres_city', 'pres_state', 'pres_zip',\n",
       "       'pres_phone', 'pres_npi', 'pres_dea', 'facility_name', 'rxdate',\n",
       "       'rxnumber', 'rxrefills', 'rxfill', 'refill_remaining', 'prev_disp',\n",
       "       'rx_ndc_number', 'medication', 'quantity', 'day_supply', 'ship_date',\n",
       "       'ship_carrier', 'shiptracking_num', 'ship_location', 'ship_address',\n",
       "       'ship_city', 'ship_state', 'ship_zip', 'has_medical',\n",
       "       'primary_coverage_type', 'primary_payer_name', 'primary_payer_type',\n",
       "       'secondary_coverage_type', 'secondary_payer_name',\n",
       "       'secondary_payer_type', 'plan_paid_amt', 'pat_copay',\n",
       "       'copay_assist_amount', 'oth_payer_amt', 'xfer_pharmname',\n",
       "       'msa_patient_id', 'msa_patient_bmap', '__metadata_run_timestamp',\n",
       "       '__metadata_app_version', '__metadata_transform_timestamp',\n",
       "       '__metadata_output_contract', '__metadata_run_id'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_dataframe.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'pharm_npi': 'int64',\n",
       " 'pharm_ncpdp': 'int64',\n",
       " 'pharm_zip': 'int64',\n",
       " 'txn_id': 'int64',\n",
       " 'txn_seq': 'int64',\n",
       " 'long_pat_id': 'int64',\n",
       " 'pat_zip': 'int64',\n",
       " 'hcp_zip': 'int64',\n",
       " 'hcp_phone': 'int64',\n",
       " 'hcp_npi': 'int64',\n",
       " 'rx_fills': 'int64',\n",
       " 'rx_fill_num': 'int64',\n",
       " 'rx_refills_rem': 'int64',\n",
       " 'prev_disp': 'int64',\n",
       " 'ndc': 'int64',\n",
       " 'qty_disp': 'int64',\n",
       " 'days_supply': 'int64',\n",
       " 'ship_zip': 'int64',\n",
       " 'prim_payer_bin': 'int64',\n",
       " 'prim_payer_iin': 'int64',\n",
       " 'prim_payer_pcn': 'int64',\n",
       " 'sec_payer_bin': 'int64',\n",
       " 'sec_payer_iin': 'int64',\n",
       " 'sec_payer_pcn': 'int64',\n",
       " 'agg_ship_id': 'int64',\n",
       " 'ref_num': 'int64'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int_as_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Only a column name can be used for the key in a dtype mappings argument.'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-a06c04d836aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#  Convert all int columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfinal_dataframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_dataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mint_as_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#  Conert all float columns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mfinal_dataframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfinal_dataframe\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfloat_as_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36mastype\u001b[0;34m(self, dtype, copy, errors, **kwargs)\u001b[0m\n\u001b[1;32m   5671\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcol_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   5672\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcol_name\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 5673\u001b[0;31m                     raise KeyError('Only a column name can be used for the '\n\u001b[0m\u001b[1;32m   5674\u001b[0m                                    'key in a dtype mappings argument.')\n\u001b[1;32m   5675\u001b[0m             \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Only a column name can be used for the key in a dtype mappings argument.'"
     ]
    }
   ],
   "source": [
    "#  Convert all int columns\n",
    "final_dataframe = final_dataframe.astype(int_as_type)\n",
    "\n",
    "#  Conert all float columns\n",
    "final_dataframe = final_dataframe.astype(float_as_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Publish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## that's it - just provide the final dataframe to the var final_dataframe and we take it from there\n",
    "transform.publish_contract.publish(final_dataframe, run_id, session, False)\n",
    "session.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
