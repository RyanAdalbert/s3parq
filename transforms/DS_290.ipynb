{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-07-17 19:27:38,303 - core.helpers.session_helper.SessionHelper - INFO - Creating session for dev environment...\n",
      "2019-07-17 19:27:38,338 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating administrator mocks.\n",
      "2019-07-17 19:27:38,397 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating administrator mocks.\n",
      "2019-07-17 19:27:38,399 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating pharmaceutical company mocks.\n",
      "2019-07-17 19:27:38,407 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating pharmaceutical company mocks.\n",
      "2019-07-17 19:27:38,410 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating brand mocks.\n",
      "2019-07-17 19:27:38,427 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating brand mocks.\n",
      "2019-07-17 19:27:38,432 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating segment mocks.\n",
      "2019-07-17 19:27:38,441 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating segment mocks.\n",
      "2019-07-17 19:27:38,446 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating pipeline type mocks.\n",
      "2019-07-17 19:27:38,452 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating pipeline type mocks.\n",
      "2019-07-17 19:27:38,460 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating pipeline mocks.\n",
      "2019-07-17 19:27:38,465 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating pipeline mocks.\n",
      "2019-07-17 19:27:38,469 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating pipeline state type mocks.\n",
      "2019-07-17 19:27:38,478 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating pipeline state type mocks.\n",
      "2019-07-17 19:27:38,480 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating pipeline state mocks.\n",
      "2019-07-17 19:27:38,489 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating pipeline state mocks.\n",
      "2019-07-17 19:27:38,490 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating tag mocks.\n",
      "2019-07-17 19:27:38,496 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating tag mocks.\n",
      "2019-07-17 19:27:38,498 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating transformation_template mocks.\n",
      "2019-07-17 19:27:38,503 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating transformation_template mocks.\n",
      "2019-07-17 19:27:38,505 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating bridge table mocks for transformation_templates <=> tags.\n",
      "2019-07-17 19:27:38,510 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating transformation_templates_tags mocks.\n",
      "2019-07-17 19:27:38,511 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating transformation mocks.\n",
      "2019-07-17 19:27:38,519 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating transformation mocks.\n",
      "2019-07-17 19:27:38,521 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating transformation_variables mocks\n",
      "2019-07-17 19:27:38,526 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating transformation_variables mocks.\n",
      "2019-07-17 19:27:38,526 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating run_events mocks.\n",
      "2019-07-17 19:27:38,532 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating run_events mocks.\n",
      "2019-07-17 19:27:38,534 - core.helpers.session_helper.SessionHelper - INFO - Done. Created dev session with mock data.\n"
     ]
    }
   ],
   "source": [
    "transform_id = 1\n",
    "\n",
    "\"\"\"\n",
    "************ SETUP - DON'T TOUCH **************\n",
    "This section imports data from the configuration database\n",
    "and should not need to be altered, molested or otherwise messed with. \n",
    "~~These are not the droids you are looking for~~\n",
    "\"\"\"\n",
    "from core.constants import BRANCH_NAME, ENV_BUCKET\n",
    "from core.helpers.session_helper import SessionHelper\n",
    "from core.models.configuration import Transformation\n",
    "from dataclasses import dataclass\n",
    "from core.dataset_contract import DatasetContract\n",
    "\n",
    "db_transform = SessionHelper().session.query(Transformation).filter(Transformation.id == transform_id).one()\n",
    "\n",
    "@dataclass\n",
    "class DbTransform:\n",
    "    id: int = db_transform.id ## the instance id of the transform in the config app\n",
    "    name: str = db_transform.transformation_template.name ## the transform name in the config app\n",
    "    state: str = db_transform.pipeline_state.pipeline_state_type.name ## the pipeline state, one of raw, ingest, master, enhance, enrich, metrics, dimensional\n",
    "    branch:str = BRANCH_NAME ## the git branch for this execution \n",
    "    brand: str = db_transform.pipeline_state.pipeline.brand.name ## the pharma brand name\n",
    "    pharmaceutical_company: str = db_transform.pipeline_state.pipeline.brand.pharmaceutical_company.name # the pharma company name\n",
    "    publish_contract: DatasetContract = DatasetContract(branch=BRANCH_NAME,\n",
    "                            state=db_transform.pipeline_state.pipeline_state_type.name,\n",
    "                            parent=db_transform.pipeline_state.pipeline.brand.pharmaceutical_company.name,\n",
    "                            child=db_transform.pipeline_state.pipeline.brand.name,\n",
    "                            dataset=db_transform.transformation_template.name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CORE Cartridge Notebook::[Referral Date Enrichment]\n",
    "![CORE Logo](assets/coreLogo.png) \n",
    "\n",
    "---\n",
    "## Keep in Mind\n",
    "Good Transforms Are...\n",
    "- **singular in purpose:** good transforms do one and only one thing, and handle all known cases for that thing. \n",
    "- **repeatable:** transforms should be written in a way that they can be run against the same dataset an infinate number of times and get the same result every time. \n",
    "- **easy to read:** 99 times out of 100, readable, clear code that runs a little slower is more valuable than a mess that runs quickly. \n",
    "- **No 'magic numbers':** if a variable or function is not instantly obvious as to what it is or does, without context, maybe consider renaming it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow - how to use this notebook to make science\n",
    "#### Data Science\n",
    "1. **Document your transform.** Fill out the _description_ cell below describing what it is this transform does; this will appear in the configuration application where Ops will create, configure and update pipelines. \n",
    "1. **Define your config object.** Fill out the _configuration_ cell below the commented-out guide to define the variables you want ops to set in the configuration application (these will populate here for every pipeline). \n",
    "2. **Build your transformation logic.** Use the transformation cell to do that magic that you do. \n",
    "![caution](assets/cautionTape.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "********* CONFIGURATION - PLEASE TOUCH ********* \n",
    "This section defines what you expect to get from the configuration application \n",
    "in a single \"transform\" object. Define the vars you need here, and comment inline to the right of them \n",
    "for all-in-one documentation. \n",
    "Engineering will build a production \"transform\" object for every pipeline that matches what you define here.\n",
    "\n",
    "@@@ FORMAT OF THE DATA CLASS IS: @@@ \n",
    "\n",
    "<value_name>: <data_type> #<comment explaining what the value is to future us>\n",
    "\n",
    "~~These ARE the droids you are looking for~~\n",
    "\"\"\"\n",
    "\n",
    "class Transform(DbTransform):\n",
    "    '''\n",
    "    YOUR properties go here!!\n",
    "    Include your input dataset(s) here. Variable properties should be assigned to the exact name of\n",
    "    the transformation as it appears in the Jupyter notebook filename.\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Please place your value assignments for development here!!\n",
    "## This cell will be turned off in production and Engineering will set to pull form the configuration application instead\n",
    "trans_id = 'pmcTransactionId'\n",
    "product = 'medication'\n",
    "patient_id = 'pmcPatientId'\n",
    "pharm = 'pharmName'\n",
    "status_date = 'statusDate'\n",
    "ref_date = 'refDate'\n",
    "status =  'statusCode'\n",
    "substatus =  'custStatusCode'\n",
    "ic_status = 'integrichain_status'\n",
    "ic_substatus = 'integrichain_sub_status'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description\n",
    "What does this transformation do? be specific.\n",
    "\n",
    "![what does your transform do](assets/what.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Transform provides the preliminary enrichment format. Takes patient data in from S3 and adjusts all possibly inaccurate reference dates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = Transform()\n",
    "\n",
    "transform.name = 'DS_290'\n",
    "transform.brand = 'ofev'\n",
    "transform.state = 'enrich'\n",
    "transform.pharmaceutical_company = 'bi'\n",
    "transform.filesystem_path = 's3://ichain-dev/movahlx/bi/transactions'\n",
    "\n",
    "transform.secret_name = 'bi'\n",
    "transform.secret_type_of = 'database'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from s3fs import S3FileSystem\n",
    "#import mysql.connector as mysql\n",
    "\n",
    "from core.secret import Secret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pandas_from_parquet_s3(file_path):\n",
    "    \n",
    "    s3 = S3FileSystem()\n",
    "    df = (\n",
    "        pq\n",
    "        .ParquetDataset(file_path, filesystem=s3)\n",
    "        .read_pandas()\n",
    "        .to_pandas()\n",
    "    )\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def pandas_from_database(query, *args):\n",
    "    \n",
    "    connection = mysql.connect(\n",
    "        host=secret.host, \n",
    "        user=secret.user, \n",
    "        passwd=secret.password, \n",
    "        port=secret.port, \n",
    "        charset='utf8'\n",
    "    )\n",
    "    \n",
    "    query = query.format(*args)\n",
    "    df = pd.read_sql(sql=query, con=connection)\n",
    "    connection.close()\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "def pandas_to_parquet_s3(df, partition, file_path):\n",
    "    \n",
    "    s3 = S3FileSystem()\n",
    "    table = pa.Table.from_pandas(df)\n",
    "    \n",
    "    pq.write_to_dataset(table, file_path, partition_cols=partition, filesystem=s3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pharmName</th>\n",
       "      <th>sp_file_id</th>\n",
       "      <th>sp_file_dt</th>\n",
       "      <th>sp_file_tm</th>\n",
       "      <th>sp_rec_id</th>\n",
       "      <th>restmt_flg</th>\n",
       "      <th>pharmy_npi_id</th>\n",
       "      <th>ncpdp_id</th>\n",
       "      <th>pharmy_nm</th>\n",
       "      <th>statusCode</th>\n",
       "      <th>...</th>\n",
       "      <th>outletZip</th>\n",
       "      <th>regionId</th>\n",
       "      <th>districtId</th>\n",
       "      <th>territoryId</th>\n",
       "      <th>regionName</th>\n",
       "      <th>districtName</th>\n",
       "      <th>zipCode</th>\n",
       "      <th>prescriptionId</th>\n",
       "      <th>bridgeId</th>\n",
       "      <th>startDateLong</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BRIOVARX</td>\n",
       "      <td>811072016</td>\n",
       "      <td>20161107</td>\n",
       "      <td>080008</td>\n",
       "      <td>None</td>\n",
       "      <td>N</td>\n",
       "      <td>1083045140</td>\n",
       "      <td>1564930</td>\n",
       "      <td>BRIOVARX OF INDIANA, LLC</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>...</td>\n",
       "      <td>35242</td>\n",
       "      <td>B0300000</td>\n",
       "      <td>B03S1100</td>\n",
       "      <td>B03S1101</td>\n",
       "      <td>SOUTHEAST</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>35242</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1474934400000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BRIOVARX</td>\n",
       "      <td>811072016</td>\n",
       "      <td>20161107</td>\n",
       "      <td>080008</td>\n",
       "      <td>None</td>\n",
       "      <td>N</td>\n",
       "      <td>1083045140</td>\n",
       "      <td>1564930</td>\n",
       "      <td>BRIOVARX OF INDIANA, LLC</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>...</td>\n",
       "      <td>35242</td>\n",
       "      <td>B0300000</td>\n",
       "      <td>B03S1100</td>\n",
       "      <td>B03S1101</td>\n",
       "      <td>SOUTHEAST</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>35242</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1477353600000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BRIOVARX</td>\n",
       "      <td>811072016</td>\n",
       "      <td>20161107</td>\n",
       "      <td>080008</td>\n",
       "      <td>None</td>\n",
       "      <td>N</td>\n",
       "      <td>1083045140</td>\n",
       "      <td>1564930</td>\n",
       "      <td>BRIOVARX OF INDIANA, LLC</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>...</td>\n",
       "      <td>35242</td>\n",
       "      <td>B0300000</td>\n",
       "      <td>B03S1100</td>\n",
       "      <td>B03S1101</td>\n",
       "      <td>SOUTHEAST</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>35242</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1477440000000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BRIOVARX</td>\n",
       "      <td>811072016</td>\n",
       "      <td>20161107</td>\n",
       "      <td>080008</td>\n",
       "      <td>None</td>\n",
       "      <td>N</td>\n",
       "      <td>1083045140</td>\n",
       "      <td>1564930</td>\n",
       "      <td>BRIOVARX OF INDIANA, LLC</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>...</td>\n",
       "      <td>35242</td>\n",
       "      <td>B0300000</td>\n",
       "      <td>B03S1100</td>\n",
       "      <td>B03S1101</td>\n",
       "      <td>SOUTHEAST</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>35242</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1475625600000000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BRIOVARX</td>\n",
       "      <td>811072016</td>\n",
       "      <td>20161107</td>\n",
       "      <td>080008</td>\n",
       "      <td>None</td>\n",
       "      <td>N</td>\n",
       "      <td>1083045140</td>\n",
       "      <td>1564930</td>\n",
       "      <td>BRIOVARX OF INDIANA, LLC</td>\n",
       "      <td>ACTIVE</td>\n",
       "      <td>...</td>\n",
       "      <td>35242</td>\n",
       "      <td>B0300000</td>\n",
       "      <td>B03S1100</td>\n",
       "      <td>B03S1101</td>\n",
       "      <td>SOUTHEAST</td>\n",
       "      <td>ALABAMA</td>\n",
       "      <td>35242</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>1476316800000000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 126 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  pharmName sp_file_id sp_file_dt sp_file_tm sp_rec_id restmt_flg  \\\n",
       "0  BRIOVARX  811072016   20161107     080008      None          N   \n",
       "1  BRIOVARX  811072016   20161107     080008      None          N   \n",
       "2  BRIOVARX  811072016   20161107     080008      None          N   \n",
       "3  BRIOVARX  811072016   20161107     080008      None          N   \n",
       "4  BRIOVARX  811072016   20161107     080008      None          N   \n",
       "\n",
       "  pharmy_npi_id ncpdp_id                 pharmy_nm statusCode  ... outletZip  \\\n",
       "0    1083045140  1564930  BRIOVARX OF INDIANA, LLC     ACTIVE  ...     35242   \n",
       "1    1083045140  1564930  BRIOVARX OF INDIANA, LLC     ACTIVE  ...     35242   \n",
       "2    1083045140  1564930  BRIOVARX OF INDIANA, LLC     ACTIVE  ...     35242   \n",
       "3    1083045140  1564930  BRIOVARX OF INDIANA, LLC     ACTIVE  ...     35242   \n",
       "4    1083045140  1564930  BRIOVARX OF INDIANA, LLC     ACTIVE  ...     35242   \n",
       "\n",
       "   regionId districtId territoryId regionName districtName zipCode  \\\n",
       "0  B0300000   B03S1100    B03S1101  SOUTHEAST      ALABAMA   35242   \n",
       "1  B0300000   B03S1100    B03S1101  SOUTHEAST      ALABAMA   35242   \n",
       "2  B0300000   B03S1100    B03S1101  SOUTHEAST      ALABAMA   35242   \n",
       "3  B0300000   B03S1100    B03S1101  SOUTHEAST      ALABAMA   35242   \n",
       "4  B0300000   B03S1100    B03S1101  SOUTHEAST      ALABAMA   35242   \n",
       "\n",
       "  prescriptionId bridgeId        startDateLong  \n",
       "0           None     None  1474934400000000000  \n",
       "1           None     None  1477353600000000000  \n",
       "2           None     None  1477440000000000000  \n",
       "3           None     None  1475625600000000000  \n",
       "4           None     None  1476316800000000000  \n",
       "\n",
       "[5 rows x 126 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pandas_from_parquet_s3(transform.filesystem_path)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_clean_file(cust_df, trans_id, product, patient_id, pharm, status_date, ref_date, status, substatus):\n",
    "    \n",
    "    # Extract and map relevant columns\n",
    "    #cust_df = cust_input_df.loc[:,[trans_id,\n",
    "    #                               patient,\n",
    "    #                               patient_id,\n",
    "    #                               pharm,\n",
    "    #                               product,\n",
    "    #                               status_date,\n",
    "    #                               ref_date,\n",
    "    #                               status,\n",
    "    #                               substatus]]\n",
    "\n",
    "    cust_df = cust_df.rename(columns={trans_id:'trans_id',\n",
    "                                      patient_id:'patient_id',\n",
    "                                      pharm:'pharm',\n",
    "                                      product:'product',\n",
    "                                      status_date:'status_date',\n",
    "                                      ref_date:'ref_date',\n",
    "                                      status:'status_code',\n",
    "                                      substatus:'substatus_code'})\n",
    "    \n",
    "    # Convert dates to datetime format\n",
    "    cust_df.status_date = pd.to_datetime(cust_df.status_date)\n",
    "    cust_df.ref_date = pd.to_datetime(cust_df.ref_date)\n",
    "    \n",
    "    ## Extract brand from medication\n",
    "    cust_df['product'] = cust_df['product'].apply(lambda x: x.split()[0].strip())\n",
    "    \n",
    "\t## Convert status codes to uppercase\n",
    "    cust_df.status_code = cust_df.status_code.str.upper()\n",
    "    cust_df.substatus_code = cust_df.substatus_code.str.upper()\n",
    "    \n",
    "\t## Fill missing referral_date with min(status_date)\n",
    "\t\n",
    "    min_status_dates=cust_df.groupby(['patient_id','pharm','product'])['status_date'].min().reset_index().rename(columns={'status_date':'min_status_date'})\n",
    "    \n",
    "    cust_df = pd.merge(cust_df, min_status_dates, how='inner', on=['patient_id','pharm','product'])\n",
    "    \n",
    "    cust_df.loc[cust_df['ref_date'].isnull(), ['ref_date']] = cust_df['min_status_date']\n",
    "    \n",
    "    cust_df = cust_df.drop(['min_status_date'],axis=1).drop_duplicates()\n",
    "    \n",
    "    cust_df.sort_values(by=['patient_id', 'pharm', 'product', 'status_date'], ascending=[True, True, True, True], inplace=True)\n",
    "    cust_df = cust_df.reset_index(drop=True)\n",
    "\n",
    "    # Output clean customer file\n",
    "    return cust_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def referral_date_enrichment(df: pd.DataFrame, cols, statuses,\n",
    "#                         table_columns,\n",
    "#                         ref_date_enrichment_threshold):\n",
    "def referral_date_enrichment(df: pd.DataFrame, table_columns, ref_date_enrichment_threshold):\n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "#    status_date = cols.status_date\n",
    "#    ref_date = cols.ref_date\n",
    "#    patient = cols.patient\n",
    "#    pharm = cols.pharm\n",
    "#    product = cols.product\n",
    "    min_date_df = df.groupby(['patient_id', 'pharm', 'product'])['status_date'].min().reset_index().rename(columns={'status_date': 'First_Status_Date'})\n",
    "    df = pd.merge(df, min_date_df, how='inner', on=['patient_id', 'pharm', 'product'])\n",
    "    min_ref_date_df = df.groupby(['patient_id', 'pharm', 'product'])['ref_date'].min().reset_index().rename(columns={'ref_date': 'First_Ref_Date'})\n",
    "    df = pd.merge(df, min_ref_date_df, how='inner', on=['patient_id', 'pharm', 'product'])\n",
    "\n",
    "    df['min_ref_day_diff'] = (df['First_Status_Date'] - df['First_Ref_Date']) / np.timedelta64(1, 'D')\n",
    "    df['ref_day_diff'] = (df['First_Status_Date'] - df['ref_date']) / np.timedelta64(1, 'D')\n",
    "\n",
    "    to_enrich_df = df[(df['min_ref_day_diff'] > ref_date_enrichment_threshold) & (df['ref_day_diff'] > ref_date_enrichment_threshold)]\n",
    "    to_enrich_df['ref_date'] = to_enrich_df['First_Status_Date']\n",
    "    #to_enrich_df = to_enrich_df[table_columns]\n",
    "    enriched_ids = to_enrich_df['trans_id'].values.tolist()\n",
    "    df = df[~(df['trans_id'].isin(enriched_ids))]\n",
    "    df = df.append(to_enrich_df)\n",
    "    #df = df[table_columns]\n",
    "    return (df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_standard(cust_df, trans_id, product, patient_id, pharm, status_date, ref_date, status, substatus):\n",
    "\n",
    "    cust_df = cust_df.rename(columns={'trans_id': trans_id,\n",
    "                                      'patient_id': patient_id,\n",
    "                                      'pharm': pharm,\n",
    "                                      'product': product,\n",
    "                                      'status_date': status_date,\n",
    "                                      'ref_date': ref_date,\n",
    "                                      'status_code': status,\n",
    "                                      'substatus_code': substatus})\n",
    "    return cust_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Use the variables above to execute your transformation. the final output needs to be a variable named final_dataframe\n",
    "df = load_clean_file(df, trans_id, product, patient_id, pharm, status_date, ref_date, status, substatus)\n",
    "columns = list(df.columns)\n",
    "final_dataframe = referral_date_enrichment(df, columns, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "639699"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(final_dataframe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Publish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## that's it - just provide the final dataframe to the var final_dataframe and we take it from there\n",
    "transform.publish_contract.publish(final_dataframe)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
