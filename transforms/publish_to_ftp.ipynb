{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CORE Cartridge Notebook::Publish to FTP\n",
    "![CORE Logo](assets/coreLogo.png) \n",
    "\n",
    "---\n",
    "## Keep in Mind\n",
    "Good Transforms Are...\n",
    "- **singular in purpose:** good transforms do one and only one thing, and handle all known cases for that thing. \n",
    "- **repeatable:** transforms should be written in a way that they can be run against the same dataset an infinate number of times and get the same result every time. \n",
    "- **easy to read:** 99 times out of 100, readable, clear code that runs a little slower is more valuable than a mess that runs quickly. \n",
    "- **No 'magic numbers':** if a variable or function is not instantly obvious as to what it is or does, without context, maybe consider renaming it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow - how to use this notebook to make science\n",
    "#### Data Science\n",
    "1. **Document your transform.** Fill out the _description_ cell below describing what it is this transform does; this will appear in the configuration application where Ops will create, configure and update pipelines. \n",
    "1. **Define your config object.** Fill out the _configuration_ cell below the commented-out guide to define the variables you want ops to set in the configuration application (these will populate here for every pipeline). \n",
    "2. **Build your transformation logic.** Use the transformation cell to do that magic that you do. \n",
    "![caution](assets/cautionTape.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description\n",
    "What does this transformation do? be specific.\n",
    "\n",
    "![what does your transform do](assets/what.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This transformation publishes a dataset in S3 to an external FTP server. The credentials for the FTP server should be stored securely in an AWS Secret, with the secret_name and secret_type_of provided to the transformation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.helpers.session_helper import SessionHelper\n",
    "session = SessionHelper().session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "************ SETUP - DON'T TOUCH **************\n",
    "This section imports data from the configuration database\n",
    "and should not need to be altered, molested or otherwise messed with. \n",
    "~~These are not the droids you are looking for~~\n",
    "\"\"\"\n",
    "from core.constants import BRANCH_NAME, ENV_BUCKET\n",
    "from core.models.configuration import Transformation\n",
    "from dataclasses import dataclass\n",
    "from core.dataset_contract import DatasetContract\n",
    "import pandas as pd\n",
    "\n",
    "db_transform = session.query(Transformation).filter(Transformation.id == transform_id).one()\n",
    "\n",
    "@dataclass\n",
    "class DbTransform:\n",
    "    id: int = db_transform.id ## the instance id of the transform in the config app\n",
    "    name: str = db_transform.transformation_template.name ## the transform name in the config app\n",
    "    state: str = db_transform.pipeline_state.pipeline_state_type.name ## the pipeline state, one of raw, ingest, master, enhance, enrich, metrics, dimensional\n",
    "    branch:str = BRANCH_NAME ## the git branch for this execution \n",
    "    brand: str = db_transform.pipeline_state.pipeline.brand.name ## the pharma brand name\n",
    "    pharmaceutical_company: str = db_transform.pipeline_state.pipeline.brand.pharmaceutical_company.name # the pharma company name\n",
    "    publish_contract: DatasetContract = DatasetContract(branch=BRANCH_NAME,\n",
    "                            state=db_transform.pipeline_state.pipeline_state_type.name,\n",
    "                            parent=db_transform.pipeline_state.pipeline.brand.pharmaceutical_company.name,\n",
    "                            child=db_transform.pipeline_state.pipeline.brand.name,\n",
    "                            dataset=db_transform.transformation_template.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "********* CONFIGURATION - PLEASE TOUCH ********* \n",
    "This section defines what you expect to get from the configuration application \n",
    "in a single \"transform\" object. Define the vars you need here, and comment inline to the right of them \n",
    "for all-in-one documentation. \n",
    "Engineering will build a production \"transform\" object for every pipeline that matches what you define here.\n",
    "\n",
    "@@@ FORMAT OF THE DATA CLASS IS: @@@ \n",
    "\n",
    "<value_name>: <data_type> #<comment explaining what the value is to future us>\n",
    "\n",
    "~~These ARE the droids you are looking for~~\n",
    "\"\"\"\n",
    "\n",
    "class Transform(DbTransform):\n",
    "    input_transform: str = db_transform.variables.input_transform # name of transformation to pull dataset from\n",
    "    prefix: str = db_transform.variables.prefix # file prefix to publish to ftp\n",
    "    suffix: str = db_transform.variables.suffix # file suffix to publish to ftp\n",
    "    filetype: str = db_transform.variables.filetype # filetype to publish to ftp (DO NOT INCLUDE . IN FILETYPE)\n",
    "    separator: str = db_transform.variables.separator # single character separator for output file\n",
    "    compression: bool = db_transform.variables.compression # if true, published file will be compressed as gzip\n",
    "    date_format: str = db_transform.variables.date_format # string formatting for datetime\n",
    "    remote_path: str = db_transform.variables.remote_path # path to publish to on FTP server\n",
    "    secret_name: str = db_transform.variables.secret_name # AWS secret name containing FTP credentials\n",
    "    secret_type_of: str = db_transform.variables.secret_type_of # AWS secret type of, should almost always be \"FTP\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Please place your value assignments for development here!!\n",
    "## This cell will be turned off in production and Engineering will set to pull form the configuration application instead\n",
    "\n",
    "transform = Transform()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Retrieve current dataset from contract\n",
    "from core.dataset_diff import DatasetDiff\n",
    "\n",
    "diff = DatasetDiff(db_transform.id)\n",
    "df = diff.get_diff(transform_name=transform.input_transform, values=[run_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.helpers import file_mover\n",
    "from core.secret import Secret\n",
    "import core.helpers.drop_metadata as dropper\n",
    "import tempfile, datetime\n",
    "\n",
    "if len(transform.separator) != 1:\n",
    "    raise ValueError(\"Error: Separator must be a single character.\")\n",
    "\n",
    "if transform.filetype.find(\".\") != -1:\n",
    "    raise ValueError(\"Error: Filetype should not contain '.'\")\n",
    "\n",
    "prefix = \"/\" + transform.prefix + \"_\" + transform.brand.upper()\n",
    "suffix = transform.suffix\n",
    "filetype = \".\" + transform.filetype.lower()\n",
    "\n",
    "ts = datetime.datetime.now()\n",
    "time = ts.strftime(transform.date_format)\n",
    "\n",
    "if suffix == \"\":\n",
    "    filename = '_'.join([prefix, time]) + filetype\n",
    "else:\n",
    "    filename = '_'.join([prefix, time, suffix]) + filetype\n",
    "    \n",
    "if transform.compression:\n",
    "    filename += '.gz'\n",
    "\n",
    "df = dropper.drop_metadata(df)\n",
    "\n",
    "with tempfile.TemporaryDirectory() as temp_dir:\n",
    "    filename = temp_dir + filename\n",
    "    \n",
    "    if transform.compression:\n",
    "        df.fillna('')\\\n",
    "            .to_csv(filename,\n",
    "                    sep=transform.separator,\n",
    "                    header=True,\n",
    "                    index=False,\n",
    "                    compression='gzip'\n",
    "                   )\n",
    "    else:\n",
    "        df.fillna('')\\\n",
    "            .to_csv(filename,\n",
    "                    sep=transform.separator,\n",
    "                    header=True,\n",
    "                    index=False\n",
    "                   )\n",
    "\n",
    "    ftp_secret = Secret(name=transform.secret_name, type_of=transform.secret_type_of, mode=\"write\")\n",
    "    file_mover.publish_file(local_path=filename, remote_path=transform.remote_path, secret=ftp_secret)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Publish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Files are published to FTP in this transformation. This transformation does not publish to a contract in S3."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
