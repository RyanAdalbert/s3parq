{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "************ SETUP - DON'T TOUCH **************\n",
    "This section imports data from the configuration database\n",
    "and should not need to be altered, molested or otherwise messed with. \n",
    "~~These are not the droids you are looking for~~\n",
    "\"\"\"\n",
    "from core.constants import BRANCH_NAME, ENV_BUCKET\n",
    "from core.helpers.session_helper import SessionHelper\n",
    "from core.models.configuration import Transformation\n",
    "from dataclasses import dataclass\n",
    "from core.dataset_contract import DatasetContract\n",
    "\n",
    "session = SessionHelper().session\n",
    "db_transform = session.query(Transformation).filter(Transformation.id == transform_id).one()\n",
    "\n",
    "@dataclass\n",
    "class DbTransform:\n",
    "    id: int = db_transform.id ## the instance id of the transform in the config app\n",
    "    name: str = db_transform.transformation_template.name ## the transform name in the config app\n",
    "    state: str = db_transform.pipeline_state.pipeline_state_type.name ## the pipeline state, one of raw, ingest, master, enhance, enrich, metrics, dimensional\n",
    "    branch:str = BRANCH_NAME ## the git branch for this execution \n",
    "    brand: str = db_transform.pipeline_state.pipeline.brand.name ## the pharma brand name\n",
    "    pharmaceutical_company: str = db_transform.pipeline_state.pipeline.brand.pharmaceutical_company.name # the pharma company name\n",
    "    publish_contract: DatasetContract = DatasetContract(branch=BRANCH_NAME,\n",
    "                            parent=db_transform.pipeline_state.pipeline.brand.pharmaceutical_company.name,\n",
    "                            child=db_transform.pipeline_state.pipeline.brand.name,\n",
    "                            state=db_transform.pipeline_state.pipeline_state_type.name,\n",
    "                            dataset=db_transform.transformation_template.name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CORE Cartridge Notebook :: symphony_health_association_refinement\n",
    "![CORE Logo](assets/coreLogo.png) \n",
    "\n",
    "---\n",
    "## Keep in Mind\n",
    "Good Transforms Are...\n",
    "- **singular in purpose:** good transforms do one and only one thing, and handle all known cases for that thing. \n",
    "- **repeatable:** transforms should be written in a way that they can be run against the same dataset an infinate number of times and get the same result every time. \n",
    "- **easy to read:** 99 times out of 100, readable, clear code that runs a little slower is more valuable than a mess that runs quickly. \n",
    "- **No 'magic numbers':** if a variable or function is not instantly obvious as to what it is or does, without context, maybe consider renaming it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow - how to use this notebook to make science\n",
    "#### Data Science\n",
    "1. **Document your transform.** Fill out the _description_ cell below describing what it is this transform does; this will appear in the configuration application where Ops will create, configure and update pipelines. \n",
    "1. **Define your config object.** Fill out the _configuration_ cell below the commented-out guide to define the variables you want ops to set in the configuration application (these will populate here for every pipeline). \n",
    "2. **Build your transformation logic.** Use the transformation cell to do that magic that you do. \n",
    "![caution](assets/cautionTape.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "********* CONFIGURATION - PLEASE TOUCH ********* \n",
    "This section defines what you expect to get from the configuration application \n",
    "in a single \"transform\" object. Define the vars you need here, and comment inline to the right of them \n",
    "for all-in-one documentation. \n",
    "Engineering will build a production \"transform\" object for every pipeline that matches what you define here.\n",
    "\n",
    "@@@ FORMAT OF THE DATA CLASS IS: @@@ \n",
    "\n",
    "<value_name>: <data_type> #<comment explaining what the value is to future us>\n",
    "\n",
    "~~These ARE the droids you are looking for~~\n",
    "\"\"\"\n",
    "\n",
    "class Transform(DbTransform):\n",
    "        ## YOUR properties go here!!\n",
    "        ingest_source_transform: str = db_transform.variables.ingest_source_transform # The name of the dataset to pull from\n",
    "        ingest_source_file_prefix: str = db_transform.variables.ingest_source_file_prefix # If from initial ingest, the file prefix name\n",
    "        transaction_date: str = db_transform.variables.transaction_date\n",
    "        pharmacy_code: str = db_transform.variables.pharmacy_code\n",
    "        pharmacy_npi: str = db_transform.variables.pharmacy_npi\n",
    "        pharmacy_hin: str = db_transform.variables.pharmacy_hin\n",
    "        pharmacy_name: str = db_transform.variables.pharmacy_name\n",
    "        pharmacy_ncpdp: str = db_transform.variables.pharmacy_ncpdp\n",
    "        pharmacy_address_1: str = db_transform.variables.pharmacy_address_1\n",
    "        pharmacy_address_2: str = db_transform.variables.pharmacy_address_2\n",
    "        pharmacy_city: str = db_transform.variables.pharmacy_city\n",
    "        pharmacy_state: str = db_transform.variables.pharmacy_state\n",
    "        pharmacy_zip: str = db_transform.variables.pharmacy_zip\n",
    "        transaction_type: str = db_transform.variables.transaction_type\n",
    "        pharmacy_transaction_id: str = db_transform.variables.pharmacy_transaction_id\n",
    "        transaction_sequence: str = db_transform.variables.transaction_sequence\n",
    "        referral_source: str = db_transform.variables.referral_source\n",
    "        referral_date: str = db_transform.variables.referral_date\n",
    "        longitudinal_patient_id: str = db_transform.variables.longitudinal_patient_id\n",
    "        pharmacy_patient_id: str = db_transform.variables.pharmacy_patient_id\n",
    "        patient_dob: str = db_transform.variables.patient_dob\n",
    "        hub_patient_id: str = db_transform.variables.hub_patient_id\n",
    "        bridge_patient: str = db_transform.variables.bridge_patient\n",
    "        hub_patient: str = db_transform.variables.hub_patient\n",
    "        patient_gender: str = db_transform.variables.patient_gender\n",
    "        dx_1: str = db_transform.variables.dx_1\n",
    "        dx_2: str = db_transform.variables.dx_2\n",
    "        status_date: str = db_transform.variables.status_date\n",
    "        status: str = db_transform.variables.status\n",
    "        substatus: str = db_transform.variables.substatus\n",
    "        customer_status: str = db_transform.variables.customer_status\n",
    "        customer_substatus: str = db_transform.variables.customer_substatus\n",
    "        customer_status_description: str = db_transform.variables.customer_status_description\n",
    "        hcp_last_name: str = db_transform.variables.hcp_last_name\n",
    "        hcp_first_name: str = db_transform.variables.hcp_first_name\n",
    "        hcp_address_1: str = db_transform.variables.hcp_address_1\n",
    "        hcp_address_2: str = db_transform.variables.hcp_address_2\n",
    "        hcp_city: str = db_transform.variables.hcp_city\n",
    "        hcp_state: str = db_transform.variables.hcp_state\n",
    "        hcp_zip: str = db_transform.variables.hcp_zip\n",
    "        hcp_phone: str = db_transform.variables.hcp_phone\n",
    "        hcp_specialty: str = db_transform.variables.hcp_specialty\n",
    "        hcp_npi: str = db_transform.variables.hcp_npi\n",
    "        hcp_dea_number: str = db_transform.variables.hcp_dea_number\n",
    "        hcp_facility: str = db_transform.variables.hcp_facility\n",
    "        rx_date: str = db_transform.variables.rx_date\n",
    "        rx_number: str = db_transform.variables.rx_number\n",
    "        rx_fills: str = db_transform.variables.rx_fills\n",
    "        rx_fill_number: str = db_transform.variables.rx_fill_number\n",
    "        rx_refills_remaining: str = db_transform.variables.rx_refills_remaining\n",
    "        prev_dispensed: str = db_transform.variables.prev_dispensed\n",
    "        ndc: str = db_transform.variables.ndc\n",
    "        brand_column: str = db_transform.variables.brand\n",
    "        medication: str = db_transform.variables.medication\n",
    "        quantity_dispensed: str = db_transform.variables.quantity_dispensed\n",
    "        uom_dispensed: str = db_transform.variables.uom_dispensed\n",
    "        days_supply: str = db_transform.variables.days_supply\n",
    "        ship_date: str = db_transform.variables.ship_date\n",
    "        ship_carrier: str = db_transform.variables.ship_carrier\n",
    "        ship_tracking_id: str = db_transform.variables.ship_tracking_id\n",
    "        ship_location: str = db_transform.variables.ship_location\n",
    "        ship_address_1: str = db_transform.variables.ship_address_1\n",
    "        ship_address_2: str = db_transform.variables.ship_address_2\n",
    "        ship_city: str = db_transform.variables.ship_city\n",
    "        ship_state: str = db_transform.variables.ship_state\n",
    "        ship_zip: str = db_transform.variables.ship_zip\n",
    "        has_medical_coverage_flag: str = db_transform.variables.has_medical_coverage_flag\n",
    "        primary_coverage_type: str = db_transform.variables.primary_coverage_type\n",
    "        primary_payer: str = db_transform.variables.primary_payer\n",
    "        primary_payer_type: str = db_transform.variables.primary_payer_type\n",
    "        primary_payer_subtype: str = db_transform.variables.primary_payer_subtype\n",
    "        primary_payer_group: str = db_transform.variables.primary_payer_group\n",
    "        primary_payer_bin: str = db_transform.variables.primary_payer_bin\n",
    "        primary_payer_iin: str = db_transform.variables.primary_payer_iin\n",
    "        primary_payer_pcn: str = db_transform.variables.primary_payer_pcn\n",
    "        primary_plan: str = db_transform.variables.primary_plan\n",
    "        primary_plan_type: str = db_transform.variables.primary_plan_type\n",
    "        secondary_coverage_type: str = db_transform.variables.secondary_coverage_type\n",
    "        secondary_payer: str = db_transform.variables.secondary_payer\n",
    "        secondary_payer_type: str = db_transform.variables.secondary_payer_type\n",
    "        secondary_payer_subtype: str = db_transform.variables.secondary_payer_subtype\n",
    "        secondary_payer_group: str = db_transform.variables.secondary_payer_group\n",
    "        secondary_payer_bin: str = db_transform.variables.secondary_payer_bin\n",
    "        secondary_payer_iin: str = db_transform.variables.secondary_payer_iin\n",
    "        secondary_payer_pcn: str = db_transform.variables.secondary_payer_pcn\n",
    "        secondary_plan: str = db_transform.variables.secondary_plan\n",
    "        secondary_plan_type: str = db_transform.variables.secondary_plan_type\n",
    "        primary_plan_paid: str = db_transform.variables.primary_plan_paid\n",
    "        secondary_plan_paid: str = db_transform.variables.secondary_plan_paid\n",
    "        primary_copay: str = db_transform.variables.primary_copay\n",
    "        primary_coins: str = db_transform.variables.primary_coins\n",
    "        primary_deductible: str = db_transform.variables.primary_deductible\n",
    "        primary_patient_responsibility: str = db_transform.variables.primary_patient_responsibility\n",
    "        secondary_copay: str = db_transform.variables.secondary_copay\n",
    "        secondary_coins: str = db_transform.variables.secondary_coins\n",
    "        secondary_deductible: str = db_transform.variables.secondary_deductible\n",
    "        secondary_patient_responsibility: str = db_transform.variables.secondary_patient_responsibility\n",
    "        copay_as_amount: str = db_transform.variables.copay_as_amount\n",
    "        other_payer_amount: str = db_transform.variables.other_payer_amount\n",
    "        transfer_pharmacy: str = db_transform.variables.transfer_pharmacy\n",
    "        bridge_quantity_dispensed: str = db_transform.variables.bridge_quantity_dispensed\n",
    "        prior_therapy_name: str = db_transform.variables.prior_therapy_name\n",
    "        pharmacy_parent_name: str = db_transform.variables.pharmacy_parent_name\n",
    "        hcp_state_license_number: str = db_transform.variables.hcp_state_license_number\n",
    "        patient_state: str = db_transform.variables.patient_state\n",
    "        dose_exchange_flag: str = db_transform.variables.dose_exchange_flag\n",
    "        dose_exchange_count: str = db_transform.variables.dose_exchange_count\n",
    "        dose_titration_quantity: str = db_transform.variables.dose_titration_quantity\n",
    "        dose_titration_count: str = db_transform.variables.dose_titration_count\n",
    "        oxygen_flag: str = db_transform.variables.oxygen_flag\n",
    "        patient_zip: str = db_transform.variables.patient_zip\n",
    "        secondary_payer_flag: str = db_transform.variables.secondary_payer_flag\n",
    "        restatement_flag: str = db_transform.variables.restatement_flag\n",
    "        aggregator_transaction_id: str = db_transform.variables.aggregator_transaction_id\n",
    "        primary_pbm_name: str = db_transform.variables.primary_pbm_name\n",
    "        referral_number: str = db_transform.variables.referral_number\n",
    "        hcp_middle_name: str = db_transform.variables.hcp_middle_name\n",
    "        hcp_suffix: str = db_transform.variables.hcp_suffix\n",
    "        pharmacy_dea_number: str = db_transform.variables.pharmacy_dea_number\n",
    "        primary_prior_auth_required_flag: str = db_transform.variables.primary_prior_auth_required_flag\n",
    "        primary_prior_auth_expiration_date: str = db_transform.variables.primary_prior_auth_expiration_date\n",
    "        patient_consent_date: str = db_transform.variables.patient_consent_date\n",
    "        primary_cost_type: str = db_transform.variables.primary_cost_type\n",
    "        primary_cost_amount: str = db_transform.variables.primary_cost_amount\n",
    "        patient_support_1: str = db_transform.variables.patient_support_1\n",
    "        patient_support_2: str = db_transform.variables.patient_support_2\n",
    "        patient_oop_program_name: str = db_transform.variables.patient_oop_program_name\n",
    "        bridge_quantity_dispensed_2: str = db_transform.variables.bridge_quantity_dispensed_2\n",
    "        enroll_received_date: str = db_transform.variables.enroll_received_date\n",
    "        fitness_for_duty_request_flag: str = db_transform.variables.fitness_for_duty_request_flag\n",
    "        fitness_for_duty_ship_date: str = db_transform.variables.fitness_for_duty_ship_date\n",
    "        triage_date: str = db_transform.variables.triage_date\n",
    "        dose_count: str = db_transform.variables.dose_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.logging import get_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = Transform()\n",
    "logger = get_logger(f\"core.transforms.{transform.state}.{transform.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data model is hardcoded as a constant that will require a PR to edit for security\n",
    "column_renames = {\n",
    "    'transaction_date' : transform.transaction_date,\n",
    "    'pharmacy_code' : transform.pharmacy_code,\n",
    "    'pharmacy_npi' : transform.pharmacy_npi,\n",
    "    'pharmacy_hin' : transform.pharmacy_hin,\n",
    "    'pharmacy_name' : transform.pharmacy_name,\n",
    "    'pharmacy_ncpdp' : transform.pharmacy_ncpdp,\n",
    "    'pharmacy_address_1' : transform.pharmacy_address_1,\n",
    "    'pharmacy_address_2' : transform.pharmacy_address_2,\n",
    "    'pharmacy_city' : transform.pharmacy_city,\n",
    "    'pharmacy_state' : transform.pharmacy_state,\n",
    "    'pharmacy_zip' : transform.pharmacy_zip,\n",
    "    'transaction_type' : transform.transaction_type,\n",
    "    'pharmacy_transaction_id' : transform.pharmacy_transaction_id,\n",
    "    'transaction_sequence' : transform.transaction_sequence,\n",
    "    'referral_source' : transform.referral_source,\n",
    "    'referral_date' : transform.referral_date,\n",
    "    'longitudinal_patient_id' : transform.longitudinal_patient_id,\n",
    "    'pharmacy_patient_id' : transform.pharmacy_patient_id,\n",
    "    'patient_dob' : transform.patient_dob,\n",
    "    'hub_patient_id' : transform.hub_patient_id,\n",
    "    'bridge_patient' : transform.bridge_patient,\n",
    "    'hub_patient' : transform.hub_patient,\n",
    "    'patient_gender' : transform.patient_gender,\n",
    "    'dx_1' : transform.dx_1,\n",
    "    'dx_2' : transform.dx_2,\n",
    "    'status_date' : transform.status_date,\n",
    "    'status' : transform.status,\n",
    "    'substatus' : transform.substatus,\n",
    "    'customer_status' : transform.customer_status,\n",
    "    'customer_substatus' : transform.customer_substatus,\n",
    "    'customer_status_description' : transform.customer_status_description,\n",
    "    'hcp_last_name' : transform.hcp_last_name,\n",
    "    'hcp_first_name' : transform.hcp_first_name,\n",
    "    'hcp_address_1' : transform.hcp_address_1,\n",
    "    'hcp_address_2' : transform.hcp_address_2,\n",
    "    'hcp_city' : transform.hcp_city,\n",
    "    'hcp_state' : transform.hcp_state,\n",
    "    'hcp_zip' : transform.hcp_zip,\n",
    "    'hcp_phone' : transform.hcp_phone,\n",
    "    'hcp_specialty' : transform.hcp_specialty,\n",
    "    'hcp_npi' : transform.hcp_npi,\n",
    "    'hcp_dea_number' : transform.hcp_dea_number,\n",
    "    'hcp_facility' : transform.hcp_facility,\n",
    "    'rx_date' : transform.rx_date,\n",
    "    'rx_number' : transform.rx_number,\n",
    "    'rx_fills' : transform.rx_fills,\n",
    "    'rx_fill_number' : transform.rx_fill_number,\n",
    "    'rx_refills_remaining' : transform.rx_refills_remaining,\n",
    "    'prev_dispensed' : transform.prev_dispensed,\n",
    "    'ndc' : transform.ndc,\n",
    "    'brand' : transform.brand_column,\n",
    "    'medication' : transform.medication,\n",
    "    'quantity_dispensed' : transform.quantity_dispensed,\n",
    "    'uom_dispensed' : transform.uom_dispensed,\n",
    "    'days_supply' : transform.days_supply,\n",
    "    'ship_date' : transform.ship_date,\n",
    "    'ship_carrier' : transform.ship_carrier,\n",
    "    'ship_tracking_id' : transform.ship_tracking_id,\n",
    "    'ship_location' : transform.ship_location,\n",
    "    'ship_address_1' : transform.ship_address_1,\n",
    "    'ship_address_2' : transform.ship_address_2,\n",
    "    'ship_city' : transform.ship_city,\n",
    "    'ship_state' : transform.ship_state,\n",
    "    'ship_zip' : transform.ship_zip,\n",
    "    'has_medical_coverage_flag' : transform.has_medical_coverage_flag,\n",
    "    'primary_coverage_type' : transform.primary_coverage_type,\n",
    "    'primary_payer' : transform.primary_payer,\n",
    "    'primary_payer_type' : transform.primary_payer_type,\n",
    "    'primary_payer_subtype' : transform.primary_payer_subtype,\n",
    "    'primary_payer_group' : transform.primary_payer_group,\n",
    "    'primary_payer_bin' : transform.primary_payer_bin,\n",
    "    'primary_payer_iin' : transform.primary_payer_iin,\n",
    "    'primary_payer_pcn' : transform.primary_payer_pcn,\n",
    "    'primary_plan' : transform.primary_plan,\n",
    "    'primary_plan_type' : transform.primary_plan_type,\n",
    "    'secondary_coverage_type' : transform.secondary_coverage_type,\n",
    "    'secondary_payer' : transform.secondary_payer,\n",
    "    'secondary_payer_type' : transform.secondary_payer_type,\n",
    "    'secondary_payer_subtype' : transform.secondary_payer_subtype,\n",
    "    'secondary_payer_group' : transform.secondary_payer_group,\n",
    "    'secondary_payer_bin' : transform.secondary_payer_bin,\n",
    "    'secondary_payer_iin' : transform.secondary_payer_iin,\n",
    "    'secondary_payer_pcn' : transform.secondary_payer_pcn,\n",
    "    'secondary_plan' : transform.secondary_plan,\n",
    "    'secondary_plan_type' : transform.secondary_plan_type,\n",
    "    'primary_plan_paid' : transform.primary_plan_paid,\n",
    "    'secondary_plan_paid' : transform.secondary_plan_paid,\n",
    "    'primary_copay' : transform.primary_copay,\n",
    "    'primary_coins' : transform.primary_coins,\n",
    "    'primary_deductible' : transform.primary_deductible,\n",
    "    'primary_patient_responsibility' : transform.primary_patient_responsibility,\n",
    "    'secondary_copay' : transform.secondary_copay,\n",
    "    'secondary_coins' : transform.secondary_coins,\n",
    "    'secondary_deductible' : transform.secondary_deductible,\n",
    "    'secondary_patient_responsibility' : transform.secondary_patient_responsibility,\n",
    "    'copay_as_amount' : transform.copay_as_amount,\n",
    "    'other_payer_amount' : transform.other_payer_amount,\n",
    "    'transfer_pharmacy' : transform.transfer_pharmacy,\n",
    "    'bridge_quantity_dispensed' : transform.bridge_quantity_dispensed,\n",
    "    'prior_therapy_name' : transform.prior_therapy_name,\n",
    "    'pharmacy_parent_name' : transform.pharmacy_parent_name,\n",
    "    'hcp_state_license_number' : transform.hcp_state_license_number,\n",
    "    'patient_state' : transform.patient_state,\n",
    "    'dose_exchange_flag' : transform.dose_exchange_flag,\n",
    "    'dose_exchange_count' : transform.dose_exchange_count,\n",
    "    'dose_titration_quantity' : transform.dose_titration_quantity,\n",
    "    'dose_titration_count' : transform.dose_titration_count,\n",
    "    'oxygen_flag' : transform.oxygen_flag,\n",
    "    'patient_zip' : transform.patient_zip,\n",
    "    'secondary_payer_flag' : transform.secondary_payer_flag,\n",
    "    'restatement_flag' : transform.restatement_flag,\n",
    "    'aggregator_transaction_id' : transform.aggregator_transaction_id,\n",
    "    'primary_pbm_name' : transform.primary_pbm_name,\n",
    "    'referral_number' : transform.referral_number,\n",
    "    'hcp_middle_name' : transform.hcp_middle_name,\n",
    "    'hcp_suffix' : transform.hcp_suffix,\n",
    "    'pharmacy_dea_number' : transform.pharmacy_dea_number,\n",
    "    'primary_prior_auth_required_flag' : transform.primary_prior_auth_required_flag,\n",
    "    'primary_prior_auth_expiration_date' : transform.primary_prior_auth_expiration_date,\n",
    "    'patient_consent_date' : transform.patient_consent_date,\n",
    "    'primary_cost_type' : transform.primary_cost_type,\n",
    "    'primary_cost_amount' : transform.primary_cost_amount,\n",
    "    'patient_support_1' : transform.patient_support_1,\n",
    "    'patient_support_2' : transform.patient_support_2,\n",
    "    'patient_oop_program_name' : transform.patient_oop_program_name,\n",
    "    'bridge_quantity_dispensed_2' : transform.bridge_quantity_dispensed_2,\n",
    "    'enroll_received_date' : transform.enroll_received_date,\n",
    "    'fitness_for_duty_request_flag' : transform.fitness_for_duty_request_flag,\n",
    "    'fitness_for_duty_ship_date' : transform.fitness_for_duty_ship_date,\n",
    "    'triage_date' : transform.triage_date,\n",
    "    'dose_count' : transform.dose_count\n",
    "}\n",
    "\n",
    "# Likewise, the list of required columns is kept as well\n",
    "required_columns = [\n",
    "    \"pharmacy_npi\",\n",
    "    \"transaction_sequence\",\n",
    "    \"pharmacy_patient_id\",\n",
    "    \"status_date\",\n",
    "    \"hcp_last_name\",\n",
    "    \"hcp_first_name\",\n",
    "    \"hcp_address_1\",\n",
    "    \"hcp_city\",\n",
    "    \"hcp_state\",\n",
    "    \"hcp_npi\",\n",
    "    \"ndc\",\n",
    "    \"primary_coverage_type\",\n",
    "    \"primary_payer_type\",\n",
    "    \"patient_state\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description\n",
    "What does this transformation do? be specific.\n",
    "\n",
    "![what does your transform do](assets/what.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This transform takes patient status data and maps it to our internal schema. It rejects files missing the defined required columns, cuts any extra columns they gave us, and adds in the missing columns with all NaN's."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import boto3\n",
    "from s3parq import fetch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get dataframes only by file name\n",
    "# This has to be done through string manipulation on files under the prefix\n",
    "# TODO: Find a more elegant solution\n",
    "#    If problematique files get ingested without file name barrier it would never fetch properly\n",
    "\n",
    "input_contract = DatasetContract(parent=transform.publish_contract.parent, \n",
    "                                child=transform.publish_contract.child,\n",
    "                                state=\"ingest\",\n",
    "                                dataset=transform.ingest_source_transform\n",
    "                                )\n",
    "\n",
    "ingest_prefix=input_contract.key+\"/\"+transform.ingest_source_file_prefix\n",
    "bucket = transform.publish_contract.env\n",
    "\n",
    "# Need : set of file names\n",
    "#    Fetching will be iterating over them, fetching with key-less S3 paths\n",
    "\n",
    "# Get names of all files under key\n",
    "file_names = set()\n",
    "files_with_prefix = []\n",
    "s3_client = boto3.client('s3')\n",
    "paginator = s3_client.get_paginator('list_objects')\n",
    "operation_parameters = {'Bucket': bucket,\n",
    "                        'Prefix': ingest_prefix}\n",
    "page_iterator = paginator.paginate(**operation_parameters)\n",
    "for page in page_iterator:\n",
    "    if not \"Contents\" in page.keys():\n",
    "        break\n",
    "\n",
    "    for item in page['Contents']:\n",
    "        if item['Key'].endswith('.parquet'):\n",
    "            files_with_prefix.append(item['Key'])\n",
    "            \n",
    "# Remove key\n",
    "key_len = len(ingest_prefix)\n",
    "\n",
    "def subtract_key(file):\n",
    "    # +1 due to the extra slash at the end\n",
    "    return file[(key_len + 1):]\n",
    "\n",
    "files_without_prefix = [subtract_key(file) for file in files_with_prefix]\n",
    "\n",
    "for file_path in files_without_prefix:\n",
    "    # Split up so other parts can be easily deleted\n",
    "    unparsed_parts = file_path.split(\"/\")\n",
    "    \n",
    "    # Remove parquet names at the end\n",
    "    del unparsed_parts[-1]\n",
    "\n",
    "    # Remove all partition columns\n",
    "    for part in unparsed_parts:\n",
    "        if \"=\" not in part:\n",
    "            file_names.add(part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom exception class, this makes exception handling specific\n",
    "# Given the try except, other exceptions could catch valid errors occuring\n",
    "class MissingRequiredColumnError(Exception):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_required_columns(df: pd.DataFrame)->None:\n",
    "    logger.debug(f\"Expecting the following columns : {list(column_renames.values())}\")\n",
    "    logger.debug(f\"Dataframe has these columns : {list(df.columns)}\")\n",
    "\n",
    "    # Gets the pre-mapping required column names\n",
    "    required_columns_preschema = [value for key,value in column_renames.items() if key in required_columns]\n",
    "    \n",
    "    logger.debug(f\"The following columns are required : {required_columns_preschema}\")\n",
    "    \n",
    "    missing_required_columns = set(required_columns_preschema) - set(df.columns)\n",
    "\n",
    "    if missing_required_columns:\n",
    "        logger.error(\"Data does not have all required columns.\")\n",
    "        raise MissingRequiredColumnError(f\"Missing required columns : {missing_required_columns}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dataframe=pd.DataFrame()\n",
    "run_filter = [{\"partition\": \"__metadata_run_id\", \"comparison\": \"==\", \"values\": [run_id]}]\n",
    "\n",
    "for file_name in file_names:\n",
    "    logger.debug(f\"Retrieving data from path : {ingest_prefix}\")\n",
    "    logger.debug(f\"Ingesting data under file name : {file_name} , with run_id : {run_id}\")\n",
    "    \n",
    "    # Run with parallel as False since its much slower if the data is not large\n",
    "    file_df = fetch(bucket=bucket, key=(ingest_prefix+\"/\"+file_name), filters=run_filter, parallel=False)\n",
    "    \n",
    "    logger.debug(f\"File data fetched, fetched dataframe shape : {file_df.shape}\")\n",
    "    \n",
    "    # Check base requirement fullfillment\n",
    "    try:\n",
    "        check_required_columns(file_df)\n",
    "    except MissingRequiredColumnError:\n",
    "        # TODO: this needs to send a notification! That is occuring in a separate story however\n",
    "        logger.info(f\"File :   {file_name}   : is missing required columns and is being skipped.\")\n",
    "        continue\n",
    "        \n",
    "    logger.debug(\"File meets requirements.\")\n",
    "    \n",
    "    # First cut down to the necesarry columns in case of accidental extras - Pandas wont catch those\n",
    "    extra_columns = set(file_df.columns) - set(column_renames.values())\n",
    "    file_df = file_df.drop(axis=1,labels=list(extra_columns))\n",
    "\n",
    "    # Rename based on above created configuration variables\n",
    "    # Reverse dictionary made since theres a clash in order needs\n",
    "    column_renames_pandas_style = {value: key for key, value in column_renames.items()}\n",
    "    file_df = file_df.rename(column_renames_pandas_style, axis=\"columns\")\n",
    "    \n",
    "    # Add missing columns to match schema and fill with NaN\n",
    "    missing_columns = set(column_renames.keys()) - set(file_df.columns)\n",
    "    for column in missing_columns:\n",
    "        file_df[column] = \"\"\n",
    "    \n",
    "    logger.debug(\"File successfully appended.\")\n",
    "    final_dataframe = final_dataframe.append(file_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Publish"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## that's it - just provide the final dataframe to the var final_dataframe and we take it from there\n",
    "transform.publish_contract.publish(final_dataframe, run_id, session, False)\n",
    "session.close()"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
