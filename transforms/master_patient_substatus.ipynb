{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"CELL1\"></a>\n",
    "## CELL 1 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-01 13:03:35,510 - core.helpers.session_helper.SessionHelper - INFO - Creating session for dev environment...\n",
      "2019-08-01 13:03:35,574 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating administrator mocks.\n",
      "2019-08-01 13:03:35,586 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating administrator mocks.\n",
      "2019-08-01 13:03:35,587 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating pharmaceutical company mocks.\n",
      "2019-08-01 13:03:35,593 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating pharmaceutical company mocks.\n",
      "2019-08-01 13:03:35,594 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating brand mocks.\n",
      "2019-08-01 13:03:35,598 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating brand mocks.\n",
      "2019-08-01 13:03:35,599 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating segment mocks.\n",
      "2019-08-01 13:03:35,604 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating segment mocks.\n",
      "2019-08-01 13:03:35,605 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating pipeline type mocks.\n",
      "2019-08-01 13:03:35,610 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating pipeline type mocks.\n",
      "2019-08-01 13:03:35,611 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating pipeline mocks.\n",
      "2019-08-01 13:03:35,618 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating pipeline mocks.\n",
      "2019-08-01 13:03:35,619 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating pipeline state type mocks.\n",
      "2019-08-01 13:03:35,626 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating pipeline state type mocks.\n",
      "2019-08-01 13:03:35,627 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating pipeline state mocks.\n",
      "2019-08-01 13:03:35,631 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating pipeline state mocks.\n",
      "2019-08-01 13:03:35,632 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating tag mocks.\n",
      "2019-08-01 13:03:35,639 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating tag mocks.\n",
      "2019-08-01 13:03:35,640 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating transformation_template mocks.\n",
      "2019-08-01 13:03:35,646 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating transformation_template mocks.\n",
      "2019-08-01 13:03:35,647 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating bridge table mocks for transformation_templates <=> tags.\n",
      "2019-08-01 13:03:35,652 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating transformation_templates_tags mocks.\n",
      "2019-08-01 13:03:35,654 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating transformation mocks.\n",
      "2019-08-01 13:03:35,660 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating transformation mocks.\n",
      "2019-08-01 13:03:35,661 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating transformation_variables mocks\n",
      "2019-08-01 13:03:35,666 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating transformation_variables mocks.\n",
      "2019-08-01 13:03:35,667 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Generating run_events mocks.\n",
      "2019-08-01 13:03:35,670 - core.helpers.configuration_mocker.ConfigurationMocker - DEBUG - Done generating run_events mocks.\n",
      "2019-08-01 13:03:35,671 - core.helpers.session_helper.SessionHelper - INFO - Done. Created dev session with mock data.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"CELL 1\n",
    "builds and returns a database session\n",
    "local assumes a psql instance in a local docker container\n",
    "only postgres database is supported for configuration_application at this time\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "gets env-based configuration secret\n",
    "returns a session to the configuration db\n",
    "for dev env it pre-populates the database with helper and seed data\n",
    "\"\"\"\n",
    "from core.helpers.session_helper import SessionHelper\n",
    "session = SessionHelper().session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONFIGURATION - PLEASE TOUCH\n",
    "### <font color=pink>This cell will be off in production as configurations will come from the configuration postgres DB</color>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "************ CONFIGURATION - PLEASE TOUCH **************\n",
    "Pipeline Builder configuration: creates configurations from variables specified here!!\n",
    "This cell will be off in production as configurations will come from the configuration postgres DB.\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "PIPELINE STATE:\n",
    "\n",
    "raw-->ingest-->master-->enhance-->enrich-->metrics-->dimensional\n",
    "\n",
    "\"\"\"\n",
    "# config vars: this dataset\n",
    "config_pharma = \"sun\" # the pharmaceutical company which owns {brand}\n",
    "config_brand = \"ilumya\" # the brand this pipeline operates on\n",
    "config_state = \"master\" # the state this transform runs in\n",
    "config_name = \"master_patient_substatus\" # the name of this transform!!!, which is the name of this notebook without .ipynb\n",
    "\n",
    "# input vars: dataset to fetch. \n",
    "# Recall that a contract published to S3 has a key format branch/pharma/brand/state/name\n",
    "input_branch = \"sun-extract-validation\"\n",
    "# None\n",
    "# if None, input_branch is automagically set to your working branch\n",
    "input_pharma = \"sun\"\n",
    "input_brand = \"ilumya\"\n",
    "input_state = \"ingest\"\n",
    "input_name = \"symphony_health_association_ingest_column_mapping\"\n",
    "\n",
    "#This contract defines the base of the output structure of data into S3.\n",
    "#\n",
    "#contract structure in s3: \n",
    "#s3:// {ENV} / {BRANCH} / {PARENT} / {CHILD} / {STATE} / {name of input}\n",
    "#\n",
    "#ENV - environment Must be one of development, uat, production.\n",
    "#Prefixed with integrichain- due to global unique reqirement\n",
    "#BRANCH - the software branch for development this will be the working pull request (eg pr-225)\n",
    "#in uat this will be edge, in production this will be master\n",
    "#PARENT - The top level source identifier\n",
    "#this is generally the customer (and it is aliased as such) but can be IntegriChain for internal sources,\n",
    "#or another aggregator for future-proofing\n",
    "#CHILD - The sub level source identifier, generally the brand (and is aliased as such)\n",
    "#STATE - One of: raw, ingest, master, enhance, enrich, metrics\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=orange>SETUP - DON'T TOUCH </font>\n",
    "Populating config mocker based on config parameters..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-01 13:03:42,135 - core.logging - DEBUG - Adding/getting mocks for specified configurations...\n",
      "2019-08-01 13:03:42,172 - core.logging - DEBUG - Done. Creating mock run event and committing results to configuration mocker.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "************ SETUP - DON'T TOUCH **************\n",
    "Populating config mocker based on config parameters...\n",
    "\"\"\"\n",
    "import core.helpers.pipeline_builder as builder\n",
    "\n",
    "ids = builder.build(config_pharma, config_brand, config_state, config_name, session)\n",
    "\"\"\"\n",
    "RETURNS: A list of 2 items: [transformation_id, run_id] where transformation_id corresponds\n",
    "to the configuration created/found for {transformation} and run_id is a randomly generated 6 digit\n",
    "number (to avoid publishing to the same place with the same dataset)\n",
    "\"\"\"\n",
    "transform_id = ids[0]\n",
    "run_id = ids[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n",
      "706377\n"
     ]
    }
   ],
   "source": [
    "# debug only\n",
    "print(transform_id)\n",
    "print(run_id)\n",
    "# e.g:\n",
    "# 6\n",
    "# 644707\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=orange>SETUP - DON'T TOUCH </font>\n",
    "This section imports data from the configuration database\n",
    "and should not need to be altered or otherwise messed with. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"************ SETUP - DON'T TOUCH **************\n",
    "This section imports data from the configuration database\n",
    "and should not need to be altered or otherwise messed with. \n",
    "~~These are not the droids you are looking for~~\n",
    "\"\"\"\n",
    "from core.constants import BRANCH_NAME, ENV_BUCKET, BATCH_JOB_QUEUE\n",
    "from core.helpers.session_helper import SessionHelper\n",
    "from core.models.configuration import Transformation\n",
    "from dataclasses import dataclass\n",
    "from core.dataset_contract import DatasetContract\n",
    "from core.logging import get_logger\n",
    "\n",
    "db_transform = session.query(Transformation).filter(Transformation.id == transform_id).one()\n",
    "\n",
    "@dataclass\n",
    "class DbTransform:\n",
    "    id: int = db_transform.id ## the instance id of the transform in the config app\n",
    "    name: str = db_transform.transformation_template.name ## the transform name in the config app\n",
    "    state: str = db_transform.pipeline_state.pipeline_state_type.name ## the pipeline state, one of raw, ingest, master, enhance, enrich, metrics, dimensional\n",
    "    branch:str = BRANCH_NAME ## the git branch for this execution \n",
    "    brand: str = db_transform.pipeline_state.pipeline.brand.name ## the pharma brand name\n",
    "    pharmaceutical_company: str = db_transform.pipeline_state.pipeline.brand.pharmaceutical_company.name # the pharma company name\n",
    "    publish_contract: DatasetContract = DatasetContract(branch=BRANCH_NAME,\n",
    "                            state=db_transform.pipeline_state.pipeline_state_type.name,\n",
    "                            parent=db_transform.pipeline_state.pipeline.brand.pharmaceutical_company.name,\n",
    "                            child=db_transform.pipeline_state.pipeline.brand.name,\n",
    "                            dataset=db_transform.transformation_template.name)\n",
    "        \n",
    "logger = get_logger(f\"core.transforms.{transform.state}.{transform.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DC-578_PatientSubStatus\n",
      "ichain-dev\n",
      "dev-core\n"
     ]
    }
   ],
   "source": [
    "#debug only\n",
    "print(BRANCH_NAME)\n",
    "print(ENV_BUCKET)\n",
    "print(BATCH_JOB_QUEUE)\n",
    "#e.g: \n",
    "#DC-578_PatientStatus\n",
    "#ichain-dev\n",
    "#dev-core"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "# CORE Cartridge Notebook::[master_patient_substatus]\n",
    "![CORE Logo](assets/coreLogo.png) \n",
    "\n",
    "---\n",
    "## Keep in Mind\n",
    "Good Transforms Are...\n",
    "- **singular in purpose:** good transforms do one and only one thing, and handle all known cases for that thing. \n",
    "- **repeatable:** transforms should be written in a way that they can be run against the same dataset an infinate number of times and get the same result every time. \n",
    "- **easy to read:** 99 times out of 100, readable, clear code that runs a little slower is more valuable than a mess that runs quickly. \n",
    "- **No 'magic numbers':** if a variable or function is not instantly obvious as to what it is or does, without context, maybe consider renaming it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow - how to use this notebook to make science\n",
    "#### Data Science\n",
    "1. **Document your transform.** Fill out the _description_ cell below describing what it is this transform does; this will appear in the configuration application where Ops will create, configure and update pipelines. \n",
    "1. **Define your config object.** Fill out the _configuration_ cell below the commented-out guide to define the variables you want ops to set in the configuration application (these will populate here for every pipeline). \n",
    "2. **Build your transformation logic.** Use the transformation cell to do that magic that you do. \n",
    "![caution](assets/cautionTape.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CONFIGURATION - VARIABLES - PLEASE TOUCH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TRANSFORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" \n",
    "CONFIGURATION ********* VARIABLES - PLEASE TOUCH ********* \n",
    "This section defines what you expect to get from the configuration application \n",
    "in a single \"transform\" object. Define the vars you need here, and comment inline to the right of them \n",
    "for all-in-one documentation. \n",
    "Engineering will build a production \"transform\" object for every pipeline that matches what you define here.\n",
    "\n",
    "@@@ FORMAT OF THE DATA CLASS IS: @@@ \n",
    "\n",
    "<variable_name>: <data_type> #<comment explaining what the value is to future us>\n",
    "e.g.\n",
    "class Transform(DbTransform):\n",
    "    some_ratio: float\n",
    "    site_name: str\n",
    "\n",
    "~~These ARE the droids you are looking for~~\n",
    "\"\"\"\n",
    "\"\"\"\n",
    "imports\n",
    "\"\"\"\n",
    "import pandas as pd\n",
    "import re \n",
    "\n",
    "\n",
    "\n",
    " \n",
    "class Transform(DbTransform):\n",
    "    '''\n",
    "    YOUR properties go here!!\n",
    "    Variable properties should be assigned to the exact name of\n",
    "    the transformation as it appears in the Jupyter notebook filename.\n",
    "    ''' \n",
    "\n",
    "    ## col of interest\n",
    "    ##Field\t        Description\t     Data Type / Format\tComments\tRequired\t             OLD Name in Data Model\tNew Name in Data Model\t<-- Map to\tBIPI\tSun\tAlkermes - Status\n",
    "    ##Sub Status\tSub-StatusCode\tX(50)\t\t                    Required if Available\tsubstatus\t             substatus\t\t\t\t\n",
    "    col_substatus: str \n",
    "    customer_name: str\n",
    "        \n",
    "    def master_substatus(customer_name:str):\n",
    "        try:\n",
    "            \n",
    "            if customer_name=='sun':\n",
    "                substatus_dict = Transform.master_substatus_sun()\n",
    "                substatus_conversion_dict = Transform.master_substatus_conversion_sun()\n",
    "            elif customer_name=='bi':\n",
    "                substatus_dict = Transform.master_substatus_bi()\n",
    "            elif customer_name=='alkermes':\n",
    "                substatus_dict = Transform.master_substatus_alkermes()\n",
    "            else:\n",
    "                #go = False # something did not work\n",
    "                logger.exception('expecting customer name as sun bi or alkermes')\n",
    "                raise Exception('expecting customer name as sun bi or alkermes') \n",
    "        except Exception as e:\n",
    "            go = False # something did not work\n",
    "            logger.exception(\"exception:\".format(e))\n",
    "            raise Exception(str(e))    \n",
    "        return substatus_dict, substatus_conversion_dict  \n",
    "    \n",
    "    def master_substatus_sun():\n",
    "        # need to input/ define for ic-gold mapping\n",
    "        # for substatus for sun\n",
    "        # temporary until furture User defines\n",
    "        # IC - GOLD persistence solution\n",
    "        substatus_dict = {}\n",
    "        substatus_dict[1]='ALT THERAPY'\n",
    "        substatus_dict[2]='APPEAL'\n",
    "        substatus_dict[3]='BENEFITS'\n",
    "        substatus_dict[4]='COPAY ASSISTANCE'\n",
    "        substatus_dict[5]='DELAY'\n",
    "        substatus_dict[6]='DOSAGE'\n",
    "        substatus_dict[7]='FORMULARY'\n",
    "        substatus_dict[8]='FOUNDATION'\n",
    "        substatus_dict[9]='HOLD OTHER'\n",
    "        substatus_dict[10]='HOLD RTS'\n",
    "        substatus_dict[11]='INFORMATION'\n",
    "        substatus_dict[12]='INS OTHER'\n",
    "        substatus_dict[13]='INSURANCE COPAY'\n",
    "        substatus_dict[14]='INSURANCE DENIED'\n",
    "        substatus_dict[15]='INSURANCE HOLD'\n",
    "        substatus_dict[16]='INSURANCE OON'\n",
    "        substatus_dict[17]='INSURANCE OTHER'\n",
    "        substatus_dict[18]='INVENTORY HOLD'\n",
    "        substatus_dict[19]='MATERIAL'\n",
    "        substatus_dict[20]='NEW'\n",
    "        substatus_dict[21]='OTHER'\n",
    "        substatus_dict[22]='PA'\n",
    "        substatus_dict[23]='PATIENT CONTACT'\n",
    "        substatus_dict[24]='PATIENT DECEASED'\n",
    "        substatus_dict[25]='PATIENT END'\n",
    "        substatus_dict[26]='PATIENT FINANCIAL'\n",
    "        substatus_dict[27]='PATIENT HOLD'\n",
    "        substatus_dict[28]='PATIENT RESPONSE'\n",
    "        substatus_dict[29]='PRESCRIBER'\n",
    "        substatus_dict[30]='PRESCRIBER END'\n",
    "        substatus_dict[31]='PRESCRIBER HOLD'\n",
    "        substatus_dict[32]='PT HOLD'\n",
    "        substatus_dict[33]='QUANTITY'\n",
    "        substatus_dict[34]='READY'\n",
    "        substatus_dict[35]='SERVICES END'\n",
    "        substatus_dict[36]='SHIPMENT'\n",
    "        substatus_dict[37]='STEP EDIT'\n",
    "        substatus_dict[38]='THERAPY COMPLETE'\n",
    "        substatus_dict[39]='THERAPY END'\n",
    "        substatus_dict[40]='THERAPY HOLD'\n",
    "        substatus_dict[41]='TRANSFER HUB'\n",
    "        substatus_dict[42]='TRANSFER SP'\n",
    "        substatus_dict[43]='TREATMENT DELAY'\n",
    "        return substatus_dict\n",
    "   \n",
    "\n",
    "    def master_substatus_conversion_sun():\n",
    "        substatus_conversion_dict = {}\n",
    "        substatus_conversion_dict = {'BENEFITS INVESTIGATION':'BENEFITS','INS OON ':'INSURANCE OON','OTHER ':'OTHER','P05':'PA','PATENT RESPONSE':'PATIENT RESPONSE','PATIENT  RESPONSE':'PATIENT RESPONSE','PATIENT RESPOSNE':'PATIENT RESPONSE','PRESCRIBERHOLD':'PRESCRIBER HOLD','TRANSER SP':'TRANSFER SP'}\n",
    "        return substatus_conversion_dict\n",
    "    \n",
    "    \n",
    "    def master_substatus_bi():\n",
    "        substatus_dict = {}\n",
    "        return substatus_dict\n",
    "\n",
    "    \n",
    "    def master_substatus_alkermes():\n",
    "        substatus_dict = {}\n",
    "        return substatus_dict\n",
    "\n",
    "    \n",
    "    def master_patient_substatus(self,df):\n",
    "        try:        \n",
    "            logger.info('try:')\n",
    "            go = False # assume things are not working YET.\n",
    "           \n",
    "            dffail = pd.DataFrame() # initialize df for fails\n",
    "            \n",
    "            # df in\n",
    "\n",
    "            #dfSize = df.size\n",
    "            dfShape = df.shape\n",
    "            logger.info('df in  shape: {} {}'.format(dfShape[0],dfShape[1])) \n",
    "            logger.info('df in {}'.format(df.head()))  \n",
    "            \n",
    "            # am I expecting certain column names? YES \n",
    "            substatusColNameExpected = transform.col_substatus\n",
    "            \n",
    "            logger.info('expecting column name patient sub status as:{}'.format(substatusColNameExpected))\n",
    "            columnNamesArr = df.columns.values.tolist()\n",
    "            logger.info('df column names:{}'.format(columnNamesArr))\n",
    "            \n",
    "            if substatusColNameExpected in columnNamesArr:\n",
    "                logger.info('Clean: space Strip and Upper and other cleanup...')  \n",
    "\n",
    "                df[substatusColNameExpected]= df[substatusColNameExpected].apply(lambda x: x.upper() if x is not None else x)   \n",
    "                df[substatusColNameExpected]= df[substatusColNameExpected].apply(lambda x: x.strip() if x is not None else x)\n",
    "                df[substatusColNameExpected]= df[substatusColNameExpected].apply(lambda x: x.replace('_',' ').replace('\\r', '').replace('\\t', '').replace('\\w', '') if x is not None else x)\n",
    "                #df[substatusColNameExpected]= df[substatusColNameExpected].apply(lambda x: x.replace('[^a-zA-Z0-9]', '') if x is not None else x)\n",
    "                # re.sub(r'\\s+', ' ',   stringin)  \n",
    "\n",
    "\n",
    "                # master data IC-GOLD substatus\n",
    "                substatus_dict = {}\n",
    "                substatus_conversion_dict = {}\n",
    "                substatus_dict, substatus_conversion_dict = Transform.master_substatus(transform.customer_name)\n",
    "                print(substatus_conversion_dict)\n",
    "                # store the golden values in a list\n",
    "                substatus_list = list(substatus_dict.values())           \n",
    "                logger.info('Gold Domain List:{}'.format(substatus_list))  \n",
    "                \n",
    "                # apply master conversions\n",
    "                #df = df[substatusColNameExpected].map(substatus_conversion_dict).fillna(df[substatusColNameExpected])\n",
    "                #df.replace({substatusColNameExpected: substatus_conversion_dict})\n",
    "                #df[substatusColNameExpected]=df[substatusColNameExpected].notnull().map(substatus_conversion_dict).fillna(df[substatusColNameExpected])\n",
    "                df[substatusColNameExpected].replace(substatus_conversion_dict, inplace=True)\n",
    "                \n",
    "                \n",
    "                # what fails\n",
    "                dffail = df.loc[~df[substatusColNameExpected].isin(substatus_list)]\n",
    "                # apply master selection for the column of interest\n",
    "                # what passes\n",
    "                df = df.loc[df[substatusColNameExpected].isin(substatus_list)]\n",
    "                \n",
    "                # meta data log for what comes out of the function pass and fail df\n",
    "                dfOutSize = df.size\n",
    "                dfOutShape = df.shape\n",
    "                dffailSize = dffail.size\n",
    "                dffailShape = dffail.shape\n",
    "                logger.info('df in   shape: {} {}'.format(dfShape[0],dfShape[1]))                 \n",
    "                logger.info('df pass shape: {} {}'.format(dfOutShape[0],dfOutShape[1]))\n",
    "                logger.info('df fail shape: {} {}'.format(dffailShape[0],dffailShape[1]))  \n",
    "                # meta data log for what comes out of the function pass df\n",
    "                logger.info('df pass {}'.format(df.head()))\n",
    "                # meta data log for what comes out of the function fail df\n",
    "                logger.info('df fail {}'.format(dffail.head()))  \n",
    "                go = True\n",
    "            else:\n",
    "                go = False # something did not work\n",
    "                logger.exception('expecting column name for patient substatus if/else exception raise')\n",
    "                raise Exception(\"sub_status ColNameExpected NOT in columnNamesArr\")              \n",
    "        except Exception as e:\n",
    "            go = False # something did not work\n",
    "            logger.exception(\"exception:\".format(e))\n",
    "            raise Exception(str(e))\n",
    "        else:\n",
    "            pass\n",
    "        finally:\n",
    "            pass\n",
    "        return df,dffail,go\n",
    "                \n",
    "\n",
    "transform = Transform()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *Please place your value assignments for development below !!!*\n",
    "### <font color=pink>This cell will be turned off in production, Engineering will set to pull from the configuration</color>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Please place your value assignments for development here!!\n",
    "## This cell will be turned off in production and Engineering will set to pull from the configuration application instead\n",
    "## For the last example, this could look like...\n",
    "## transform.some_ratio = 0.6\n",
    "## transform.site_name = \"WALGREENS\"\n",
    "\n",
    "transform.col_substatus = 'sub_status'\n",
    "transform.customer_name = 'sun'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Description\n",
    "What does this transformation do? be specific.\n",
    "\n",
    "![what does your transform do](assets/what.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Planned\n",
    "1. Collect all unique raw patient substatus instances\n",
    "2. Auto-map as many raw patient substatus instances to a defined cleansed data model per **Customer**\n",
    "\n",
    "3. Process for identifying and manually mapping where auto-map fails.\n",
    "4. Do not publish un-mapped instances. Drop them, give us the ability to triage and map to IC-gold in a later event.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FETCH DATA - TOUCH, BUT CAREFULLY\n",
    "### <font color=pink>This cell will be turned off in production, as the input_contract will be handled by the pipeline</color>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-01 13:04:27,863 - core.transforms.master.master_patient_substatus - INFO - FETCH DATA CELL - TOUCH - This cell will be turned off in production, as the input_contract will be handled by the pipeline. \n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "************ FETCH DATA - TOUCH, BUT CAREFULLY **************\n",
    "This cell will be turned off in production, as the input_contract will be handled by the pipeline.\n",
    "\"\"\"\n",
    "logger.info(\"FETCH DATA CELL - TOUCH - This cell will be turned off in production, as the input_contract will be handled by the pipeline. \")\n",
    "\n",
    "# for testing / development only\n",
    "run_id = 3\n",
    "\n",
    "if not input_branch:\n",
    "    input_branch = BRANCH_NAME\n",
    "input_contract = DatasetContract(branch=input_branch,\n",
    "                                 state=input_state, \n",
    "                                 parent=input_pharma, \n",
    "                                 child=input_brand, \n",
    "                                 dataset=input_name)\n",
    "run_filter = []\n",
    "run_filter.append(dict(partition=\"__metadata_run_id\", comparison=\"==\", values=[run_id]))\n",
    "# IF YOU HAVE PUBLISHED DATA MULTIPLE TIMES, uncomment the above line and change the int to the run_id to fetch.\n",
    "# Otherwise, you will have duplicate values in your fetched dataset!\n",
    "\n",
    "# bypass/comment out when unit testing individual parquet files\n",
    "#df = input_contract.fetch(filters=run_filter)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## *<font color=grey>unit test development only*</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n",
    "import s3fs\n",
    "\n",
    "def pandas_from_parquet_s3(file_path):  \n",
    "    s3 = s3fs.S3FileSystem()\n",
    "    df = (\n",
    "        pq\n",
    "        .ParquetDataset(file_path, filesystem=s3)\n",
    "        .read_pandas()\n",
    "        .to_pandas()\n",
    "    )    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unit test/development \n",
    "# isolate on individual parquet files\n",
    "#TEST 1\n",
    "#df = pandas_from_parquet_s3('ichain-dev/sun-extract-validation/sun/ilumya/ingest/symphony_health_association_ingest_column_mapping/__metadata_run_id=3/d7ad974cef284e19aa7b5ac410220b96.parquet')\n",
    "# TEST 2\n",
    "# df = pandas_from_parquet_s3('ichain-dev/sun-extract-validation/sun/ilumya/ingest/symphony_health_association_ingest_column_mapping/__metadata_run_id=3/1a6ffd3598d442e38fbba66ea85a55a2.parquet')\n",
    "# TEST 3\n",
    "df = pandas_from_parquet_s3('ichain-dev/sun-extract-validation/sun/ilumya/ingest/symphony_health_association_ingest_column_mapping/__metadata_run_id=3/6eceb7ce59bd4dec8720316b4209b0e3.parquet')\n",
    "# TEST 4\n",
    "#df = pandas_from_parquet_s3('ichain-dev/sun-extract-validation/sun/ilumya/ingest/symphony_health_association_ingest_column_mapping/__metadata_run_id=3/5c00059d9fc04b0e8bc4ce764c50f3fb.parquet')\n",
    "# TEST 5\n",
    "#df = pandas_from_parquet_s3('ichain-dev/sun-extract-validation/sun/ilumya/ingest/symphony_health_association_ingest_column_mapping/__metadata_run_id=3/90ca3aa7b0bb4246a281591b013ff54e.parquet')\n",
    "\n",
    "# THEN ALL TEST use \n",
    "# then use the FETCH DATA - TOUCH, BUT CAREFULLY CELL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "size: 714260 shape: 10060 71\n"
     ]
    }
   ],
   "source": [
    "# unit test/development\n",
    "# before shot unit testing only\n",
    "dfSize = df.size\n",
    "dfShape = df.shape\n",
    "print('size: {} shape: {} {}'.format(dfSize,dfShape[0],dfShape[1])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unit test/development\n",
    "# needed to see the col(s) of interest\n",
    "pd.set_option('display.max_columns', 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rec_date</th>\n",
       "      <th>pharm_code</th>\n",
       "      <th>pharm_npi</th>\n",
       "      <th>transtype</th>\n",
       "      <th>pharm_transaction_id</th>\n",
       "      <th>trans_seq</th>\n",
       "      <th>ref_source</th>\n",
       "      <th>ref_date</th>\n",
       "      <th>program_id</th>\n",
       "      <th>pharmacy_id</th>\n",
       "      <th>pat_last_name</th>\n",
       "      <th>pat_first_name</th>\n",
       "      <th>pat_dob</th>\n",
       "      <th>pat_gender</th>\n",
       "      <th>pat_addr1</th>\n",
       "      <th>pat_addr2</th>\n",
       "      <th>pat_city</th>\n",
       "      <th>pat_state</th>\n",
       "      <th>pat_zip</th>\n",
       "      <th>dx1_code</th>\n",
       "      <th>dx2_code</th>\n",
       "      <th>status_date</th>\n",
       "      <th>status_code</th>\n",
       "      <th>sub_status</th>\n",
       "      <th>pres_last_name</th>\n",
       "      <th>...</th>\n",
       "      <th>ship_carrier</th>\n",
       "      <th>shiptracking_num</th>\n",
       "      <th>ship_location</th>\n",
       "      <th>ship_address</th>\n",
       "      <th>ship_city</th>\n",
       "      <th>ship_state</th>\n",
       "      <th>ship_zip</th>\n",
       "      <th>has_medical</th>\n",
       "      <th>primary_coverage_type</th>\n",
       "      <th>primary_payer_name</th>\n",
       "      <th>primary_payer_type</th>\n",
       "      <th>secondary_coverage_type</th>\n",
       "      <th>secondary_payer_name</th>\n",
       "      <th>secondary_payer_type</th>\n",
       "      <th>plan_paid_amt</th>\n",
       "      <th>pat_copay</th>\n",
       "      <th>copay_assist_amount</th>\n",
       "      <th>oth_payer_amt</th>\n",
       "      <th>xfer_pharmname</th>\n",
       "      <th>msa_patient_id</th>\n",
       "      <th>msa_patient_bmap</th>\n",
       "      <th>__metadata_run_timestamp</th>\n",
       "      <th>__metadata_app_version</th>\n",
       "      <th>__metadata_output_contract</th>\n",
       "      <th>__metadata_transform_timestamp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20181024115959</td>\n",
       "      <td>ACCREDO</td>\n",
       "      <td>1346208949</td>\n",
       "      <td>COM</td>\n",
       "      <td>279133432018102401</td>\n",
       "      <td>0</td>\n",
       "      <td>DIRECT</td>\n",
       "      <td>20181019120000</td>\n",
       "      <td>None</td>\n",
       "      <td>27913343</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>00</td>\n",
       "      <td>L40.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20181024115959</td>\n",
       "      <td>CANCELLED</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>None</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Y</td>\n",
       "      <td>MEDICAL</td>\n",
       "      <td>GENERAL DIRECT</td>\n",
       "      <td>COMMERCIAL</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NNNNV</td>\n",
       "      <td>2019-07-01 13:25:07</td>\n",
       "      <td>0.0.11</td>\n",
       "      <td>s3://ichain-dev/sun-extract-validation/sun/ilu...</td>\n",
       "      <td>2019-07-01 13:35:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20181025115959</td>\n",
       "      <td>ACCREDO</td>\n",
       "      <td>1346208949</td>\n",
       "      <td>COM</td>\n",
       "      <td>278370982018102502</td>\n",
       "      <td>0</td>\n",
       "      <td>DIRECT</td>\n",
       "      <td>20181022120000</td>\n",
       "      <td>None</td>\n",
       "      <td>27837098</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>00</td>\n",
       "      <td>L40.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20181025115959</td>\n",
       "      <td>CANCELLED</td>\n",
       "      <td>INSURANCE OON</td>\n",
       "      <td>GREENBERG</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Y</td>\n",
       "      <td>MEDICAL</td>\n",
       "      <td>BROWN &amp; TOLAND MEDICAL GRP</td>\n",
       "      <td>COMMERCIAL</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NNNVV</td>\n",
       "      <td>2019-07-01 13:25:07</td>\n",
       "      <td>0.0.11</td>\n",
       "      <td>s3://ichain-dev/sun-extract-validation/sun/ilu...</td>\n",
       "      <td>2019-07-01 13:35:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20181029115959</td>\n",
       "      <td>ACCREDO</td>\n",
       "      <td>1346208949</td>\n",
       "      <td>COM</td>\n",
       "      <td>279181482018102903</td>\n",
       "      <td>0</td>\n",
       "      <td>DIRECT</td>\n",
       "      <td>20181024120000</td>\n",
       "      <td>None</td>\n",
       "      <td>27918148</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>M</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>00</td>\n",
       "      <td>L40.0</td>\n",
       "      <td>None</td>\n",
       "      <td>20181029115959</td>\n",
       "      <td>CANCELLED</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>SCIURBA</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Y</td>\n",
       "      <td>MEDICAL</td>\n",
       "      <td>GENERAL HORIZON BCBS NJ</td>\n",
       "      <td>COMMERCIAL</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NNNVV</td>\n",
       "      <td>2019-07-01 13:25:07</td>\n",
       "      <td>0.0.11</td>\n",
       "      <td>s3://ichain-dev/sun-extract-validation/sun/ilu...</td>\n",
       "      <td>2019-07-01 13:35:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20181102115959</td>\n",
       "      <td>ACCREDO</td>\n",
       "      <td>1346208949</td>\n",
       "      <td>COM</td>\n",
       "      <td>267244982018110204</td>\n",
       "      <td>0</td>\n",
       "      <td>DIRECT</td>\n",
       "      <td>20181030120000</td>\n",
       "      <td>None</td>\n",
       "      <td>26724498</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>00</td>\n",
       "      <td>Q84</td>\n",
       "      <td>L40.0</td>\n",
       "      <td>20181102115959</td>\n",
       "      <td>CANCELLED</td>\n",
       "      <td>INSURANCE OON</td>\n",
       "      <td>KNUCKLES</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Y</td>\n",
       "      <td>MEDICAL</td>\n",
       "      <td>ANTHEM BCBS OF KENTUCKY</td>\n",
       "      <td>MEDICARE</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NNNVV</td>\n",
       "      <td>2019-07-01 13:25:07</td>\n",
       "      <td>0.0.11</td>\n",
       "      <td>s3://ichain-dev/sun-extract-validation/sun/ilu...</td>\n",
       "      <td>2019-07-01 13:35:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20181106115959</td>\n",
       "      <td>ACCREDO</td>\n",
       "      <td>1346208949</td>\n",
       "      <td>COM</td>\n",
       "      <td>160618142018110605</td>\n",
       "      <td>0</td>\n",
       "      <td>DIRECT</td>\n",
       "      <td>20181102120000</td>\n",
       "      <td>None</td>\n",
       "      <td>16061814</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>F</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>00</td>\n",
       "      <td>696.1</td>\n",
       "      <td>None</td>\n",
       "      <td>20181106115959</td>\n",
       "      <td>CANCELLED</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>KORY</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>Y</td>\n",
       "      <td>MEDICAL</td>\n",
       "      <td>EXPRESS SCRIPTS</td>\n",
       "      <td>COMMERCIAL</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>NNNVV</td>\n",
       "      <td>2019-07-01 13:25:07</td>\n",
       "      <td>0.0.11</td>\n",
       "      <td>s3://ichain-dev/sun-extract-validation/sun/ilu...</td>\n",
       "      <td>2019-07-01 13:35:22</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         rec_date pharm_code   pharm_npi transtype pharm_transaction_id  \\\n",
       "0  20181024115959    ACCREDO  1346208949       COM   279133432018102401   \n",
       "1  20181025115959    ACCREDO  1346208949       COM   278370982018102502   \n",
       "2  20181029115959    ACCREDO  1346208949       COM   279181482018102903   \n",
       "3  20181102115959    ACCREDO  1346208949       COM   267244982018110204   \n",
       "4  20181106115959    ACCREDO  1346208949       COM   160618142018110605   \n",
       "\n",
       "  trans_seq ref_source        ref_date program_id pharmacy_id pat_last_name  \\\n",
       "0         0     DIRECT  20181019120000       None    27913343          None   \n",
       "1         0     DIRECT  20181022120000       None    27837098          None   \n",
       "2         0     DIRECT  20181024120000       None    27918148          None   \n",
       "3         0     DIRECT  20181030120000       None    26724498          None   \n",
       "4         0     DIRECT  20181102120000       None    16061814          None   \n",
       "\n",
       "  pat_first_name pat_dob pat_gender pat_addr1 pat_addr2 pat_city pat_state  \\\n",
       "0           None    None       None      None      None     None      None   \n",
       "1           None    None          F      None      None     None      None   \n",
       "2           None    None          M      None      None     None      None   \n",
       "3           None    None          F      None      None     None      None   \n",
       "4           None    None          F      None      None     None      None   \n",
       "\n",
       "  pat_zip dx1_code dx2_code     status_date status_code     sub_status  \\\n",
       "0      00    L40.0     None  20181024115959   CANCELLED          OTHER   \n",
       "1      00    L40.0     None  20181025115959   CANCELLED  INSURANCE OON   \n",
       "2      00    L40.0     None  20181029115959   CANCELLED          OTHER   \n",
       "3      00      Q84    L40.0  20181102115959   CANCELLED  INSURANCE OON   \n",
       "4      00    696.1     None  20181106115959   CANCELLED          OTHER   \n",
       "\n",
       "  pres_last_name  ... ship_carrier shiptracking_num ship_location  \\\n",
       "0           None  ...         None             None          None   \n",
       "1      GREENBERG  ...         None             None          None   \n",
       "2        SCIURBA  ...         None             None          None   \n",
       "3       KNUCKLES  ...         None             None          None   \n",
       "4           KORY  ...         None             None          None   \n",
       "\n",
       "  ship_address ship_city ship_state ship_zip has_medical  \\\n",
       "0         None      None       None     None           Y   \n",
       "1         None      None       None     None           Y   \n",
       "2         None      None       None     None           Y   \n",
       "3         None      None       None     None           Y   \n",
       "4         None      None       None     None           Y   \n",
       "\n",
       "  primary_coverage_type          primary_payer_name primary_payer_type  \\\n",
       "0               MEDICAL              GENERAL DIRECT         COMMERCIAL   \n",
       "1               MEDICAL  BROWN & TOLAND MEDICAL GRP         COMMERCIAL   \n",
       "2               MEDICAL     GENERAL HORIZON BCBS NJ         COMMERCIAL   \n",
       "3               MEDICAL     ANTHEM BCBS OF KENTUCKY           MEDICARE   \n",
       "4               MEDICAL             EXPRESS SCRIPTS         COMMERCIAL   \n",
       "\n",
       "  secondary_coverage_type secondary_payer_name secondary_payer_type  \\\n",
       "0                    None                 None                 None   \n",
       "1                    None                 None                 None   \n",
       "2                    None                 None                 None   \n",
       "3                    None                 None                 None   \n",
       "4                    None                 None                 None   \n",
       "\n",
       "  plan_paid_amt pat_copay copay_assist_amount oth_payer_amt xfer_pharmname  \\\n",
       "0          None      None                None          None           None   \n",
       "1          None      None                None          None           None   \n",
       "2          None      None                None          None           None   \n",
       "3          None      None                None          None           None   \n",
       "4          None      None                None          None           None   \n",
       "\n",
       "  msa_patient_id msa_patient_bmap __metadata_run_timestamp  \\\n",
       "0           None            NNNNV      2019-07-01 13:25:07   \n",
       "1           None            NNNVV      2019-07-01 13:25:07   \n",
       "2           None            NNNVV      2019-07-01 13:25:07   \n",
       "3           None            NNNVV      2019-07-01 13:25:07   \n",
       "4           None            NNNVV      2019-07-01 13:25:07   \n",
       "\n",
       "  __metadata_app_version                         __metadata_output_contract  \\\n",
       "0                 0.0.11  s3://ichain-dev/sun-extract-validation/sun/ilu...   \n",
       "1                 0.0.11  s3://ichain-dev/sun-extract-validation/sun/ilu...   \n",
       "2                 0.0.11  s3://ichain-dev/sun-extract-validation/sun/ilu...   \n",
       "3                 0.0.11  s3://ichain-dev/sun-extract-validation/sun/ilu...   \n",
       "4                 0.0.11  s3://ichain-dev/sun-extract-validation/sun/ilu...   \n",
       "\n",
       "  __metadata_transform_timestamp  \n",
       "0            2019-07-01 13:35:22  \n",
       "1            2019-07-01 13:35:22  \n",
       "2            2019-07-01 13:35:22  \n",
       "3            2019-07-01 13:35:22  \n",
       "4            2019-07-01 13:35:22  \n",
       "\n",
       "[5 rows x 71 columns]"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unit test/development\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color=red>**CALL**</font> THE TRANSFORM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-08-01 21:44:54,244 - core.transforms.master.master_patient_substatus - INFO - CALL THE TRANSFORM - execute your transformation\n",
      "2019-08-01 21:44:54,246 - core.transforms.master.master_patient_substatus - INFO - try:\n",
      "2019-08-01 21:44:54,249 - core.transforms.master.master_patient_substatus - INFO - df in  shape: 10060 71\n",
      "2019-08-01 21:44:54,286 - core.transforms.master.master_patient_substatus - INFO - df in            rec_date pharm_code   pharm_npi transtype  \\\n",
      "0  2018103004:01:55        BRV  1083045140       COM   \n",
      "1  2018103004:01:55        BRV  1497845317       COM   \n",
      "2  2018103004:01:55        BRV  1497845317       COM   \n",
      "3  2018103004:01:55        BRV  1497845317       COM   \n",
      "4  2018103004:01:55        BRV  1083045140       COM   \n",
      "\n",
      "          pharm_transaction_id trans_seq ref_source          ref_date  \\\n",
      "0  BRIOVARX_20181030_110343541         0     DIRECT  2018102616:24:58   \n",
      "1  BRIOVARX_20181030_110401861         0     DIRECT  2018102708:20:12   \n",
      "2  BRIOVARX_20181030_110401862         0     DIRECT  2018102708:20:12   \n",
      "3  BRIOVARX_20181030_110401863         0     DIRECT  2018102708:20:12   \n",
      "4  BRIOVARX_20181030_110555232         0     DIRECT  2018102911:21:44   \n",
      "\n",
      "  program_id pharmacy_id pat_last_name pat_first_name pat_dob pat_gender  \\\n",
      "0       None   421315044          None           None    None          M   \n",
      "1       None   413720460          None           None    None          F   \n",
      "2       None   413720460          None           None    None          F   \n",
      "3       None   413720460          None           None    None          F   \n",
      "4       None   418462704          None           None    None          M   \n",
      "\n",
      "  pat_addr1 pat_addr2 pat_city pat_state pat_zip dx1_code dx2_code  \\\n",
      "0      None      None     None      None      11      E11     None   \n",
      "1      None      None     None      None      78    L40.0     None   \n",
      "2      None      None     None      None      78    L40.0     None   \n",
      "3      None      None     None      None      78    L40.0     None   \n",
      "4      None      None     None      None      46      C61     None   \n",
      "\n",
      "        status_date status_code       sub_status pres_last_name  ...  \\\n",
      "0  2018102915:50:41      ACTIVE            READY   PAPADOPOULOS  ...   \n",
      "1  2018102914:48:33      ACTIVE         SHIPMENT        VIERNES  ...   \n",
      "2  2018102912:57:51   CANCELLED            OTHER        VIERNES  ...   \n",
      "3  2018102912:57:51   CANCELLED            OTHER        VIERNES  ...   \n",
      "4  2018102914:59:23     PENDING  PATIENT CONTACT          ZHANG  ...   \n",
      "\n",
      "  ship_carrier shiptracking_num      ship_location             ship_address  \\\n",
      "0         None             None               None                     None   \n",
      "1         None             None  PRESCRIBER OFFICE  6811 AUSTIN CENTER BLVD   \n",
      "2         None             None               None                     None   \n",
      "3         None             None               None                     None   \n",
      "4         None             None               None                     None   \n",
      "\n",
      "  ship_city ship_state ship_zip has_medical primary_coverage_type  \\\n",
      "0      None       None     None           N              PHARMACY   \n",
      "1    AUSTIN         TX       78           N              PHARMACY   \n",
      "2      None       None     None           N              PHARMACY   \n",
      "3      None       None     None           N              PHARMACY   \n",
      "4      None       None     None           N              PHARMACY   \n",
      "\n",
      "  primary_payer_name primary_payer_type secondary_coverage_type  \\\n",
      "0           CAREMARK                PBM                    None   \n",
      "1        UHC C AND S         MEDICARE D                    None   \n",
      "2        UHC C AND S         MEDICARE D                    None   \n",
      "3        UHC C AND S         MEDICARE D                    None   \n",
      "4        UHC C AND S         MEDICARE D                    None   \n",
      "\n",
      "  secondary_payer_name secondary_payer_type plan_paid_amt pat_copay  \\\n",
      "0                 None                 None          None      None   \n",
      "1                 None                 None          None      None   \n",
      "2                 None                 None          None      None   \n",
      "3                 None                 None          None      None   \n",
      "4                 None                 None          None      None   \n",
      "\n",
      "  copay_assist_amount oth_payer_amt xfer_pharmname msa_patient_id  \\\n",
      "0                None          None           None        2130008   \n",
      "1                None          None           None        2220004   \n",
      "2                None          None           None        2220004   \n",
      "3                None          None           None        2220004   \n",
      "4                None          None           None        2260000   \n",
      "\n",
      "  msa_patient_bmap __metadata_run_timestamp __metadata_app_version  \\\n",
      "0            VVVVV      2019-07-01 13:25:07                 0.0.11   \n",
      "1            VVVVV      2019-07-01 13:25:07                 0.0.11   \n",
      "2            VVVVV      2019-07-01 13:25:07                 0.0.11   \n",
      "3            VVVVV      2019-07-01 13:25:07                 0.0.11   \n",
      "4            VVVVV      2019-07-01 13:25:07                 0.0.11   \n",
      "\n",
      "                          __metadata_output_contract  \\\n",
      "0  s3://ichain-dev/sun-extract-validation/sun/ilu...   \n",
      "1  s3://ichain-dev/sun-extract-validation/sun/ilu...   \n",
      "2  s3://ichain-dev/sun-extract-validation/sun/ilu...   \n",
      "3  s3://ichain-dev/sun-extract-validation/sun/ilu...   \n",
      "4  s3://ichain-dev/sun-extract-validation/sun/ilu...   \n",
      "\n",
      "  __metadata_transform_timestamp  \n",
      "0            2019-07-01 13:35:28  \n",
      "1            2019-07-01 13:35:28  \n",
      "2            2019-07-01 13:35:28  \n",
      "3            2019-07-01 13:35:28  \n",
      "4            2019-07-01 13:35:28  \n",
      "\n",
      "[5 rows x 71 columns]\n",
      "2019-08-01 21:44:54,288 - core.transforms.master.master_patient_substatus - INFO - expecting column name patient sub status as:sub_status\n",
      "2019-08-01 21:44:54,289 - core.transforms.master.master_patient_substatus - INFO - df column names:['rec_date', 'pharm_code', 'pharm_npi', 'transtype', 'pharm_transaction_id', 'trans_seq', 'ref_source', 'ref_date', 'program_id', 'pharmacy_id', 'pat_last_name', 'pat_first_name', 'pat_dob', 'pat_gender', 'pat_addr1', 'pat_addr2', 'pat_city', 'pat_state', 'pat_zip', 'dx1_code', 'dx2_code', 'status_date', 'status_code', 'sub_status', 'pres_last_name', 'pres_first_name', 'pres_addr1', 'pres_addr2', 'pres_city', 'pres_state', 'pres_zip', 'pres_phone', 'pres_npi', 'pres_dea', 'facility_name', 'rxdate', 'rxnumber', 'rxrefills', 'rxfill', 'refill_remaining', 'prev_disp', 'rx_ndc_number', 'medication', 'quantity', 'day_supply', 'ship_date', 'ship_carrier', 'shiptracking_num', 'ship_location', 'ship_address', 'ship_city', 'ship_state', 'ship_zip', 'has_medical', 'primary_coverage_type', 'primary_payer_name', 'primary_payer_type', 'secondary_coverage_type', 'secondary_payer_name', 'secondary_payer_type', 'plan_paid_amt', 'pat_copay', 'copay_assist_amount', 'oth_payer_amt', 'xfer_pharmname', 'msa_patient_id', 'msa_patient_bmap', '__metadata_run_timestamp', '__metadata_app_version', '__metadata_output_contract', '__metadata_transform_timestamp']\n",
      "2019-08-01 21:44:54,290 - core.transforms.master.master_patient_substatus - INFO - Clean: space Strip and Upper and other cleanup...\n",
      "{'BENEFITS INVESTIGATION': 'BENEFITS', 'INS OON\\xa0': 'INSURANCE OON', 'OTHER ': 'OTHER', 'P05': 'PA', 'PATENT RESPONSE': 'PATIENT RESPONSE', 'PATIENT\\xa0 RESPONSE': 'PATIENT RESPONSE', 'PATIENT RESPOSNE': 'PATIENT RESPONSE', 'PRESCRIBERHOLD': 'PRESCRIBER HOLD', 'TRANSER SP': 'TRANSFER SP'}\n",
      "2019-08-01 21:44:54,315 - core.transforms.master.master_patient_substatus - INFO - Gold Domain List:['ALT THERAPY', 'APPEAL', 'BENEFITS', 'COPAY ASSISTANCE', 'DELAY', 'DOSAGE', 'FORMULARY', 'FOUNDATION', 'HOLD OTHER', 'HOLD RTS', 'INFORMATION', 'INS OTHER', 'INSURANCE COPAY', 'INSURANCE DENIED', 'INSURANCE HOLD', 'INSURANCE OON', 'INSURANCE OTHER', 'INVENTORY HOLD', 'MATERIAL', 'NEW', 'OTHER', 'PA', 'PATIENT CONTACT', 'PATIENT DECEASED', 'PATIENT END', 'PATIENT FINANCIAL', 'PATIENT HOLD', 'PATIENT RESPONSE', 'PRESCRIBER', 'PRESCRIBER END', 'PRESCRIBER HOLD', 'PT HOLD', 'QUANTITY', 'READY', 'SERVICES END', 'SHIPMENT', 'STEP EDIT', 'THERAPY COMPLETE', 'THERAPY END', 'THERAPY HOLD', 'TRANSFER HUB', 'TRANSFER SP', 'TREATMENT DELAY']\n",
      "2019-08-01 21:44:54,349 - core.transforms.master.master_patient_substatus - INFO - df in   shape: 10060 71\n",
      "2019-08-01 21:44:54,349 - core.transforms.master.master_patient_substatus - INFO - df pass shape: 10060 71\n",
      "2019-08-01 21:44:54,350 - core.transforms.master.master_patient_substatus - INFO - df fail shape: 0 71\n",
      "2019-08-01 21:44:54,382 - core.transforms.master.master_patient_substatus - INFO - df pass            rec_date pharm_code   pharm_npi transtype  \\\n",
      "0  2018103004:01:55        BRV  1083045140       COM   \n",
      "1  2018103004:01:55        BRV  1497845317       COM   \n",
      "2  2018103004:01:55        BRV  1497845317       COM   \n",
      "3  2018103004:01:55        BRV  1497845317       COM   \n",
      "4  2018103004:01:55        BRV  1083045140       COM   \n",
      "\n",
      "          pharm_transaction_id trans_seq ref_source          ref_date  \\\n",
      "0  BRIOVARX_20181030_110343541         0     DIRECT  2018102616:24:58   \n",
      "1  BRIOVARX_20181030_110401861         0     DIRECT  2018102708:20:12   \n",
      "2  BRIOVARX_20181030_110401862         0     DIRECT  2018102708:20:12   \n",
      "3  BRIOVARX_20181030_110401863         0     DIRECT  2018102708:20:12   \n",
      "4  BRIOVARX_20181030_110555232         0     DIRECT  2018102911:21:44   \n",
      "\n",
      "  program_id pharmacy_id pat_last_name pat_first_name pat_dob pat_gender  \\\n",
      "0       None   421315044          None           None    None          M   \n",
      "1       None   413720460          None           None    None          F   \n",
      "2       None   413720460          None           None    None          F   \n",
      "3       None   413720460          None           None    None          F   \n",
      "4       None   418462704          None           None    None          M   \n",
      "\n",
      "  pat_addr1 pat_addr2 pat_city pat_state pat_zip dx1_code dx2_code  \\\n",
      "0      None      None     None      None      11      E11     None   \n",
      "1      None      None     None      None      78    L40.0     None   \n",
      "2      None      None     None      None      78    L40.0     None   \n",
      "3      None      None     None      None      78    L40.0     None   \n",
      "4      None      None     None      None      46      C61     None   \n",
      "\n",
      "        status_date status_code       sub_status pres_last_name  ...  \\\n",
      "0  2018102915:50:41      ACTIVE            READY   PAPADOPOULOS  ...   \n",
      "1  2018102914:48:33      ACTIVE         SHIPMENT        VIERNES  ...   \n",
      "2  2018102912:57:51   CANCELLED            OTHER        VIERNES  ...   \n",
      "3  2018102912:57:51   CANCELLED            OTHER        VIERNES  ...   \n",
      "4  2018102914:59:23     PENDING  PATIENT CONTACT          ZHANG  ...   \n",
      "\n",
      "  ship_carrier shiptracking_num      ship_location             ship_address  \\\n",
      "0         None             None               None                     None   \n",
      "1         None             None  PRESCRIBER OFFICE  6811 AUSTIN CENTER BLVD   \n",
      "2         None             None               None                     None   \n",
      "3         None             None               None                     None   \n",
      "4         None             None               None                     None   \n",
      "\n",
      "  ship_city ship_state ship_zip has_medical primary_coverage_type  \\\n",
      "0      None       None     None           N              PHARMACY   \n",
      "1    AUSTIN         TX       78           N              PHARMACY   \n",
      "2      None       None     None           N              PHARMACY   \n",
      "3      None       None     None           N              PHARMACY   \n",
      "4      None       None     None           N              PHARMACY   \n",
      "\n",
      "  primary_payer_name primary_payer_type secondary_coverage_type  \\\n",
      "0           CAREMARK                PBM                    None   \n",
      "1        UHC C AND S         MEDICARE D                    None   \n",
      "2        UHC C AND S         MEDICARE D                    None   \n",
      "3        UHC C AND S         MEDICARE D                    None   \n",
      "4        UHC C AND S         MEDICARE D                    None   \n",
      "\n",
      "  secondary_payer_name secondary_payer_type plan_paid_amt pat_copay  \\\n",
      "0                 None                 None          None      None   \n",
      "1                 None                 None          None      None   \n",
      "2                 None                 None          None      None   \n",
      "3                 None                 None          None      None   \n",
      "4                 None                 None          None      None   \n",
      "\n",
      "  copay_assist_amount oth_payer_amt xfer_pharmname msa_patient_id  \\\n",
      "0                None          None           None        2130008   \n",
      "1                None          None           None        2220004   \n",
      "2                None          None           None        2220004   \n",
      "3                None          None           None        2220004   \n",
      "4                None          None           None        2260000   \n",
      "\n",
      "  msa_patient_bmap __metadata_run_timestamp __metadata_app_version  \\\n",
      "0            VVVVV      2019-07-01 13:25:07                 0.0.11   \n",
      "1            VVVVV      2019-07-01 13:25:07                 0.0.11   \n",
      "2            VVVVV      2019-07-01 13:25:07                 0.0.11   \n",
      "3            VVVVV      2019-07-01 13:25:07                 0.0.11   \n",
      "4            VVVVV      2019-07-01 13:25:07                 0.0.11   \n",
      "\n",
      "                          __metadata_output_contract  \\\n",
      "0  s3://ichain-dev/sun-extract-validation/sun/ilu...   \n",
      "1  s3://ichain-dev/sun-extract-validation/sun/ilu...   \n",
      "2  s3://ichain-dev/sun-extract-validation/sun/ilu...   \n",
      "3  s3://ichain-dev/sun-extract-validation/sun/ilu...   \n",
      "4  s3://ichain-dev/sun-extract-validation/sun/ilu...   \n",
      "\n",
      "  __metadata_transform_timestamp  \n",
      "0            2019-07-01 13:35:28  \n",
      "1            2019-07-01 13:35:28  \n",
      "2            2019-07-01 13:35:28  \n",
      "3            2019-07-01 13:35:28  \n",
      "4            2019-07-01 13:35:28  \n",
      "\n",
      "[5 rows x 71 columns]\n",
      "2019-08-01 21:44:54,385 - core.transforms.master.master_patient_substatus - INFO - df fail Empty DataFrame\n",
      "Columns: [rec_date, pharm_code, pharm_npi, transtype, pharm_transaction_id, trans_seq, ref_source, ref_date, program_id, pharmacy_id, pat_last_name, pat_first_name, pat_dob, pat_gender, pat_addr1, pat_addr2, pat_city, pat_state, pat_zip, dx1_code, dx2_code, status_date, status_code, sub_status, pres_last_name, pres_first_name, pres_addr1, pres_addr2, pres_city, pres_state, pres_zip, pres_phone, pres_npi, pres_dea, facility_name, rxdate, rxnumber, rxrefills, rxfill, refill_remaining, prev_disp, rx_ndc_number, medication, quantity, day_supply, ship_date, ship_carrier, shiptracking_num, ship_location, ship_address, ship_city, ship_state, ship_zip, has_medical, primary_coverage_type, primary_payer_name, primary_payer_type, secondary_coverage_type, secondary_payer_name, secondary_payer_type, plan_paid_amt, pat_copay, copay_assist_amount, oth_payer_amt, xfer_pharmname, msa_patient_id, msa_patient_bmap, __metadata_run_timestamp, __metadata_app_version, __metadata_output_contract, __metadata_transform_timestamp]\n",
      "Index: []\n",
      "\n",
      "[0 rows x 71 columns]\n",
      "2019-08-01 21:44:54,386 - core.transforms.master.master_patient_substatus - INFO - CALL THE TRANSFORM -  go no go = GO\n"
     ]
    }
   ],
   "source": [
    "### Use the variables above to execute your transformation.\n",
    "### the final output needs to be a variable named final_dataframe\n",
    "logger.info(\"CALL THE TRANSFORM - execute your transformation\")\n",
    "\n",
    "final_dataframe, final_fail, go = transform.master_patient_substatus(df)\n",
    "\n",
    "if go==True:\n",
    "    logger.info(\"CALL THE TRANSFORM -  go no go = GO\")\n",
    "elif go==False:\n",
    "    logger.info(\"CALL THE TRANSFORM -  go no go = NO go\")\n",
    "else:\n",
    "    go=False\n",
    "    logger.info(\"CALL THE TRANSFORM -  go no go = unknown make it NO go\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### *<font color=grey>unittest python*</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "test_ut_shape (__main__.TestNotebook) ... ok\n",
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.002s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.main.TestProgram at 0x7fcedc3a6dd8>"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import unittest\n",
    "\n",
    "def ut_shape(final_dataframe,df):\n",
    "    \"\"\"\n",
    "    assertion will change based on coding state\n",
    "    \"\"\"\n",
    "    return final_dataframe.shape == df.shape\n",
    "\n",
    "class TestNotebook(unittest.TestCase):\n",
    "    \n",
    "    def test_ut_shape(self):\n",
    "        \n",
    "        self.assertEqual(ut_shape(final_dataframe,df),True)\n",
    "                \n",
    "\"\"\"\n",
    "expect ... ok for now until I add some transform code since transform function is doing nothing yet\n",
    "\n",
    "\"\"\"\n",
    "# for development only\n",
    "unittest.main(argv=[''], verbosity= 2, exit=False)        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Series([], Name: sub_status, dtype: object)"
      ]
     },
     "execution_count": 289,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# untit test/development look at the fails\n",
    "#final_fail.head()\n",
    "final_fail[transform.col_substatus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                  OTHER\n",
       "1          INSURANCE OON\n",
       "2                  OTHER\n",
       "3          INSURANCE OON\n",
       "4                  OTHER\n",
       "5          INSURANCE OON\n",
       "6                  OTHER\n",
       "7                  OTHER\n",
       "8                  OTHER\n",
       "9          INSURANCE OON\n",
       "10      INSURANCE DENIED\n",
       "11                 OTHER\n",
       "12           PATIENT END\n",
       "13                 READY\n",
       "14                 READY\n",
       "15              SHIPMENT\n",
       "16              SHIPMENT\n",
       "17                 READY\n",
       "18      PATIENT RESPONSE\n",
       "19                 OTHER\n",
       "20                 READY\n",
       "21              SHIPMENT\n",
       "22         INSURANCE OON\n",
       "23                 READY\n",
       "24                 READY\n",
       "25              SHIPMENT\n",
       "26              SHIPMENT\n",
       "27              SHIPMENT\n",
       "28         INSURANCE OON\n",
       "29              SHIPMENT\n",
       "              ...       \n",
       "1925               OTHER\n",
       "1926            SHIPMENT\n",
       "1927     PATIENT CONTACT\n",
       "1928            SHIPMENT\n",
       "1929            SHIPMENT\n",
       "1930               READY\n",
       "1931               OTHER\n",
       "1932               OTHER\n",
       "1933     PATIENT CONTACT\n",
       "1934               OTHER\n",
       "1935            SHIPMENT\n",
       "1936               OTHER\n",
       "1937       INSURANCE OON\n",
       "1938     PATIENT CONTACT\n",
       "1939               OTHER\n",
       "1940            SHIPMENT\n",
       "1941            SHIPMENT\n",
       "1942                 NEW\n",
       "1943               OTHER\n",
       "1944                 NEW\n",
       "1945               OTHER\n",
       "1946    INSURANCE DENIED\n",
       "1947               OTHER\n",
       "1948               READY\n",
       "1949               OTHER\n",
       "1950               READY\n",
       "1951            SHIPMENT\n",
       "1952               OTHER\n",
       "1953     PATIENT CONTACT\n",
       "1954               OTHER\n",
       "Name: sub_status, Length: 1955, dtype: object"
      ]
     },
     "execution_count": 288,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# untit test/development look at the pass(es)\n",
    "#final_dataframe.head()\n",
    "final_dataframe[transform.col_substatus]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **publish**\n",
    "### Writing to S3\n",
    "Invoke the `publish()` command to write to a given contract. Some things to know:\n",
    "- To invoke publish a contract must be at the grain of dataset. This is because file names will be set by the dataframe=\\>parquet conversion. \n",
    "- publish only accepts a pandas dataframe.\n",
    "- publish does not allow for timedelta data types at this time (this is missing functionality in pyarrow).\n",
    "- publish handles partitioning the data as per contract, creating file paths, and creating the binary parquet files in S3, as well as the needed metadata. <br>\n",
    "**- by default, all datasets include a single partition, \\_\\_metadata\\_run\\_id, the RunEvent ID of an executed pipeline**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## that's it - just provide the final dataframe to the var final_dataframe and we take it from there\n",
    "if go==True:\n",
    "    logger.info(\"PUBLISH - that's it - its a GO - just provide the final dataframe to the var final_dataframe and we take it from there\")\n",
    "    transform.publish_contract.publish(final_dataframe, run_id, session)\n",
    "elif go==False:\n",
    "    logger.info(\"PUBLISH -  go no go = NO go -  so DONT publish\")\n",
    "else:\n",
    "    go=False\n",
    "    logger.info(\"PUBLISH -  go no go = unknown make it NO go - so DONT publish\")    \n",
    "session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
